{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98438fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================\n",
    "# Extract ELA(int8) / PRNU(int8) / CLIP(float32) ‚Üí save as .npy\n",
    "# ======================================================\n",
    "\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "import os, random, warnings, json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageChops, ImageFile\n",
    "from skimage import io as skio\n",
    "from skimage.util import img_as_float32\n",
    "from skimage.restoration import denoise_wavelet\n",
    "from skimage.transform import resize\n",
    "from tqdm.notebook import tqdm\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# ---------------- ConfigÔºàÊîπÈÄôË£°Ôºâ ----------------\n",
    "REAL_DIR = Path(\"/home/yaya/ai-detect-proj/data/Pic\")\n",
    "FAKE_DIR = Path(\"/home/yaya/ai-detect-proj/data/6kflux\")\n",
    "\n",
    "OUT_ROOT = Path(\"/home/yaya/ai-detect-proj/Script/features_test\")  # ÊúÉËá™ÂãïÂª∫Á´ã\n",
    "# ÊúÉÁîüÊàêÔºö\n",
    "#   OUT_ROOT/ela_real_npy/*.npy   Ôºàint8Ôºâ\n",
    "#   OUT_ROOT/ela_fake_npy/*.npy   Ôºàint8Ôºâ\n",
    "#   OUT_ROOT/prnu_real_npy/*.npy  Ôºàint8Ôºâ\n",
    "#   OUT_ROOT/prnu_fake_npy/*.npy  Ôºàint8Ôºâ\n",
    "#   OUT_ROOT/clip_real_npy/*.npy  Ôºàfloat32Ôºâ\n",
    "#   OUT_ROOT/clip_fake_npy/*.npy  Ôºàfloat32Ôºâ\n",
    "\n",
    "RUN_CLASSES = [\"fake\"]                 # ÂèØ‰ª•Êîπ [\"real\"], [\"fake\"], Êàñ [\"real\",\"fake\"]\n",
    "SELECT_FEATURES = [\"ela\", \"prnu\", \"clip\"]  # ÊÉ≥Âè™Ë∑ëÂÖ∂‰∏≠ÂπæÂÄãÂ∞±Âà™ÊéâÂÖ∂È§ò\n",
    "\n",
    "# ‚¨áÔ∏é ÊäΩÊ®£‰∏äÈôêÔºöÊØèÂÄã class ÊúÄÂ§öËôïÁêÜÂ§öÂ∞ëÂºµÔºàNone=‰∏çÈôêÂà∂Ôºâ\n",
    "MAX_PER_CLASS = 30000  # ‰æãÂ¶ÇÂè™Âèñ 1 Ëê¨ÂºµÔºõÊàñË®≠ None Ë°®Á§∫ÂÖ®Âèñ\n",
    "\n",
    "# ELA ÂèÉÊï∏\n",
    "IMG_SIZE     = 256     # ÂÖàÊääÊúÄÁü≠ÈÇäÊîæÂà∞ >= ÈÄôÂÄãÈï∑Â∫¶ÂæåÂÅö‰∏≠ÂøÉË£ÅÂàá\n",
    "ELA_QUALITY  = 90\n",
    "ELA_SCALE    = 15      # Âè™ÊòØÊääÂ∑ÆÂÄºÊîæÂ§ß‰ª•Â¢ûÂº∑Â∞çÊØîÔºõ‰πãÂæå‰ªçÊúÉÊò†Â∞ÑÂÜçÈáèÂåñ\n",
    "ELA_FEASZ    = 128     # ELA Ëº∏Âá∫Â∞∫ÂØ∏\n",
    "# ELA int8 Ê†ºÂºèË™™ÊòéÔºöÂÖàÊää 0..1 ‚Üí uint8(0..255) ‚Üí int8 = uint8 - 128  ÔºàÊñπ‰æøÂ≠òÊàê int8Ôºâ\n",
    "# ‰πãÂæåËÆÄÂèñÊôÇËã•Ë¶ÅÈÇÑÂéü 0..1ÔºåÂèØÁî®Ôºö(arr_i8.astype(float)+128)/255.0\n",
    "\n",
    "# PRNU ÂèÉÊï∏\n",
    "PRNU_CROP_FROM = 256   # ‰∏≠ÂøÉË£ÅËµ∑ÂßãÈÇäÈï∑Ôºà‰∏çË∂≥ÊúÉÊîæÂ§ßÔºâ\n",
    "PRNU_OUT_SIZE  = 256   # PRNU Ëº∏Âá∫Â∞∫ÂØ∏\n",
    "PRNU_WAVELET   = \"db8\" # Â∞èÊ≥¢Âü∫\n",
    "PRNU_MODE      = \"soft\"\n",
    "\n",
    "# PRNU ÈáèÂåñÔºàint8ÔºâË®≠ÂÆöÔºöÂ∞çÁ®±ÈáèÂåñ q = clip(round(x/S*127), -127, 127)\n",
    "PRNU_Q_MODE    = \"per_file\"  # 'per_file'ÔºàÊé®Ëñ¶Ôºâ| 'global'\n",
    "PRNU_Q_PERC    = 0.999       # Áî® |x| ÁöÑ p99.9 Áï∂Â∞∫Â∫¶ SÔºàÂ∞ç outlier ‰∏çÊïèÊÑüÔºâ\n",
    "PRNU_Q_SAMPLES = 4096        # ÊØèÂºµÊäΩÂπæÂÄãÂÉèÁ¥†‰º∞ÂàÜ‰ΩçÊï∏\n",
    "\n",
    "# CLIP Ê®°ÂûãÔºàÈúÄË¶Å pip ÂÆâË£ù openai-clipÔºõÊúÉ lazy-loadÔºâ\n",
    "CLIP_MODEL_NAME = \"ViT-L/14\"  # ‰Ω†‰πüÂèØÁî® \"ViT-B/32\"\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd1d2bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# ===== Âπ∂Ë°å/ÊâπÊ¨°Ë®≠ÂÆöÔºàÂèØ‰æùÊ©üÂô®Ë™øÔºâ=====\n",
    "N_WORKERS_CPU = max(1, (os.cpu_count() or 4) - 1)  # Áµ¶ ELA/PRNU Áî®ÁöÑÈÄ≤Á®ãÊï∏\n",
    "CLIP_BATCH    = 64                                   # RTX 4060 + ViT-L/14 ÂèØÂÖàÁî® 64ÔºàOOM Â∞±Èôç 48/32Ôºâ\n",
    "DL_WORKERS    = min(4, max(1, (os.cpu_count() or 4)//2))  # DataLoader ÁöÑ CPU worker\n",
    "PIN_MEMORY    = True\n",
    "\n",
    "# ÈÅøÂÖçÂ§öÈÄ≤Á®ã‰∏ã BLAS ÈÅéÂ∫¶Â§öÂü∑Ë°åÁ∑í‰∫íÊâìÊû∂\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"OPENBLAS_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"1\")\n",
    "\n",
    "# tqdm in notebookÔºàËá™Âãï fallbackÔºâ\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "except Exception:\n",
    "    from tqdm.auto import tqdm\n",
    "TQDM_KW = dict(dynamic_ncols=True, leave=False)\n",
    "\n",
    "from pathlib import Path\n",
    "import os, numpy as np\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "def _atomic_save_npy(path: Path, arr: np.ndarray):\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    # ÊñπÊ≥ï AÔºöÁ∞°ÂñÆÔºÅËá®ÊôÇÊ™îÁî® \".tmp.npy\"Ôºànp.save ‰∏çÊúÉÂÜçÂä† .npyÔºâ\n",
    "    tmp = path.with_suffix(\".tmp.npy\")\n",
    "    np.save(tmp, arr, allow_pickle=False)\n",
    "    os.replace(tmp, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7812b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------- Utils ----------------\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".webp\", \".bmp\", \".tif\", \".tiff\"}\n",
    "\n",
    "def all_images(root: Path):\n",
    "    return [p for p in root.rglob(\"*\") if p.suffix.lower() in IMG_EXTS]\n",
    "\n",
    "def ensure_dirs():\n",
    "    OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "    for feat in SELECT_FEATURES:\n",
    "        for cls in RUN_CLASSES:\n",
    "            (OUT_ROOT / f\"{feat}_{cls}_npy\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def center_resize_crop_PIL(img: Image.Image, to_size: int) -> Image.Image:\n",
    "    w, h = img.size\n",
    "    if min(w, h) < to_size:\n",
    "        s = to_size / min(w, h)\n",
    "        img = img.resize((int(round(w*s)), int(round(h*s))), Image.BICUBIC)\n",
    "        w, h = img.size\n",
    "    x0, y0 = (w - to_size)//2, (h - to_size)//2\n",
    "    return img.crop((x0, y0, x0 + to_size, y0 + to_size))\n",
    "\n",
    "def center_resize_crop_np(img: np.ndarray, crop_from=512, out_size=256) -> np.ndarray:\n",
    "    h, w = img.shape[:2]\n",
    "    if min(h, w) < crop_from:\n",
    "        s = crop_from / min(h, w)\n",
    "        img = resize(img, (int(round(h*s)), int(round(w*s))),\n",
    "                     preserve_range=True, anti_aliasing=True).astype(img.dtype)\n",
    "        h, w = img.shape[:2]\n",
    "    y0, x0 = (h - crop_from)//2, (w - crop_from)//2\n",
    "    img = img[y0:y0+crop_from, x0:x0+crop_from]\n",
    "    if crop_from != out_size:\n",
    "        img = resize(img, (out_size, out_size),\n",
    "                     preserve_range=True, anti_aliasing=True).astype(img.dtype)\n",
    "    return img\n",
    "\n",
    "# ---------------- ELAÔºà‚Üí int8Ôºâ ----------------\n",
    "def _to_int8_offset128_from_01(x01: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"x01 in [0,1] ‚Üí uint8(0..255) ‚Üí int8(-128..127)\"\"\"\n",
    "    u8 = np.rint(np.clip(x01, 0.0, 1.0) * 255.0).astype(np.uint8)\n",
    "    i8 = (u8.astype(np.int16) - 128).astype(np.int8)\n",
    "    return i8\n",
    "\n",
    "def extract_ela_i8(p: Path) -> np.ndarray | None:\n",
    "    \"\"\"ÂõûÂÇ≥ int8 (H,W) Â§ßÂ∞èÁÇ∫ ELA_FEASZ√óELA_FEASZÔºõÂÑ≤Â≠òÊ†ºÂºèÔºöuint8-128\"\"\"\n",
    "    try:\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        img = center_resize_crop_PIL(img, IMG_SIZE)\n",
    "        # JPEG ÈáçÂ£ì & Â∑ÆÂàÜ\n",
    "        buf = BytesIO()\n",
    "        img.save(buf, format=\"JPEG\", quality=int(ELA_QUALITY), subsampling=0, optimize=False)\n",
    "        buf.seek(0)\n",
    "        diff = ImageChops.difference(img, Image.open(buf)).point(lambda x: x * ELA_SCALE)\n",
    "        diff = diff.convert(\"L\").resize((ELA_FEASZ, ELA_FEASZ))\n",
    "        arr01 = np.asarray(diff, dtype=np.float32) / 255.0  # 0..1\n",
    "        q = _to_int8_offset128_from_01(arr01)\n",
    "        return q\n",
    "    except Exception as e:\n",
    "        print(\"[ELA] skip\", p.name, \"|\", e)\n",
    "        return None\n",
    "\n",
    "# ---------------- PRNUÔºà‚Üí int8Ôºâ ----------------\n",
    "def _sample_abs_vals(a: np.ndarray, k: int, rng=np.random.default_rng(SEED)) -> np.ndarray:\n",
    "    v = a.reshape(-1).astype(np.float32, copy=False)\n",
    "    if v.size <= k: return np.abs(v)\n",
    "    idx = rng.integers(0, v.size, size=k, endpoint=False)\n",
    "    return np.abs(v[idx])\n",
    "\n",
    "def _fast_percentile(v: np.ndarray, q: float) -> float:\n",
    "    if v.size == 0: return 1e-8\n",
    "    k = int(q * (v.size - 1))\n",
    "    val = np.partition(v, k)[k]\n",
    "    return float(max(val, 1e-8))\n",
    "\n",
    "def _prnu_quant_i8(a: np.ndarray, S: float) -> np.ndarray:\n",
    "    x = np.clip(a, -S, S) / S * 127.0\n",
    "    q = np.rint(x).astype(np.int16)\n",
    "    q = np.clip(q, -127, 127).astype(np.int8)\n",
    "    return q\n",
    "\n",
    "def extract_prnu_i8(p: Path) -> np.ndarray | None:\n",
    "    \"\"\"ÂõûÂÇ≥ int8 (PRNU_OUT_SIZE, PRNU_OUT_SIZE)ÔºåÂ∞çÁ®±ÈáèÂåñ\"\"\"\n",
    "    try:\n",
    "        im = skio.imread(str(p))\n",
    "        if im.ndim == 2:\n",
    "            im = np.repeat(im[..., None], 3, axis=-1)\n",
    "        im = img_as_float32(im)  # 0..1\n",
    "        crop = center_resize_crop_np(im, PRNU_CROP_FROM, PRNU_OUT_SIZE)\n",
    "        gray = crop.mean(axis=2, dtype=np.float32)\n",
    "        denoised = denoise_wavelet(gray, channel_axis=None, mode=PRNU_MODE,\n",
    "                                   wavelet=PRNU_WAVELET, convert2ycbcr=False)\n",
    "        residual = gray - denoised\n",
    "        residual -= residual.mean()\n",
    "\n",
    "        # ‰º∞ per-file S\n",
    "        if PRNU_Q_MODE == \"per_file\":\n",
    "            vals = _sample_abs_vals(residual, PRNU_Q_SAMPLES)\n",
    "            S = _fast_percentile(vals, PRNU_Q_PERC)\n",
    "        else:\n",
    "            # Ëã•Ë¶Å globalÔºåÂèØÂÖàÊéÉ‰∏ÄËº™‰º∞ SÔºåÂÜçÊîæÈÄ≤ÈÄôË£°ÔºõÁ∞°ÂåñËµ∑Ë¶ãÁî®‰øùÂ∫ï S\n",
    "            S = max(1e-6, float(np.std(residual)) * 6.0)\n",
    "\n",
    "        q = _prnu_quant_i8(residual, S)\n",
    "        return q\n",
    "    except Exception as e:\n",
    "        print(\"[PRNU] skip\", p.name, \"|\", e)\n",
    "        return None\n",
    "\n",
    "# ---------------- CLIPÔºà‚Üí float32 ÂêëÈáèÔºâ ----------------\n",
    "# ---------------- CLIPÔºà‚Üí float32ÔºõÂÄíÊï∏Á¨¨‰∫åÂ±§Ôºõopen_clip/LAIONÔºâ ----------------\n",
    "# Âèñ‰ª£ÂéüÊú¨ÁöÑ \"import torch, clip\" Ëàá extract_clip_vec() ÂçÄÂ°ä\n",
    "\n",
    "# Ë®≠ÂÆöÔºöÈÅ∏ backbone ËàáÂ∞çÊáâÁöÑ LAION Ê¨äÈáç\n",
    "CLIP_BACKBONE   = \"ViT-L-14\"         # ÂèØÊîπ \"ViT-B-32\"„ÄÅ\"ViT-L-14-336\" Á≠â\n",
    "CLIP_PRETRAINED = {\n",
    "    \"ViT-L-14\":       \"laion2b_s32b_b82k\",\n",
    "    \"ViT-B-32\":       \"laion400m_e32\",\n",
    "    \"ViT-L-14-336\":   \"laion2b_s32b_b82k\"  # 336 ËÆäÈ´îËã•ÂèØÁî®ÔºåÁ∂≠ÊåÅÂêåÊ¨äÈáçÁ≥ªÂàó\n",
    "}.get(CLIP_BACKBONE, \"laion2b_s32b_b82k\")\n",
    "\n",
    "_openclip_model = None\n",
    "_openclip_pre   = None\n",
    "_openclip_dev   = \"cpu\"\n",
    "\n",
    "# ---------------- Fix: open_clip loaderÔºàÁõ∏ÂÆπ 2/3 ÂõûÂÇ≥ÂÄºÔºâ ----------------\n",
    "_openclip_model = None\n",
    "_openclip_pre   = None\n",
    "_openclip_dev   = \"cpu\"\n",
    "\n",
    "def load_openclip():\n",
    "    global _openclip_model, _openclip_pre, _openclip_dev\n",
    "    if _openclip_model is None:\n",
    "        import torch, open_clip\n",
    "        _openclip_dev = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        res = open_clip.create_model_and_transforms(\n",
    "            CLIP_BACKBONE, pretrained=CLIP_PRETRAINED\n",
    "        )\n",
    "        # res ÂèØËÉΩÊòØ (model, pre_train, pre_val) Êàñ (model, pre)\n",
    "        if isinstance(res, tuple) and len(res) == 3:\n",
    "            model, pre_train, pre_val = res\n",
    "            pre = pre_val   # Êé®Ë´ñÁî® eval ÁâàËÆäÊèõ\n",
    "        elif isinstance(res, tuple) and len(res) == 2:\n",
    "            model, pre = res\n",
    "        else:\n",
    "            # Ê•µÂ∞ëÊï∏ÁâàÊú¨‰øùÂ∫ïÔºöÁõ¥Êé•Áî®Âè¶‰∏ÄÂÄã API\n",
    "            model, pre = open_clip.create_model_from_pretrained(\n",
    "                CLIP_BACKBONE, pretrained=CLIP_PRETRAINED\n",
    "            )\n",
    "\n",
    "        _openclip_model = model.to(_openclip_dev)\n",
    "        _openclip_model.eval()\n",
    "        _openclip_pre = pre\n",
    "\n",
    "    return _openclip_model, _openclip_pre, _openclip_dev\n",
    "\n",
    "\n",
    "def _encode_image_penultimate(model, image_tensor):\n",
    "    \"\"\"\n",
    "    ÂõûÂÇ≥ÂÄíÊï∏Á¨¨‰∫åÂ±§Ôºàpre-projectionÔºâCLS ÁâπÂæµÔºö\n",
    "    - ÂÑ™ÂÖàÂú® visual.ln_post ÂèñÂæóËº∏Âá∫ÔºàOpenAI/early open_clip ViT ÁµêÊßãÔºâ\n",
    "    - ÈÄÄËÄåÊ±ÇÂÖ∂Ê¨°Áî® trunk.forward_features() Âèñ CLSÔºåÂÜçÁ∂ì ln_postÔºàËã•Â≠òÂú®Ôºâ\n",
    "    - ÊúÄÂæåÁöÑ‰øùÂ∫ïÊòØÁî® encode_imageÔºàÊäïÂΩ±ÂæåÔºâÔºåÁ¢∫‰øù‰∏çÊúÉÂ†±ÈåØ\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    feats = {}\n",
    "    handle = None\n",
    "\n",
    "    # 1) ÂòóË©¶ hook Âú® ln_postÔºàÊäïÂΩ±ÂâçÊúÄÂæå‰∏ÄÂ±§Ôºâ\n",
    "    try:\n",
    "        target = getattr(model.visual, \"ln_post\", None)\n",
    "        if target is not None:\n",
    "            def _hook(_m, _inp, out):\n",
    "                feats[\"penult\"] = out.detach()\n",
    "            handle = target.register_forward_hook(_hook)\n",
    "            _ = model.encode_image(image_tensor)  # Ëß∏Áôº forward\n",
    "            if handle is not None:\n",
    "                handle.remove()\n",
    "            if \"penult\" in feats:\n",
    "                return feats[\"penult\"]\n",
    "    except Exception:\n",
    "        if handle is not None:\n",
    "            handle.remove()\n",
    "\n",
    "    # 2) timm trunkÔºöÁõ¥Êé•Êãø forward_features ÁöÑ CLSÔºå‰∏¶Â•ó ln_postÔºàËã•ÊúâÔºâ\n",
    "    try:\n",
    "        visual = model.visual\n",
    "        if hasattr(visual, \"trunk\") and hasattr(visual.trunk, \"forward_features\"):\n",
    "            x = visual.trunk.forward_features(image_tensor)\n",
    "            if isinstance(x, (tuple, list)):\n",
    "                x = x[0]\n",
    "            # Ëã•‰ªçÊòØ token mapÔºåÂèñ CLS\n",
    "            if x.ndim == 3:\n",
    "                x = x[:, 0, :]\n",
    "            if hasattr(visual, \"ln_post\") and visual.ln_post is not None:\n",
    "                x = visual.ln_post(x)\n",
    "            return x\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 3) ‰øùÂ∫ïÔºö‰ΩøÁî®ÊúÄÁµÇÊäïÂΩ±ÂæåÂêëÈáèÔºà‰∏çÊòØÂÄíÊï∏Á¨¨‰∫åÂ±§Ôºå‰ΩÜÈÅøÂÖç‰∏≠Êñ∑ÊµÅÁ®ãÔºâ\n",
    "    with torch.no_grad():\n",
    "        return model.encode_image(image_tensor)\n",
    "\n",
    "def extract_clip_vec(p: Path) -> np.ndarray | None:\n",
    "    \"\"\"ÂõûÂÇ≥ float32 ÂêëÈáè (D,)ÔºåD ÂèñÊ±∫Êñº backboneÔºà‰æãÂ¶Ç ViT-L-14 ‚âà 1024 Á∂≠ÂÄíÊï∏Á¨¨‰∫åÂ±§Ôºâ\"\"\"\n",
    "    try:\n",
    "        import torch\n",
    "        model, pre, dev = load_openclip()\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        # ÂÖàÂÅöÊ≠£ÊñπÂΩ¢‰∏≠ÂøÉË£ÅÂàáÔºå‰πãÂæå‰∫§Áµ¶ open_clip ÁöÑ preprocess ÂÅöÂ∞∫ÂØ∏/Ê®ôÊ∫ñÂåñ\n",
    "        w, h = img.size\n",
    "        s = min(w, h)\n",
    "        img = img.crop(((w - s)//2, (h - s)//2, (w + s)//2, (h + s)//2))\n",
    "        im = pre(img).unsqueeze(0).to(dev)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            penult = _encode_image_penultimate(model, im).float()\n",
    "            # L2 normalizeÔºàËàá‰Ω†ÂéüÊú¨‰∏ÄËá¥Ôºâ\n",
    "            penult = penult / penult.norm(dim=-1, keepdim=True).clamp_min(1e-12)\n",
    "            vec = penult.squeeze(0).cpu().numpy().astype(np.float32)\n",
    "        return vec\n",
    "    except Exception as e:\n",
    "        print(\"[CLIP] skip\", p.name, \"|\", e)\n",
    "        return None\n",
    "\n",
    "def _ela_worker(args):\n",
    "    img_path, out_path = args\n",
    "    try:\n",
    "        if out_path.exists(): \n",
    "            return True\n",
    "        arr = extract_ela_i8(img_path)\n",
    "        if arr is None:\n",
    "            return False\n",
    "        _atomic_save_npy(out_path, arr)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _prnu_worker(args):\n",
    "    img_path, out_path = args\n",
    "    try:\n",
    "        if out_path.exists():\n",
    "            return True\n",
    "        arr = extract_prnu_i8(img_path)\n",
    "        if arr is None:\n",
    "            return False\n",
    "        _atomic_save_npy(out_path, arr)\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cf6ccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _center_square(img: Image.Image) -> Image.Image:\n",
    "    w, h = img.size\n",
    "    s = min(w, h)\n",
    "    return img.crop(((w - s)//2, (h - s)//2, (w + s)//2, (h + s)//2))\n",
    "\n",
    "class _ClipPathsDataset:\n",
    "    def __init__(self, paths, pre):\n",
    "        self.paths = paths\n",
    "        self.pre   = pre\n",
    "    def __len__(self): return len(self.paths)\n",
    "    def __getitem__(self, i):\n",
    "        p = self.paths[i]\n",
    "        try:\n",
    "            img = Image.open(p).convert(\"RGB\")\n",
    "            img = _center_square(img)\n",
    "            t   = self.pre(img)\n",
    "            ok  = True\n",
    "        except Exception:\n",
    "            t, ok = None, False\n",
    "        return p, t, ok\n",
    "\n",
    "def _collate(batch):\n",
    "    # batch: list of (path, tensor, ok)\n",
    "    ps, ts = [], []\n",
    "    for p, t, ok in batch:\n",
    "        if ok and t is not None:\n",
    "            ps.append(p); ts.append(t)\n",
    "    if len(ts) == 0:\n",
    "        return [], None\n",
    "    import torch\n",
    "    return ps, torch.stack(ts, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5434d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------- Runner ----------------\n",
    "def _slug(s: str) -> str:\n",
    "    return \"\".join(c if (c.isalnum() or c in \"-_.\") else \"_\" for c in s)\n",
    "\n",
    "def make_id(p: Path, root: Path) -> str:\n",
    "    rel = p.relative_to(root)                 # a/b/c.jpg\n",
    "    base = \"_\".join(rel.with_suffix(\"\").parts)\n",
    "    dataset = _slug(root.name)                # e.g., \"unsplash\" or \"FLUX\"\n",
    "    return f\"{dataset}__{base}\"\n",
    "\n",
    "def run_extract_for_class(cls: str, root: Path):\n",
    "    files = all_images(root)\n",
    "    if MAX_PER_CLASS is not None and len(files) > MAX_PER_CLASS:\n",
    "        rng = np.random.default_rng(SEED)\n",
    "        idx = rng.choice(len(files), size=MAX_PER_CLASS, replace=False)\n",
    "        files = [files[i] for i in idx]\n",
    "    print(f\"‚Üí {cls} ({len(files)} images) from {root}\")\n",
    "\n",
    "    # Ê∫ñÂÇôËº∏Âá∫Ë≥áÊñôÂ§æ\n",
    "    dirs = {}\n",
    "    if \"ela\"  in SELECT_FEATURES: dirs[\"ela\"]  = OUT_ROOT / f\"ela_{cls}_npy\"\n",
    "    if \"prnu\" in SELECT_FEATURES: dirs[\"prnu\"] = OUT_ROOT / f\"prnu_{cls}_npy\"\n",
    "    if \"clip\" in SELECT_FEATURES: dirs[\"clip\"] = OUT_ROOT / f\"clip_{cls}_npy\"\n",
    "    for d in dirs.values(): d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # ---- ÂÖàË∑ë ELA/PRNUÔºöCPU Â§öÈÄ≤Á®ã ----\n",
    "    if \"ela\" in dirs:\n",
    "        tasks = []\n",
    "        for p in files:\n",
    "            fid  = make_id(p, root)\n",
    "            outp = dirs[\"ela\"] / f\"{fid}.npy\"\n",
    "            if not outp.exists():\n",
    "                tasks.append((p, outp))\n",
    "        if tasks:\n",
    "            print(f\"ELA (CPU x{N_WORKERS_CPU}) ‚Üí {len(tasks)}\")\n",
    "            with ProcessPoolExecutor(max_workers=N_WORKERS_CPU) as ex:\n",
    "                futs = [ex.submit(_ela_worker, t) for t in tasks]\n",
    "                ok = 0\n",
    "                for f in tqdm(as_completed(futs), total=len(futs), desc=\"ELA\", **TQDM_KW):\n",
    "                    ok += 1 if f.result() else 0\n",
    "            print(f\"ELA saved: {ok}/{len(tasks)}\")\n",
    "\n",
    "    if \"prnu\" in dirs:\n",
    "        tasks = []\n",
    "        for p in files:\n",
    "            fid  = make_id(p, root)\n",
    "            outp = dirs[\"prnu\"] / f\"{fid}.npy\"\n",
    "            if not outp.exists():\n",
    "                tasks.append((p, outp))\n",
    "        if tasks:\n",
    "            print(f\"PRNU (CPU x{N_WORKERS_CPU}) ‚Üí {len(tasks)}\")\n",
    "            with ProcessPoolExecutor(max_workers=N_WORKERS_CPU) as ex:\n",
    "                futs = [ex.submit(_prnu_worker, t) for t in tasks]\n",
    "                ok = 0\n",
    "                for f in tqdm(as_completed(futs), total=len(futs), desc=\"PRNU\", **TQDM_KW):\n",
    "                    ok += 1 if f.result() else 0\n",
    "            print(f\"PRNU saved: {ok}/{len(tasks)}\")\n",
    "\n",
    "    # ---- ÂÜçË∑ë CLIPÔºöGPU ÂñÆÈÄ≤Á®ã + DataLoader Â§öÂ∑•ËºâÂÖ• ----\n",
    "    if \"clip\" in dirs:\n",
    "        to_run = []\n",
    "        for p in files:\n",
    "            fid  = make_id(p, root)\n",
    "            outp = dirs[\"clip\"] / f\"{fid}.npy\"\n",
    "            if not outp.exists():\n",
    "                to_run.append((p, outp))\n",
    "        if to_run:\n",
    "            print(f\"CLIP (GPU batch={CLIP_BATCH}, loader_workers={DL_WORKERS}) ‚Üí {len(to_run)}\")\n",
    "            # Ê∫ñÂÇôË≥áÊñôÈõÜ / DataLoader\n",
    "            import torch\n",
    "            model, pre, dev = load_openclip()\n",
    "            ds_paths  = [p for p,_ in to_run]\n",
    "            out_paths = {p: outp for p, outp in to_run}\n",
    "            ds = _ClipPathsDataset(ds_paths, pre)\n",
    "            dl = torch.utils.data.DataLoader(\n",
    "                ds, batch_size=CLIP_BATCH, shuffle=False,\n",
    "                num_workers=DL_WORKERS, pin_memory=PIN_MEMORY,\n",
    "                collate_fn=_collate, drop_last=False\n",
    "            )\n",
    "            n_ok = 0\n",
    "            pbar = tqdm(total=len(ds_paths), desc=\"CLIP\", **TQDM_KW)\n",
    "            with torch.no_grad():\n",
    "                for paths, batch in dl:\n",
    "                    if not paths:  # ÂÖ®ÈÉ®Â£ûÂúñ\n",
    "                        continue\n",
    "                    batch = batch.to(dev, non_blocking=True)\n",
    "                    feats = _encode_image_penultimate(model, batch).float()\n",
    "                    feats = feats / feats.norm(dim=-1, keepdim=True).clamp_min(1e-12)\n",
    "                    vecs  = feats.cpu().numpy().astype(np.float32)\n",
    "                    # ÂØ´Ê™î\n",
    "                    for pth, vec in zip(paths, vecs):\n",
    "                        _atomic_save_npy(out_paths[pth], vec)\n",
    "                        n_ok += 1\n",
    "                    pbar.update(len(paths))\n",
    "            pbar.close()\n",
    "            print(f\"CLIP saved: {n_ok}/{len(ds_paths)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e412270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí fake (3650 images) from /home/yaya/ai-detect-proj/data/6kflux\n",
      "ELA (CPU x7) ‚Üí 3650\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37fda8b5ae5b4bda857df4c239c37ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ELA:   0%|          | 0/3650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELA saved: 3650/3650\n",
      "PRNU (CPU x7) ‚Üí 3650\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df135c6ecb8f4406946606eb840d4795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PRNU:   0%|          | 0/3650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRNU saved: 3650/3650\n",
      "CLIP (GPU batch=64, loader_workers=4) ‚Üí 3650\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fdebbfe74a4de1b7e753129c20a188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CLIP:   0%|          | 0/3650 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP saved: 3650/3650\n",
      "‚úÖ Done. Features saved under: /home/yaya/ai-detect-proj/Script/features_test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------------- Go! ----------------\n",
    "def ensure_dirs():\n",
    "    OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "    for feat in SELECT_FEATURES:\n",
    "        for cls in RUN_CLASSES:\n",
    "            (OUT_ROOT / f\"{feat}_{cls}_npy\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ensure_dirs()\n",
    "if \"real\" in RUN_CLASSES: run_extract_for_class(\"real\", REAL_DIR)\n",
    "if \"fake\" in RUN_CLASSES: run_extract_for_class(\"fake\", FAKE_DIR)\n",
    "print(\"‚úÖ Done. Features saved under:\", OUT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230acd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_tmp_npy(root: Path):\n",
    "    cnt = 0\n",
    "    for p in root.rglob(\"*.tmp.npy\"):\n",
    "        try:\n",
    "            p.unlink()\n",
    "            cnt += 1\n",
    "        except Exception:\n",
    "            pass\n",
    "    print(f\"üßπ cleaned {cnt} orphan .tmp.npy files under {root}\")\n",
    "\n",
    "# Ë∑ë‰∏ÄÊ¨°\n",
    "cleanup_tmp_npy(OUT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84834c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, pre, dev = load_openclip()\n",
    "print(\"device:\", dev)\n",
    "p = next(iter(REAL_DIR.rglob(\"*.jpg\")), None) or next(iter(FAKE_DIR.rglob(\"*.png\")), None)\n",
    "print(\"test image:\", p)\n",
    "v = extract_clip_vec(p)\n",
    "print(\"vec shape:\", None if v is None else v.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca4bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== GPU Áâà CLIP‚ÜíSVMÔºà‰∏ÄÊ†ºÂèØË∑ëÔºâ=====\n",
    "from pathlib import Path\n",
    "import os, json, random, numpy as np\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "# -------- Âü∫Êú¨ÂèÉÊï∏ --------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "OUT_ROOT = Path(\"/home/yaya/ai-detect-proj/Script/features_256\")\n",
    "CLIP_REAL_DIR = OUT_ROOT / \"clip_real_npy\"\n",
    "CLIP_FAKE_DIR = OUT_ROOT / \"clip_fake_npy\"\n",
    "SPLIT_JSON = Path(\"/home/yaya/ai-detect-proj/Script/splits/combined_split.json\")  # Ëã•ÁÑ°ÂâáÈö®Ê©üÂàá\n",
    "N_PER_CLASS = 10000\n",
    "C = 1.0  # SVM Âº∑Â∫¶ÔºàË∂äÂ§ßË∂äË≤ºË®ìÁ∑¥ÈõÜÔºâ\n",
    "\n",
    "# -------- ÊéÉÊ™îËàáÂàáÂàÜ --------\n",
    "def list_npy(d): return sorted([p for p in d.glob(\"*.npy\")])\n",
    "def fid(p: Path): return p.stem\n",
    "\n",
    "real_files = list_npy(CLIP_REAL_DIR)\n",
    "fake_files = list_npy(CLIP_FAKE_DIR)\n",
    "assert real_files and fake_files, \"Êâæ‰∏çÂà∞ CLIP ÁâπÂæµ .npyÔºåË´ãÂÖàÂÆåÊàêÁâπÂæµÊäΩÂèñ„ÄÇ\"\n",
    "\n",
    "id2path = {\"real\": {fid(p): p for p in real_files},\n",
    "           \"fake\": {fid(p): p for p in fake_files}}\n",
    "\n",
    "def intersect_ids(need_ids, pool_dict): return [i for i in need_ids if i in pool_dict]\n",
    "\n",
    "def make_splits():\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    if SPLIT_JSON.exists():\n",
    "        ids = json.loads(SPLIT_JSON.read_text())[\"ids\"]\n",
    "        def pick(sp, cls):\n",
    "            arr = intersect_ids(ids[sp], id2path[cls])\n",
    "            if N_PER_CLASS is not None:\n",
    "                arr = arr[:min(len(arr), N_PER_CLASS)]\n",
    "            return arr\n",
    "        splits = {\n",
    "            \"train\": [(i,0) for i in pick(\"train\",\"real\")] + [(i,1) for i in pick(\"train\",\"fake\")],\n",
    "            \"val\":   [(i,0) for i in pick(\"val\",\"real\")]   + [(i,1) for i in pick(\"val\",\"fake\")],\n",
    "            \"test\":  [(i,0) for i in pick(\"test\",\"real\")]  + [(i,1) for i in pick(\"test\",\"fake\")],\n",
    "        }\n",
    "        print(f\"‰ΩøÁî® split.jsonÔºö{SPLIT_JSON}\")\n",
    "    else:\n",
    "        real_ids = list(id2path[\"real\"].keys())\n",
    "        fake_ids = list(id2path[\"fake\"].keys())\n",
    "        random.shuffle(real_ids); random.shuffle(fake_ids)\n",
    "        if N_PER_CLASS is not None:\n",
    "            real_ids = real_ids[:min(len(real_ids), N_PER_CLASS)]\n",
    "            fake_ids = fake_ids[:min(len(fake_ids), N_PER_CLASS)]\n",
    "        # 8:1:1\n",
    "        r_tr, r_tmp = train_test_split(real_ids, test_size=0.2, random_state=SEED)\n",
    "        f_tr, f_tmp = train_test_split(fake_ids, test_size=0.2, random_state=SEED)\n",
    "        r_va, r_te  = train_test_split(r_tmp, test_size=0.5, random_state=SEED)\n",
    "        f_va, f_te  = train_test_split(f_tmp, test_size=0.5, random_state=SEED)\n",
    "        splits = {\n",
    "            \"train\": [(i,0) for i in r_tr] + [(i,1) for i in f_tr],\n",
    "            \"val\":   [(i,0) for i in r_va] + [(i,1) for i in f_va],\n",
    "            \"test\":  [(i,0) for i in r_te] + [(i,1) for i in f_te],\n",
    "        }\n",
    "        print(\"‰ΩøÁî®Èö®Ê©üÂàáÂàÜÔºàÁÑ° split.jsonÔºâ\")\n",
    "    for sp in splits:\n",
    "        random.shuffle(splits[sp])\n",
    "        n0 = sum(1 for _,y in splits[sp] if y==0); n1 = len(splits[sp])-n0\n",
    "        print(f\"{sp}: total={len(splits[sp])} | real={n0} fake={n1}\")\n",
    "    return splits\n",
    "splits = make_splits()\n",
    "\n",
    "def load_pairs(pairs):\n",
    "    X, y = [], []\n",
    "    for i, lab in pairs:\n",
    "        p = id2path[\"real\" if lab==0 else \"fake\"][i]\n",
    "        v = np.load(p, allow_pickle=False)\n",
    "        X.append(v.astype(np.float32, copy=False).reshape(-1))\n",
    "        y.append(lab)\n",
    "    return np.stack(X, 0), np.array(y, dtype=np.int32)\n",
    "\n",
    "X_train, y_train = load_pairs(splits[\"train\"])\n",
    "X_val,   y_val   = load_pairs(splits[\"val\"])\n",
    "X_test,  y_test  = load_pairs(splits[\"test\"])\n",
    "print(\"shapes:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "# -------- ÂòóË©¶ cuMLÔºàËã•‰∏çÂèØÁî®ÂâáÈÄÄÂõû PyTorch Á∑öÊÄß SVMÔºâ--------\n",
    "USE_BACKEND = None\n",
    "try:\n",
    "    import cuml, cupy as cp\n",
    "    from cuml.svm import SVC\n",
    "    USE_BACKEND = \"cuml\"\n",
    "    print(\"‚úÖ ‰ΩøÁî® cuML GPU SVM\")\n",
    "except Exception as e:\n",
    "    USE_BACKEND = \"torch\"\n",
    "    print(\"‚ö†Ô∏è cuML ‰∏çÂèØÁî®ÔºåÊîπÁî® PyTorch Á∑öÊÄß SVMÔºàGPUÔºâ:\", e)\n",
    "\n",
    "def evaluate_scores(y_true, scores, name):\n",
    "    acc = accuracy_score(y_true, (scores>0).astype(np.int32))\n",
    "    auc = roc_auc_score(y_true, scores)\n",
    "    print(f\"[{name}] acc={acc:.4f} auc={auc:.4f}\")\n",
    "    print(confusion_matrix(y_true, (scores>0).astype(np.int32)))\n",
    "    print(classification_report(y_true, (scores>0).astype(np.int32), target_names=[\"real\",\"fake\"], digits=4))\n",
    "\n",
    "if USE_BACKEND == \"cuml\":\n",
    "    # ---- cuML Á∑öÊÄß SVMÔºàGPUÔºâ----\n",
    "    Xtr = cp.asarray(X_train); ytr = cp.asarray(y_train)\n",
    "    Xva = cp.asarray(X_val);   yva = cp.asarray(y_val)\n",
    "    Xte = cp.asarray(X_test);  yte = cp.asarray(y_test)\n",
    "\n",
    "    clf = SVC(kernel=\"linear\", C=C, probability=False, max_iter=100000, tol=1e-3)\n",
    "    clf.fit(Xtr, ytr)\n",
    "\n",
    "    # decision_function > 0 Ë¶ñÁÇ∫ fakeÔºàlabel=1Ôºâ\n",
    "    s_val = clf.decision_function(Xva).get()\n",
    "    s_te  = clf.decision_function(Xte).get()\n",
    "\n",
    "    evaluate_scores(y_val,  s_val,  \"val\")\n",
    "    evaluate_scores(y_test, s_te,   \"test\")\n",
    "\n",
    "    # ÂÑ≤Â≠ò\n",
    "    import joblib\n",
    "    joblib.dump({\"backend\":\"cuml\",\"model\":clf}, \"/home/yaya/ai-detect-proj/Script/saved_models/clip_svm_gpu.pkl\")\n",
    "    print(\"‚úÖ saved: saved_models/clip_svm_gpu.pkl\")\n",
    "\n",
    "else:\n",
    "    # ---- PyTorch Á∑öÊÄß SVMÔºàhingeÔºâ----\n",
    "    import torch, torch.nn as nn\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    Xtr = torch.from_numpy(X_train).to(device)\n",
    "    Xva = torch.from_numpy(X_val).to(device)\n",
    "    Xte = torch.from_numpy(X_test).to(device)\n",
    "    # y in {0,1} ‚Üí y' in {-1,+1}\n",
    "    ytr = torch.from_numpy(np.where(y_train==1, 1, -1).astype(np.float32)).to(device)\n",
    "    yva = torch.from_numpy(np.where(y_val==1,   1, -1).astype(np.float32)).to(device)\n",
    "    yte = torch.from_numpy(np.where(y_test==1,  1, -1).astype(np.float32)).to(device)\n",
    "\n",
    "    D = Xtr.shape[1]\n",
    "    model = nn.Linear(D, 1, bias=True).to(device)\n",
    "\n",
    "    # Hinge ÊêçÂ§± + L2Ôºà= SVM ÁöÑÊ≠£ÂâáÔºâÔºömin 0.5*||w||^2 + C * Œ£ max(0, 1 - y*(Wx+b))\n",
    "    def hinge_loss(out, y):\n",
    "        # out: [N,1], y: [N] in {-1,+1}\n",
    "        m = 1 - y.unsqueeze(1) * out\n",
    "        return torch.clamp(m, min=0).mean()\n",
    "\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    EPOCHS, BATCH = 50, 1024\n",
    "    N = Xtr.shape[0]\n",
    "    best_val = float(\"inf\"); best = None\n",
    "\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        model.train()\n",
    "        perm = torch.randperm(N, device=device)\n",
    "        total = 0.0\n",
    "        for i in range(0, N, BATCH):\n",
    "            idx = perm[i:i+BATCH]\n",
    "            xb, yb = Xtr[idx], ytr[idx]\n",
    "            out = model(xb)                 # [B,1]\n",
    "            reg = 0.5 * (model.weight**2).sum()\n",
    "            loss = reg + C * hinge_loss(out, yb)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            total += loss.item() * xb.size(0)\n",
    "        # Á∞°ÂñÆ val\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            s_val = model(Xva).squeeze(1)\n",
    "            val_loss = (0.5*(model.weight**2).sum() + C*hinge_loss(s_val, yva)).item()\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            best = {k: v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
    "        if ep % 5 == 0 or ep == 1:\n",
    "            print(f\"[ep{ep:02d}] train_loss={total/N:.6f} val_obj={val_loss:.6f}\")\n",
    "\n",
    "    if best is not None:\n",
    "        model.load_state_dict(best)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        s_val = model(Xva).squeeze(1).detach().cpu().numpy()\n",
    "        s_te  = model(Xte).squeeze(1).detach().cpu().numpy()\n",
    "\n",
    "    evaluate_scores(y_val,  s_val, \"val\")\n",
    "    evaluate_scores(y_test, s_te,  \"test\")\n",
    "\n",
    "    # ÂÑ≤Â≠òÔºàTorch Ê¨äÈáçÔºâ\n",
    "    torch.save({\"state_dict\": model.state_dict(), \"D\": int(D), \"C\": C},\n",
    "               \"/home/yaya/ai-detect-proj/Script/saved_models/clip_svm_gpu_torch.pt\")\n",
    "    print(\"‚úÖ saved: saved_models/clip_svm_gpu_torch.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88cfa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== PRNU(int8) ‚Üí Fast CNN (speed-optimized) =====\n",
    "from pathlib import Path\n",
    "import os, json, random, math, time\n",
    "import numpy as np\n",
    "\n",
    "# tqdmÔºàNotebook ÂèãÂñÑÔºâ\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "except Exception:\n",
    "    from tqdm.auto import tqdm\n",
    "TQDM_KW = dict(dynamic_ncols=True, leave=False)\n",
    "\n",
    "# ---------------- Config ----------------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "SCRIPT_ROOT = Path(\"/home/yaya/ai-detect-proj/Script\")\n",
    "FEA_ROOT    = SCRIPT_ROOT / \"features_256\"\n",
    "REAL_DIR    = FEA_ROOT / \"prnu_real_npy\"\n",
    "FAKE_DIR    = FEA_ROOT / \"prnu_fake_npy\"\n",
    "SPLIT_JSON  = SCRIPT_ROOT / \"splits/combined_split.json\"  # Ëã•‰∏çÂ≠òÂú®Ëá™ÂãïÈö®Ê©üÂàá\n",
    "SAVE_DIR    = SCRIPT_ROOT / \"saved_models\"; SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "BEST_PATH   = SAVE_DIR / \"prnu_fastcnn_u8_best.pt\"\n",
    "\n",
    "# Ë≥áÊñôËàáË®ìÁ∑¥\n",
    "N_PER_CLASS = 10000         # ÊØèÈ°ûÊúÄÂ§öÂèñÂ§öÂ∞ëÔºà‰Ω†ÁöÑÊÉÖÂ¢ÉÔºöÂêÑ 2000Ôºâ\n",
    "BATCH       = 64          # 4060 Âª∫Ë≠∞ 64~128ÔºåOOM Â∞±Èôç\n",
    "EPOCHS      = 15\n",
    "LR          = 2e-3\n",
    "WEIGHT_DECAY= 1e-4\n",
    "EARLY_STOP  = 5\n",
    "\n",
    "# DataLoader\n",
    "NUM_WORKERS     = min(8, os.cpu_count() or 4)\n",
    "PIN_MEMORY      = True\n",
    "PREFETCH_FACTOR = 4\n",
    "PERSISTENT      = True\n",
    "\n",
    "# Dataset Âø´ÂèñÁ≠ñÁï•Ôºö\"ram\" | \"memmap\" | None\n",
    "CACHE_MODE = \"ram\"         # 4k Âºµ * 64KB ‚âà 256MBÔºåRAM ÂÆåÂÖ®ÂèØÊâøÂèó ‚Üí ÊúÄÂø´\n",
    "\n",
    "# ---------------- Ê™îÊ°àÂàóË°® & splits ----------------\n",
    "def list_npy(d: Path):\n",
    "    assert d.exists(), f\"Not found: {d}\"\n",
    "    return sorted([p for p in d.glob(\"*.npy\")])\n",
    "\n",
    "real_files = list_npy(REAL_DIR)\n",
    "fake_files = list_npy(FAKE_DIR)\n",
    "assert real_files and fake_files, \"Êâæ‰∏çÂà∞ PRNU ÁâπÂæµ .npyÔºåË´ãÂÖàÂÆåÊàêÁâπÂæµÊäΩÂèñ„ÄÇ\"\n",
    "\n",
    "def fid(p: Path): return p.stem\n",
    "id2path = {\"real\": {fid(p): p for p in real_files},\n",
    "           \"fake\": {fid(p): p for p in fake_files}}\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "def intersect_ids(need_ids, pool_dict): return [i for i in need_ids if i in pool_dict]\n",
    "\n",
    "def make_splits():\n",
    "    if SPLIT_JSON.exists():\n",
    "        js  = json.loads(SPLIT_JSON.read_text())\n",
    "        ids = js[\"ids\"]\n",
    "        def pick(sp, cls):\n",
    "            arr = intersect_ids(ids[sp], id2path[cls])\n",
    "            if N_PER_CLASS is not None:\n",
    "                arr = arr[:min(len(arr), N_PER_CLASS)]\n",
    "            return arr\n",
    "        splits = {\n",
    "            \"train\": [(i,0) for i in pick(\"train\",\"real\")] + [(i,1) for i in pick(\"train\",\"fake\")],\n",
    "            \"val\":   [(i,0) for i in pick(\"val\",\"real\")]   + [(i,1) for i in pick(\"val\",\"fake\")],\n",
    "            \"test\":  [(i,0) for i in pick(\"test\",\"real\")]  + [(i,1) for i in pick(\"test\",\"fake\")],\n",
    "        }\n",
    "        print(f\"‰ΩøÁî® split.jsonÔºö{SPLIT_JSON}\")\n",
    "    else:\n",
    "        real_ids = list(id2path[\"real\"].keys())\n",
    "        fake_ids = list(id2path[\"fake\"].keys())\n",
    "        random.shuffle(real_ids); random.shuffle(fake_ids)\n",
    "        if N_PER_CLASS is not None:\n",
    "            real_ids = real_ids[:min(len(real_ids), N_PER_CLASS)]\n",
    "            fake_ids = fake_ids[:min(len(fake_ids), N_PER_CLASS)]\n",
    "        r_tr, r_tmp = train_test_split(real_ids, test_size=0.2, random_state=SEED)\n",
    "        f_tr, f_tmp = train_test_split(fake_ids, test_size=0.2, random_state=SEED)\n",
    "        r_va, r_te  = train_test_split(r_tmp, test_size=0.5, random_state=SEED)  # 0.1/0.1\n",
    "        f_va, f_te  = train_test_split(f_tmp, test_size=0.5, random_state=SEED)\n",
    "        splits = {\n",
    "            \"train\": [(i,0) for i in r_tr] + [(i,1) for i in f_tr],\n",
    "            \"val\":   [(i,0) for i in r_va] + [(i,1) for i in f_va],\n",
    "            \"test\":  [(i,0) for i in r_te] + [(i,1) for i in f_te],\n",
    "        }\n",
    "        print(\"‰ΩøÁî®Èö®Ê©üÂàáÂàÜÔºàÁÑ° split.jsonÔºâ\")\n",
    "    for sp in splits:\n",
    "        random.shuffle(splits[sp])\n",
    "        n0 = sum(1 for _,y in splits[sp] if y==0); n1 = len(splits[sp])-n0\n",
    "        print(f\"{sp}: total={len(splits[sp])} | real={n0} fake={n1}\")\n",
    "    return splits\n",
    "\n",
    "splits = make_splits()\n",
    "\n",
    "# ---------------- Dataset / DataLoader ----------------\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class PRNUNPY(Dataset):\n",
    "    \"\"\"\n",
    "    PRNU int8 -> float32[-1,1]Ôºåper-sample ÂéªÂùáÂÄºÔºõÂèØ RAM Âø´ÂèñÊàñ memmap„ÄÇ\n",
    "    \"\"\"\n",
    "    def __init__(self, pairs, id2path, augment=False, cache_mode=\"ram\"):\n",
    "        self.pairs = pairs\n",
    "        self.id2p  = id2path\n",
    "        self.augment = augment\n",
    "        self.cache_mode = cache_mode\n",
    "        self.cache = []\n",
    "\n",
    "        if cache_mode == \"ram\":\n",
    "            self.cache = [None]*len(pairs)\n",
    "            for i, (idx, lab) in enumerate(pairs):\n",
    "                d = \"real\" if lab==0 else \"fake\"\n",
    "                p = self.id2p[d][idx]\n",
    "                arr = np.load(p, allow_pickle=False)     # int8\n",
    "                self.cache[i] = arr.copy()\n",
    "\n",
    "    def __len__(self): return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx, lab = self.pairs[i]\n",
    "        if self.cache_mode == \"ram\":\n",
    "            arr = self.cache[i]\n",
    "        else:\n",
    "            d = \"real\" if lab==0 else \"fake\"\n",
    "            p = self.id2p[d][idx]\n",
    "            if self.cache_mode == \"memmap\":\n",
    "                arr = np.load(p, allow_pickle=False, mmap_mode='r')\n",
    "            else:\n",
    "                arr = np.load(p, allow_pickle=False)\n",
    "\n",
    "        x = (arr.astype(np.float32) / 127.0)\n",
    "        x = x - x.mean()\n",
    "        # Â¶ÇÈúÄÊõ¥Âø´ÔºåÂèØË®ªËß£Êéâ‰ªª‰ΩïÂ¢ûÂº∑\n",
    "        if self.augment:\n",
    "            # x += np.random.normal(0.0, 0.02, size=x.shape).astype(np.float32)\n",
    "            pass\n",
    "        x = np.clip(x, -2.0, 2.0)\n",
    "        x = x[None, ...]  # [1,H,W]\n",
    "        return torch.from_numpy(x), torch.tensor(lab, dtype=torch.long)\n",
    "\n",
    "def make_loader(pairs, train=False):\n",
    "    ds = PRNUNPY(pairs, id2path, augment=train, cache_mode=CACHE_MODE)\n",
    "    return DataLoader(\n",
    "        ds, batch_size=BATCH, shuffle=train,\n",
    "        num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
    "        prefetch_factor=PREFETCH_FACTOR, persistent_workers=PERSISTENT,\n",
    "        drop_last=train\n",
    "    )\n",
    "\n",
    "train_loader = make_loader(splits[\"train\"], train=True)\n",
    "val_loader   = make_loader(splits[\"val\"],   train=False)\n",
    "test_loader  = make_loader(splits[\"test\"],  train=False)\n",
    "\n",
    "# ---------------- Fast CNN Ê®°Âûã ----------------\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DSBlock(nn.Module):\n",
    "    \"\"\"Depthwise-Separable ConvÔºöDW 3x3 + BN + ReLU ‚Üí PW 1x1 + BN + ReLU\"\"\"\n",
    "    def __init__(self, c_in, c_out, stride=1):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv2d(c_in, c_in, 3, stride=stride, padding=1, groups=c_in, bias=False)\n",
    "        self.bn1= nn.BatchNorm2d(c_in)\n",
    "        self.pw = nn.Conv2d(c_in, c_out, 1, bias=False)\n",
    "        self.bn2= nn.BatchNorm2d(c_out)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.bn1(self.dw(x)))\n",
    "        x = self.act(self.bn2(self.pw(x)))\n",
    "        return x\n",
    "\n",
    "class PRNUFastCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    1√ó256√ó256 ‚Üí (stem 32) ‚Üí DS(64,s=1) ‚Üí DS(128,s=2) ‚Üí DS(128,s=1)\n",
    "                 ‚Üí DS(256,s=2) ‚Üí DS(256,s=1) ‚Üí GAP ‚Üí FC\n",
    "    Á¥Ñ 0.6M ÂèÉÊï∏ÔºåÂêûÂêêÂø´ÔºåÂ∞çÁ¥ãÁêÜÊúâÊïà„ÄÇ\n",
    "    \"\"\"\n",
    "    def __init__(self, nc=1, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(nc, 32, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.stage = nn.Sequential(\n",
    "            DSBlock(32, 64,  stride=1),   # 256\n",
    "            DSBlock(64, 128, stride=2),   # 128\n",
    "            DSBlock(128,128, stride=1),   # 128\n",
    "            DSBlock(128,256, stride=2),   # 64\n",
    "            DSBlock(256,256, stride=1),   # 64\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc   = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.stage(x)\n",
    "        x = self.head(x)\n",
    "        x = self.pool(x).squeeze(-1).squeeze(-1)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# ---------------- Ë®ìÁ∑¥ & Ë©ï‰º∞ ----------------\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    ys, logits = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device, non_blocking=True).contiguous(memory_format=torch.channels_last)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "            out = model(x)\n",
    "            logits.append(out.detach().cpu().numpy())\n",
    "            ys.append(y.detach().cpu().numpy())\n",
    "    logits = np.concatenate(logits, 0)\n",
    "    y_true = np.concatenate(ys, 0)\n",
    "    y_pred = logits.argmax(1)\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    prob1 = torch.softmax(torch.from_numpy(logits), dim=1).numpy()[:,1]\n",
    "    auc = roc_auc_score(y_true, prob1)\n",
    "    return acc, auc, y_true, y_pred, prob1\n",
    "\n",
    "def train_prnu_fastcnn():\n",
    "    set_seed(SEED)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    model  = PRNUFastCNN().to(device)\n",
    "    model  = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "    # bf16 > fp16ÔºàAda ÊîØÊè¥ bf16Ôºâ\n",
    "    AMP_DTYPE = torch.bfloat16 if (torch.cuda.is_available() and torch.cuda.is_bf16_supported()) else torch.float16\n",
    "    USE_SCALER = (AMP_DTYPE == torch.float16)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=USE_SCALER)\n",
    "\n",
    "    # È°ûÂà•Ê¨äÈáçÔºàÈÅøÂÖç‰∏çÂπ≥Ë°°Ôºâ\n",
    "    n0 = sum(1 for _,y in splits[\"train\"] if y==0); n1 = len(splits[\"train\"])-n0\n",
    "    w = torch.tensor([1.0/n0, 1.0/n1], dtype=torch.float32, device=device)\n",
    "    w = w / w.mean()\n",
    "\n",
    "    crit  = nn.CrossEntropyLoss(weight=w)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=EPOCHS)\n",
    "\n",
    "    best_auc, best_state, no_improve = -1.0, None, 0\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        model.train()\n",
    "        losses = []\n",
    "        pbar = tqdm(train_loader, desc=f\"train ep{ep}\", **TQDM_KW)\n",
    "        for x,y in pbar:\n",
    "            x = x.to(device, non_blocking=True).contiguous(memory_format=torch.channels_last)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "            with torch.cuda.amp.autocast(dtype=AMP_DTYPE):\n",
    "                out  = model(x)\n",
    "                loss = crit(out, y)\n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            if USE_SCALER:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optim)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "            losses.append(loss.item())\n",
    "            pbar.set_postfix(loss=f\"{np.mean(losses):.4f}\")\n",
    "        sched.step()\n",
    "\n",
    "        # È©óË≠â\n",
    "        val_acc, val_auc, *_ = evaluate(model, val_loader, device)\n",
    "        print(f\"[EP {ep:02d}] train_loss={np.mean(losses):.4f} | val acc={val_acc:.4f} auc={val_auc:.4f}\")\n",
    "\n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            best_state = {\"model\": model.state_dict(),\n",
    "                          \"meta\": {\"arch\":\"PRNUFastCNN\",\"seed\":SEED,\"epochs_done\":ep,\n",
    "                                   \"val_auc\":float(val_auc),\"val_acc\":float(val_acc),\n",
    "                                   \"input\":\"PRNU int8 ‚Üí float32/127, zero-mean\",\n",
    "                                   \"shape\":[1,256,256]}}\n",
    "            torch.save(best_state, BEST_PATH)\n",
    "            print(\"  ‚Ü≥ saved best:\", BEST_PATH)\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= EARLY_STOP:\n",
    "                print(f\"‚èπ Early stop (no AUC improvement {EARLY_STOP} epochs).\")\n",
    "                break\n",
    "\n",
    "    # ËºâÂÖ•ÊúÄ‰Ω≥Ê¨äÈáç‰∏¶Âú® test Ë©ï‰º∞\n",
    "    if best_state is None and BEST_PATH.exists():\n",
    "        best_state = torch.load(BEST_PATH, map_location=\"cpu\")\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state[\"model\"])\n",
    "\n",
    "    test_acc, test_auc, y_true, y_pred, prob1 = evaluate(model, test_loader, device)\n",
    "    print(f\"[TEST] acc={test_acc:.4f} auc={test_auc:.4f}\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"real\",\"fake\"], digits=4))\n",
    "    return model\n",
    "\n",
    "model = train_prnu_fastcnn()\n",
    "\n",
    "# ---- ÂñÆÂºµ .npy Êé®Ë´ñ ----\n",
    "def predict_prnu_npy(npy_path: Path):\n",
    "    arr = np.load(npy_path, allow_pickle=False).astype(np.float32)\n",
    "    x = (arr/127.0); x = x - x.mean()\n",
    "    x = torch.from_numpy(x[None, None, ...])\n",
    "    device = next(model.parameters()).device\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast(dtype=torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float16):\n",
    "        logit = model(x.to(device).contiguous(memory_format=torch.channels_last))\n",
    "        prob  = torch.softmax(logit, dim=1)[0,1].item()\n",
    "        pred  = int(prob >= 0.5)  # 1=fake, 0=real\n",
    "    return pred, prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16163d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== ELA(int8) ‚Üí Fast CNNÔºà‰∏ç‰ΩøÁî® split Ê™îÔºåÈö®Ê©üÂàá 8:1:1Ôºâ=====\n",
    "from pathlib import Path\n",
    "import os, random, re, json\n",
    "import numpy as np\n",
    "\n",
    "# tqdmÔºàNotebook ÂèãÂñÑÔºâ\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "except Exception:\n",
    "    from tqdm.auto import tqdm\n",
    "TQDM_KW = dict(dynamic_ncols=True, leave=False)\n",
    "\n",
    "# ---------------- Config ----------------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "SCRIPT_ROOT = Path(\"/home/yaya/ai-detect-proj/Script\")\n",
    "FEA_ROOT    = SCRIPT_ROOT / \"features_npy\"\n",
    "ELA_REAL    = FEA_ROOT / \"ela_real_npy\"\n",
    "ELA_FAKE    = FEA_ROOT / \"ela_fake_npy\"\n",
    "\n",
    "SAVE_DIR    = SCRIPT_ROOT / \"saved_models\"; SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "BEST_PATH   = SAVE_DIR / \"ela_fastcnn_u8_best.pt\"\n",
    "\n",
    "# ÊØèÈ°ûÂèñÂ§öÂ∞ëÔºõNone = ÂÖ®ÈÉ®ÂèØÁî®\n",
    "N_PER_CLASS = 10000\n",
    "\n",
    "# Ë®ìÁ∑¥Ë®≠ÂÆö\n",
    "BATCH       = 64          # 4060 ‰∏ä 64~128 ËºÉÁ©©ÔºõOOM Â∞±Èôç\n",
    "EPOCHS      = 15\n",
    "LR          = 2e-3\n",
    "WEIGHT_DECAY= 1e-4\n",
    "EARLY_STOP  = 5\n",
    "\n",
    "# DataLoader\n",
    "NUM_WORKERS     = min(8, os.cpu_count() or 4)\n",
    "PIN_MEMORY      = True\n",
    "PREFETCH_FACTOR = 4\n",
    "PERSISTENT      = True\n",
    "\n",
    "# Dataset Âø´ÂèñÔºö\"ram\" | \"memmap\" | None\n",
    "CACHE_MODE = \"ram\"\n",
    "\n",
    "# ELA Ê≠£Ë¶èÂåñÔºöi8(-128..127) ‚Üí (i8+128)/255 ‚àà [0,1]ÔºåÂÜçÂÅöÈõ∂ÂùáÂÄº\n",
    "ELA_ZERO_MEAN = True\n",
    "\n",
    "# ---------------- ÊéÉÊ™îÔºàÊîØÊè¥ __qXXÔºåÂÑ™ÂÖà q90Ôºâ ----------------\n",
    "def list_npy(d: Path):\n",
    "    assert d.exists(), f\"Not found: {d}\"\n",
    "    return sorted([p for p in d.glob(\"*.npy\")])\n",
    "\n",
    "_q_pat = re.compile(r\"__q(\\d+)$\")\n",
    "def base_id_from_stem(stem: str):\n",
    "    m = _q_pat.search(stem); return stem[:m.start()] if m else stem\n",
    "def quality_from_stem(stem: str):\n",
    "    m = _q_pat.search(stem); return int(m.group(1)) if m else None\n",
    "\n",
    "def build_id2path(files):\n",
    "    buckets = {}\n",
    "    for p in files:\n",
    "        b = base_id_from_stem(p.stem)\n",
    "        buckets.setdefault(b, []).append(p)\n",
    "    id2path = {}\n",
    "    for b, ps in buckets.items():\n",
    "        if len(ps) == 1:\n",
    "            id2path[b] = ps[0]\n",
    "        else:\n",
    "            # ÂÑ™ÂÖà q90ÔºåÂÖ∂Ê¨°ÊåëÈõ¢ 90 ÊúÄËøë\n",
    "            scored = []\n",
    "            for pp in ps:\n",
    "                q = quality_from_stem(pp.stem)\n",
    "                scored.append((0 if q == 90 else (abs(q-90) if q is not None else 999), pp))\n",
    "            scored.sort(key=lambda x: (x[0], str(x[1])))\n",
    "            id2path[b] = scored[0][1]\n",
    "    return id2path\n",
    "\n",
    "real_files = list_npy(ELA_REAL)\n",
    "fake_files = list_npy(ELA_FAKE)\n",
    "assert real_files and fake_files, \"Êâæ‰∏çÂà∞ ELA ÁâπÂæµ .npyÔºåË´ãÂÖàÂÆåÊàêÁâπÂæµÊäΩÂèñ„ÄÇ\"\n",
    "\n",
    "id2path = {\n",
    "    \"real\": build_id2path(real_files),\n",
    "    \"fake\": build_id2path(fake_files),\n",
    "}\n",
    "\n",
    "# ---------------- Èö®Ê©üÂàá 8:1:1Ôºà‰∏ç‰ΩøÁî® split Ê™îÔºâ ----------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def cap(ids, k):\n",
    "    ids = list(ids); random.shuffle(ids)\n",
    "    return ids if (k is None or len(ids) <= k) else ids[:k]\n",
    "\n",
    "real_ids = cap(list(id2path[\"real\"].keys()), N_PER_CLASS)\n",
    "fake_ids = cap(list(id2path[\"fake\"].keys()), N_PER_CLASS)\n",
    "\n",
    "r_tr, r_tmp = train_test_split(real_ids, test_size=0.2, random_state=SEED)\n",
    "f_tr, f_tmp = train_test_split(fake_ids, test_size=0.2, random_state=SEED)\n",
    "r_va, r_te  = train_test_split(r_tmp, test_size=0.5, random_state=SEED)  # 0.1/0.1\n",
    "f_va, f_te  = train_test_split(f_tmp, test_size=0.5, random_state=SEED)\n",
    "\n",
    "splits = {\n",
    "    \"train\": [(i,0) for i in r_tr] + [(i,1) for i in f_tr],\n",
    "    \"val\":   [(i,0) for i in r_va] + [(i,1) for i in f_va],\n",
    "    \"test\":  [(i,0) for i in r_te] + [(i,1) for i in f_te],\n",
    "}\n",
    "for sp in splits:\n",
    "    random.shuffle(splits[sp])\n",
    "    n0 = sum(1 for _,y in splits[sp] if y==0); n1 = len(splits[sp])-n0\n",
    "    print(f\"{sp}: total={len(splits[sp])} | real={n0} fake={n1}\")\n",
    "\n",
    "# ---------------- Dataset / DataLoader ----------------\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ELAFromNPY(Dataset):\n",
    "    \"\"\"ELA int8(u8-128) ‚Üí float32Ôºõ(i8+128)/255 ‚àà [0,1]ÔºåÂèØÈÅ∏ zero-meanÔºõRAM/memmap Âø´Âèñ„ÄÇ\"\"\"\n",
    "    def __init__(self, pairs, id2path, augment=False, cache_mode=\"ram\"):\n",
    "        self.pairs = pairs\n",
    "        self.id2p  = id2path\n",
    "        self.augment = augment\n",
    "        self.cache_mode = cache_mode\n",
    "        self.cache = []\n",
    "        if cache_mode == \"ram\":\n",
    "            self.cache = [None]*len(pairs)\n",
    "            for i, (idx, lab) in enumerate(pairs):\n",
    "                d = \"real\" if lab==0 else \"fake\"\n",
    "                p = self.id2p[d][idx]\n",
    "                self.cache[i] = np.load(p, allow_pickle=False).copy()  # int8\n",
    "\n",
    "    def __len__(self): return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx, lab = self.pairs[i]\n",
    "        if self.cache_mode == \"ram\":\n",
    "            arr = self.cache[i]\n",
    "        else:\n",
    "            d = \"real\" if lab==0 else \"fake\"\n",
    "            p = self.id2p[d][idx]\n",
    "            arr = np.load(p, allow_pickle=False, mmap_mode='r' if self.cache_mode==\"memmap\" else None)\n",
    "\n",
    "        x = (arr.astype(np.float32) + 128.0) / 255.0\n",
    "        if ELA_ZERO_MEAN:\n",
    "            x = x - x.mean()\n",
    "        x = np.clip(x, -2.0, 2.0)\n",
    "        x = x[None, ...]  # [1,H,W]\n",
    "        return torch.from_numpy(x), torch.tensor(lab, dtype=torch.long)\n",
    "\n",
    "def make_loader(pairs, train=False):\n",
    "    ds = ELAFromNPY(pairs, id2path, augment=train, cache_mode=CACHE_MODE)\n",
    "    return DataLoader(\n",
    "        ds, batch_size=BATCH, shuffle=train,\n",
    "        num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY,\n",
    "        prefetch_factor=PREFETCH_FACTOR, persistent_workers=PERSISTENT,\n",
    "        drop_last=train\n",
    "    )\n",
    "\n",
    "train_loader = make_loader(splits[\"train\"], train=True)\n",
    "val_loader   = make_loader(splits[\"val\"],   train=False)\n",
    "test_loader  = make_loader(splits[\"test\"],  train=False)\n",
    "\n",
    "# ---------------- Ê®°ÂûãÔºöDepthwise-Separable CNNÔºàÂø´Ôºâ ----------------\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DSBlock(nn.Module):\n",
    "    def __init__(self, c_in, c_out, stride=1):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv2d(c_in, c_in, 3, stride=stride, padding=1, groups=c_in, bias=False)\n",
    "        self.bn1= nn.BatchNorm2d(c_in)\n",
    "        self.pw = nn.Conv2d(c_in, c_out, 1, bias=False)\n",
    "        self.bn2= nn.BatchNorm2d(c_out)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.bn1(self.dw(x)))\n",
    "        x = self.act(self.bn2(self.pw(x)))\n",
    "        return x\n",
    "\n",
    "class ELAFastCNN(nn.Module):\n",
    "    def __init__(self, nc=1, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(nc, 32, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32), nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.stage = nn.Sequential(\n",
    "            DSBlock(32, 64,  stride=1),   # H\n",
    "            DSBlock(64, 128, stride=2),   # H/2\n",
    "            DSBlock(128,128, stride=1),   # H/2\n",
    "            DSBlock(128,256, stride=2),   # H/4\n",
    "            DSBlock(256,256, stride=1),   # H/4\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, 1, bias=False),\n",
    "            nn.BatchNorm2d(256), nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc   = nn.Linear(256, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x); x = self.stage(x); x = self.head(x)\n",
    "        x = self.pool(x).squeeze(-1).squeeze(-1)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# ---------------- Ë®ìÁ∑¥ & Ë©ï‰º∞ ----------------\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "def set_seed(seed=SEED):\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    ys, logits = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device, non_blocking=True).contiguous(memory_format=torch.channels_last)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "            out = model(x)\n",
    "            logits.append(out.detach().cpu().numpy())\n",
    "            ys.append(y.detach().cpu().numpy())\n",
    "    logits = np.concatenate(logits, 0)\n",
    "    y_true = np.concatenate(ys, 0)\n",
    "    y_pred = logits.argmax(1)\n",
    "    acc = (y_pred == y_true).mean()\n",
    "    prob1 = torch.softmax(torch.from_numpy(logits), dim=1).numpy()[:,1]\n",
    "    auc = roc_auc_score(y_true, prob1)\n",
    "    return acc, auc, y_true, y_pred, prob1\n",
    "\n",
    "import torch\n",
    "def train_ela_fastcnn():\n",
    "    set_seed(SEED)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    model  = ELAFastCNN().to(device)\n",
    "    model  = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "    AMP_DTYPE = torch.bfloat16 if (torch.cuda.is_available() and torch.cuda.is_bf16_supported()) else torch.float16\n",
    "    USE_SCALER = (AMP_DTYPE == torch.float16)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=USE_SCALER)\n",
    "\n",
    "    # È°ûÂà•Ê¨äÈáç\n",
    "    n0 = sum(1 for _,y in splits[\"train\"] if y==0); n1 = len(splits[\"train\"])-n0\n",
    "    w = torch.tensor([1.0/n0, 1.0/n1], dtype=torch.float32, device=device); w = w/w.mean()\n",
    "\n",
    "    crit  = torch.nn.CrossEntropyLoss(weight=w)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max=EPOCHS)\n",
    "\n",
    "    best_auc, best_state, no_improve = -1.0, None, 0\n",
    "    for ep in range(1, EPOCHS+1):\n",
    "        model.train(); losses = []\n",
    "        pbar = tqdm(train_loader, desc=f\"train ep{ep}\", **TQDM_KW)\n",
    "        for x,y in pbar:\n",
    "            x = x.to(device, non_blocking=True).contiguous(memory_format=torch.channels_last)\n",
    "            y = y.to(device, non_blocking=True)\n",
    "            with torch.cuda.amp.autocast(dtype=AMP_DTYPE):\n",
    "                out  = model(x)\n",
    "                loss = crit(out, y)\n",
    "            optim.zero_grad(set_to_none=True)\n",
    "            if USE_SCALER:\n",
    "                scaler.scale(loss).backward(); scaler.step(optim); scaler.update()\n",
    "            else:\n",
    "                loss.backward(); optim.step()\n",
    "            losses.append(loss.item())\n",
    "            pbar.set_postfix(loss=f\"{np.mean(losses):.4f}\")\n",
    "        sched.step()\n",
    "\n",
    "        val_acc, val_auc, *_ = evaluate(model, val_loader, device)\n",
    "        print(f\"[EP {ep:02d}] train_loss={np.mean(losses):.4f} | val acc={val_acc:.4f} auc={val_auc:.4f}\")\n",
    "\n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            best_state = {\"model\": model.state_dict(),\n",
    "                          \"meta\": {\"arch\":\"ELAFastCNN\",\"seed\":SEED,\"epochs_done\":ep,\n",
    "                                   \"val_auc\":float(val_auc),\"val_acc\":float(val_acc),\n",
    "                                   \"input\":\"ELA int8‚Üí(i8+128)/255\"+(\"‚Üízero-mean\" if ELA_ZERO_MEAN else \"\"),\n",
    "                                   \"shape\":\"[1,H,W]\"}}\n",
    "            torch.save(best_state, BEST_PATH); print(\"  ‚Ü≥ saved best:\", BEST_PATH); no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= EARLY_STOP:\n",
    "                print(f\"‚èπ Early stop (no AUC improvement {EARLY_STOP} epochs).\"); break\n",
    "\n",
    "    if best_state is None and BEST_PATH.exists():\n",
    "        best_state = torch.load(BEST_PATH, map_location=\"cpu\")\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state[\"model\"])\n",
    "\n",
    "    test_acc, test_auc, y_true, y_pred, prob1 = evaluate(model, test_loader, device)\n",
    "    print(f\"[TEST] acc={test_acc:.4f} auc={test_auc:.4f}\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"real\",\"fake\"], digits=4))\n",
    "    return model\n",
    "\n",
    "model = train_ela_fastcnn()\n",
    "\n",
    "# ---- ÂñÆÂºµ .npy Êé®Ë´ñ ----\n",
    "def predict_ela_npy(npy_path: Path):\n",
    "    arr = np.load(npy_path, allow_pickle=False).astype(np.float32)\n",
    "    x = (arr + 128.0) / 255.0\n",
    "    if ELA_ZERO_MEAN: x = x - x.mean()\n",
    "    x = torch.from_numpy(x[None, None, ...])\n",
    "    device = next(model.parameters()).device\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast(dtype=torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float16):\n",
    "        logit = model(x.to(device).contiguous(memory_format=torch.channels_last))\n",
    "        prob  = torch.softmax(logit, dim=1)[0,1].item()\n",
    "        pred  = int(prob >= 0.5)  # 1=fake, 0=real\n",
    "    return pred, prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2682881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================ Export CLIP pooled(1024) per-split ‚Üí .npy (memmap) ================\n",
    "# ‰∏çÂÅöË®ìÁ∑¥ÔºåÂè™ÊääË≥áÊñôÊ∫ñÂÇôÂ•Ω„ÄÇÊîØÊè¥Ôºö\n",
    "#  - ÈáèÂåñ .npzÔºöÂÑ™ÂÖàËÆÄ 'pooled'ÔºõÊ≤íÊúâÂ∞±ÂãïÊÖãÈÇÑÂéüÂÜç pool\n",
    "#  - ÂéüÂßã .npyÔºöÂΩ¢ÁãÄ [257,1024] Êàñ [1024]\n",
    "# Áî¢Áâ©Ôºöexports/clip_pooled/<split>/{X.npy,y.npy,ids.txt,meta.json}\n",
    "\n",
    "from pathlib import Path\n",
    "import os, json, random, numpy as np\n",
    "\n",
    "# tqdmÔºàconsole ÁâàÔºåÈÅøÂÖç IProgressÔºâ\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except Exception:\n",
    "    def tqdm(x, **kw): return x\n",
    "\n",
    "# ---------------- ConfigÔºàÊîπÈÄôË£°Ôºâ ----------------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "SCRIPT_ROOT = Path(\"/home/yaya/ai-detect-proj/Script\")\n",
    "SPLIT_JSON  = SCRIPT_ROOT / \"splits/combined_split.json\"\n",
    "SPLIT_KEY   = \"iid\"          # \"iid\" / \"smoke_10p\" / \"ood_gen_strict.sd3\" ...\n",
    "EXPORT_ROOT = SCRIPT_ROOT / \"exports/clip_pooled\"  # Ëº∏Âá∫Ê†πÁõÆÈåÑ\n",
    "\n",
    "# ÁâπÂæµ‰æÜÊ∫êÔºàÂÖ©Á®ÆÈÉΩÊúÉÊéÉÔºå.npz ÂÑ™ÂÖàÔºâ\n",
    "CLIP_REAL_DIRS = [\n",
    "    SCRIPT_ROOT / \"features_256q/clip_real_q\",   # ÈáèÂåñ\n",
    "    SCRIPT_ROOT / \"features_256/clip_real_npy\",  # ÂéüÂßã\n",
    "]\n",
    "CLIP_FAKE_DIRS = [\n",
    "    SCRIPT_ROOT / \"features_256q/clip_fake_q\",\n",
    "    SCRIPT_ROOT / \"features_256/clip_fake_npy\",\n",
    "]\n",
    "\n",
    "SAVE_DTYPE   = \"float32\"   # Ëº∏Âá∫ÂêëÈáèÁ≤æÂ∫¶Ôºö'float32'ÔºàË®ìÁ∑¥ÂèãÂñÑÔºâÊàñ 'float16'ÔºàÊõ¥ÁúÅÁ©∫ÈñìÔºâ\n",
    "SMOKE_FRAC   = None        # Ëã•ÊÉ≥Âè™ÂÖàÂåØÂá∫ÈÉ®ÂàÜÔºà‰æãÂ¶Ç 0.1 ÁÇ∫ 10%ÔºâÔºåÈ†êË®≠ None=ÂÖ®Èáè\n",
    "\n",
    "# ---------------- ÊéÉÊ™î ‚Üí id‚ÜípathÔºà.npz ÂÑ™ÂÖàÔºâ ----------------\n",
    "def scan_first_hit(dirs, exts=(\".npz\",\".npy\")):\n",
    "    lut = {}\n",
    "    for d in dirs:\n",
    "        if not d.exists(): continue\n",
    "        for ext in exts:\n",
    "            for p in sorted(d.glob(f\"*.{ext.lstrip('.')}\")):\n",
    "                k = p.stem\n",
    "                if k not in lut:\n",
    "                    lut[k] = p\n",
    "    return lut\n",
    "\n",
    "id2path = {\"real\": scan_first_hit(CLIP_REAL_DIRS),\n",
    "           \"fake\": scan_first_hit(CLIP_FAKE_DIRS)}\n",
    "assert id2path[\"real\"] and id2path[\"fake\"], \"‚ùå Êâæ‰∏çÂà∞ CLIP Ê™îÊ°àÔºåË´ãÊ™¢Êü•Ë∑ØÂæë\"\n",
    "\n",
    "# ---------------- ËÆÄ unified splitÔºàÊîØÊè¥ dot-pathÔºâ ----------------\n",
    "def load_split_ids(json_path: Path, split_key: str):\n",
    "    data = json.loads(json_path.read_text())\n",
    "    node = data\n",
    "    if \"ids\" in node and split_key in (None,\"\",\"ids\"):\n",
    "        node = node[\"ids\"]\n",
    "    else:\n",
    "        for k in split_key.split(\".\"):\n",
    "            node = node[k]\n",
    "    assert all(k in node for k in (\"train\",\"val\",\"test\"))\n",
    "    return node[\"train\"], node[\"val\"], node[\"test\"]\n",
    "\n",
    "def attach(ids):\n",
    "    pairs, miss = [], 0\n",
    "    for i in ids:\n",
    "        if i in id2path[\"real\"]: pairs.append((i,0))\n",
    "        elif i in id2path[\"fake\"]: pairs.append((i,1))\n",
    "        else: miss += 1\n",
    "    if miss: print(f\"‚ö†Ô∏è split Êúâ {miss} ÂÄã id Âú®Á£ÅÁ¢üÊâæ‰∏çÂà∞ÔºåÂ∑≤ÂøΩÁï•„ÄÇ\")\n",
    "    return pairs\n",
    "\n",
    "def stratified_frac(pairs, frac, seed=SEED):\n",
    "    if not frac or frac>=1: return pairs\n",
    "    r = [(i,y) for (i,y) in pairs if y==0]\n",
    "    f = [(i,y) for (i,y) in pairs if y==1]\n",
    "    rnd = random.Random(seed); rnd.shuffle(r); rnd.shuffle(f)\n",
    "    return r[:max(1,int(len(r)*frac))] + f[:max(1,int(len(f)*frac))]\n",
    "\n",
    "tr_ids, va_ids, te_ids = load_split_ids(SPLIT_JSON, SPLIT_KEY)\n",
    "train_pairs, val_pairs, test_pairs = attach(tr_ids), attach(va_ids), attach(te_ids)\n",
    "if SMOKE_FRAC:\n",
    "    train_pairs = stratified_frac(train_pairs, SMOKE_FRAC, SEED)\n",
    "    val_pairs   = stratified_frac(val_pairs,   SMOKE_FRAC, SEED+1)\n",
    "    test_pairs  = stratified_frac(test_pairs,  SMOKE_FRAC, SEED+2)\n",
    "\n",
    "for name, pairs in [(\"train\",train_pairs),(\"val\",val_pairs),(\"test\",test_pairs)]:\n",
    "    n0 = sum(1 for _,y in pairs if y==0); n1 = len(pairs)-n0\n",
    "    print(f\"{name}: total={len(pairs)} | real={n0} fake={n1}\")\n",
    "\n",
    "# ---------------- ÈáèÂåñ .npz ‚Üí ÈÇÑÂéüÔºàÂ¶ÇÈúÄÔºâ + pooling(mean_excl_cls) ----------------\n",
    "def _unpack_int4(packed, orig_size):\n",
    "    u = np.empty(orig_size + (orig_size % 2), dtype=np.uint8)\n",
    "    u[0::2] = packed & 0x0F\n",
    "    u[1::2] = (packed >> 4) & 0x0F\n",
    "    u = u[:orig_size]\n",
    "    return (u.astype(np.int16) - 8).astype(np.int8)\n",
    "\n",
    "def dequantize_npz(npz_path: Path):\n",
    "    z = np.load(npz_path, allow_pickle=False)\n",
    "    meta = json.loads(str(z[\"meta\"][()]))\n",
    "    mode = meta[\"mode\"]; shape = tuple(meta[\"shape\"])\n",
    "    if mode == \"fp16\":\n",
    "        return z[\"q\"].astype(np.float32).reshape(shape)\n",
    "    if \"int8\" in mode:\n",
    "        q = z[\"q\"].astype(np.int8)\n",
    "        if mode == \"int8_tensor\":\n",
    "            S = float(z[\"scales\"][0]); return (q.astype(np.float32)*S).reshape(shape)\n",
    "        if mode == \"int8_row\":\n",
    "            if len(shape)==1:\n",
    "                S = float(z[\"scales\"][0]); return (q.astype(np.float32)*S).reshape(shape)\n",
    "            T,D = shape; S = z[\"scales\"].astype(np.float32)\n",
    "            out = np.empty((T,D), np.float32)\n",
    "            for t in range(T): out[t] = q[t].astype(np.float32)*S[t]\n",
    "            return out\n",
    "        if mode == \"int8_block32\":\n",
    "            B = int(meta[\"block\"])\n",
    "            if len(shape)==1:\n",
    "                D = shape[0]; S = z[\"scales\"].astype(np.float32); out = np.empty((D,), np.float32)\n",
    "                nB = (D+B-1)//B\n",
    "                for b in range(nB):\n",
    "                    s = slice(b*B, min((b+1)*B,D)); out[s] = q[s].astype(np.float32)*S[b]\n",
    "                return out\n",
    "            else:\n",
    "                T,D = shape; S = z[\"scales\"].astype(np.float32); out = np.empty((T,D), np.float32)\n",
    "                nB = (D+B-1)//B\n",
    "                for t in range(T):\n",
    "                    for b in range(nB):\n",
    "                        s = slice(b*B, min((b+1)*B,D)); out[t,s] = q[t,s].astype(np.float32)*S[t,b]\n",
    "                return out\n",
    "    if \"int4\" in mode:\n",
    "        packed = z[\"q\"].astype(np.uint8); B = int(meta[\"block\"])\n",
    "        if len(shape)==1:\n",
    "            D = shape[0]; S = z[\"scales\"].astype(np.float32)\n",
    "            q = _unpack_int4(packed, D); out = np.empty((D,), np.float32)\n",
    "            nB = (D+B-1)//B\n",
    "            for b in range(nB):\n",
    "                s = slice(b*B, min((b+1)*B,D)); out[s] = q[s].astype(np.float32)*S[b]\n",
    "            return out\n",
    "        else:\n",
    "            T,D = shape; S = z[\"scales\"].astype(np.float32)\n",
    "            q = _unpack_int4(packed, T*D).reshape(T,D); out = np.empty((T,D), np.float32)\n",
    "            nB = (D+B-1)//B\n",
    "            for t in range(T):\n",
    "                for b in range(nB):\n",
    "                    s = slice(b*B, min((b+1)*B,D)); out[t,s] = q[t,s].astype(np.float32)*S[t,b]\n",
    "            return out\n",
    "    raise ValueError(f\"Unknown quant mode: {mode}\")\n",
    "\n",
    "def pooled_vec_from_file(p: Path):\n",
    "    if p.suffix == \".npz\":\n",
    "        z = np.load(p, allow_pickle=False)\n",
    "        if \"pooled\" in z and z[\"pooled\"].size > 0:   # Áõ¥Êé•Áî®È†êÂ≠ò pooledÔºàÂø´Ôºâ\n",
    "            v = z[\"pooled\"].astype(np.float32)\n",
    "        else:\n",
    "            X = dequantize_npz(p)                    # [T,D] Êàñ [D]\n",
    "            v = X if X.ndim==1 else X[1:].mean(axis=0)   # mean_excl_cls\n",
    "    else:\n",
    "        arr = np.load(p, allow_pickle=False)\n",
    "        v = arr.astype(np.float32) if arr.ndim==1 else arr[1:].astype(np.float32).mean(axis=0)\n",
    "    # L2 normalize\n",
    "    n = np.linalg.norm(v) + 1e-12\n",
    "    return (v / n).astype(np.float32)\n",
    "\n",
    "# ---------------- Ëº∏Âá∫Â∑•ÂÖ∑Ôºö.npyÔºàopen_memmapÔºåÈÇäÂØ´ÈÇäËêΩÁõ§Ôºâ ----------------\n",
    "def export_split(name, pairs):\n",
    "    if not pairs:\n",
    "        print(f\"{name}: ÁÑ°Ë≥áÊñôÔºåÁï•ÈÅé\"); return\n",
    "    out_dir = EXPORT_ROOT / SPLIT_KEY / name\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # ÂÖà peek ‰∏ÄÂÄãÂêëÈáèÊ±∫ÂÆö D\n",
    "    iid0, y0 = pairs[0]\n",
    "    p0 = id2path[\"real\" if y0==0 else \"fake\"][iid0]\n",
    "    v0 = pooled_vec_from_file(p0)\n",
    "    D = v0.shape[0]\n",
    "\n",
    "    # Âª∫Á´ã memmap .npy\n",
    "    from numpy.lib.format import open_memmap\n",
    "    X_path = out_dir / \"X.npy\"\n",
    "    X_mm   = open_memmap(X_path, mode=\"w+\", dtype=SAVE_DTYPE, shape=(len(pairs), D))\n",
    "    y_path = out_dir / \"y.npy\"\n",
    "    y_arr  = np.empty((len(pairs),), dtype=np.int32)\n",
    "\n",
    "    ids_txt = (out_dir / \"ids.txt\").open(\"w\")\n",
    "    print(f\"‚Üí Export {name}: N={len(pairs)} D={D} ‚Üí {X_path}\")\n",
    "\n",
    "    # Á¨¨ 0 Á≠Ü\n",
    "    X_mm[0] = v0.astype(SAVE_DTYPE, copy=False)\n",
    "    y_arr[0] = y0\n",
    "    ids_txt.write(f\"{iid0}\\t{y0}\\t{p0}\\n\")\n",
    "\n",
    "    # ÂÖ∂È§ò\n",
    "    for i,(iid,lab) in enumerate(tqdm(pairs[1:], total=len(pairs)-1, desc=f\"build {name}\")):\n",
    "        p = id2path[\"real\" if lab==0 else \"fake\"][iid]\n",
    "        v = pooled_vec_from_file(p)\n",
    "        X_mm[i+1] = v.astype(SAVE_DTYPE, copy=False)\n",
    "        y_arr[i+1] = lab\n",
    "        if i < 10:  # ÂâçÂπæÁ≠ÜÁïô‰∏ãË∑ØÂæëÊñπ‰æøÈô§ÈåØ\n",
    "            ids_txt.write(f\"{iid}\\t{lab}\\t{p}\\n\")\n",
    "\n",
    "    # ÂØ´Âá∫ y / meta\n",
    "    np.save(y_path, y_arr, allow_pickle=False)\n",
    "    meta = {\n",
    "        \"split_key\": SPLIT_KEY,\n",
    "        \"split\": name,\n",
    "        \"dtype\": SAVE_DTYPE,\n",
    "        \"N\": int(len(pairs)),\n",
    "        \"D\": int(D),\n",
    "        \"pool\": \"mean_excl_cls\",\n",
    "        \"l2norm\": True,\n",
    "        \"source_priority\": [str(d) for d in (CLIP_REAL_DIRS+CLIP_FAKE_DIRS)],\n",
    "    }\n",
    "    (out_dir / \"meta.json\").write_text(json.dumps(meta, ensure_ascii=False, indent=2))\n",
    "    ids_txt.close()\n",
    "\n",
    "    # Â∞èÁ∏ΩÁµê\n",
    "    szX = X_path.stat().st_size; szy = y_path.stat().st_size\n",
    "    def human(n): \n",
    "        u=[\"B\",\"KiB\",\"MiB\",\"GiB\",\"TiB\"]; i=0; f=float(n)\n",
    "        while f>=1024 and i<len(u)-1: f/=1024; i+=1\n",
    "        return f\"{f:.1f} {u[i]}\"\n",
    "    print(f\"{name} saved: X={human(szX)} y={human(szy)} ‚Üí {out_dir}\")\n",
    "\n",
    "# ---------------- RunÔºöÈÄê split ÂåØÂá∫ ----------------\n",
    "export_split(\"train\", train_pairs)\n",
    "export_split(\"val\",   val_pairs)\n",
    "export_split(\"test\",  test_pairs)\n",
    "\n",
    "print(\"‚úÖ Done. Exports at:\", EXPORT_ROOT / SPLIT_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009b7735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== Step 1 + 2: ÂéüÂßã CLIP Ê±†Âåñ ‚Üí per-fileÔºõ‰∏âÊ®°ÊÖã‰∫§ÈõÜ ‚Üí ÂÖ±Áî® splits =====================\n",
    "from pathlib import Path\n",
    "import json, random, time, re, numpy as np\n",
    "\n",
    "# ---- Âü∫Êú¨Ë®≠ÂÆöÔºàÊîπÈÄôË£°Ôºâ----\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "SCRIPT_ROOT = Path(\"/home/yaya/ai-detect-proj/Script\")\n",
    "FEA_ROOT    = SCRIPT_ROOT / \"features_256\"\n",
    "\n",
    "# 1) ÂéüÂßã CLIP token map ÁöÑ‰æÜÊ∫êÔºàÊØèÂúñ‰∏ÄÊ™î .npyÔºâ\n",
    "CLIP_RAW_REAL = FEA_ROOT / \"clip_real_npy\"\n",
    "CLIP_RAW_FAKE = FEA_ROOT / \"clip_fake_npy\"\n",
    "\n",
    "# 1) Ê±†ÂåñÂæåË¶ÅÂ≠òÂà∞Âì™ÔºàÊØèÂúñ‰∏ÄÊ™î .npyÔºåfloat32 1024 Á∂≠Ôºâ\n",
    "CLIP_POOL_REAL = FEA_ROOT / \"clip_pooled_real_npy\"\n",
    "CLIP_POOL_FAKE = FEA_ROOT / \"clip_pooled_fake_npy\"\n",
    "\n",
    "# PRNU/ELA ‰æÜÊ∫êÔºàÊØèÂúñ‰∏ÄÊ™î .npyÔºâ\n",
    "PRNU_REAL = FEA_ROOT / \"prnu_real_npy\"\n",
    "PRNU_FAKE = FEA_ROOT / \"prnu_fake_npy\"\n",
    "ELA_REAL  = FEA_ROOT / \"ela_real_npy\"\n",
    "ELA_FAKE  = FEA_ROOT / \"ela_fake_npy\"\n",
    "\n",
    "# 2) Split Â≠òÊîæ‰ΩçÁΩÆËàáÂêçÁ®±\n",
    "SPLIT_OUT   = SCRIPT_ROOT / \"splits\" / \"combined_split.json\"\n",
    "SMOKE_FRAC  = 0.10           # 10% smoke\n",
    "IID_RATIO   = (0.8, 0.1, 0.1)  # train/val/test\n",
    "\n",
    "# Ë¶ÅÂÅö OOD ÁöÑÂÅáÂúñÁîüÊàêÂô®‰ª£ËôüÔºàÂæûÊ™îÂêç stem ÁöÑÂâçÁ∂¥Êé®Êñ∑Ôºâ\n",
    "GEN_CANON = {\n",
    "    \"sd3\": [\"sd3\"],\n",
    "    \"midjourney\": [\"midjourney\", \"midjourney-v6\", \"midjourney-v6-llava\", \"mj\"],\n",
    "    \"flux\": [\"flux\", \"black-forest-labs\", \"flux-dev\", \"flux-1\"],\n",
    "    \"dalle3\": [\"dalle3\", \"dall-e-3\", \"dalle-3\"]\n",
    "}\n",
    "\n",
    "# ===================== Â∑•ÂÖ∑ =====================\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except Exception:\n",
    "    def tqdm(x, **kw): return x\n",
    "\n",
    "def ensure_dir(d: Path):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def list_files(d: Path, ext=\".npy\"):\n",
    "    return sorted([p for p in d.glob(f\"*{ext}\")])\n",
    "\n",
    "def stem_set(d: Path, ext=\".npy\"):\n",
    "    return set(p.stem for p in d.glob(f\"*{ext}\"))\n",
    "\n",
    "def pool_clip_file(npy_path: Path) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    ËºâÂÖ•ÂéüÂßã CLIP ÁâπÂæµÔºö\n",
    "      - Ëã• shape=(257,1024)ÔºöÊé° mean_excl_clsÔºàÊéíÈô§ CLSÔºâ‚Üí 1024\n",
    "      - Ëã• shape=(1024,)   ÔºöÁõ¥Êé•Ë¶ñÁÇ∫ pooled\n",
    "    ‰πãÂæåÂÅö L2 normalizeÔºåÂõûÂÇ≥ float32[1024]\n",
    "    \"\"\"\n",
    "    arr = np.load(npy_path, allow_pickle=False)\n",
    "    if arr.ndim == 2 and arr.shape[1] == 1024:\n",
    "        v = arr[1:].astype(np.float32).mean(axis=0)\n",
    "    elif arr.ndim == 1 and arr.shape[0] == 1024:\n",
    "        v = arr.astype(np.float32)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported CLIP shape {arr.shape} @ {npy_path.name}\")\n",
    "    n = np.linalg.norm(v) + 1e-12\n",
    "    return (v / n).astype(np.float32)\n",
    "\n",
    "def atomic_save(path: Path, arr: np.ndarray):\n",
    "    tmp = path.with_suffix(path.suffix + \".tmp\")\n",
    "    np.save(tmp, arr, allow_pickle=False)\n",
    "    tmp.replace(path)\n",
    "\n",
    "def pool_all_clip(src_dir: Path, dst_dir: Path, limit=None):\n",
    "    ensure_dir(dst_dir)\n",
    "    files = list_files(src_dir, \".npy\")\n",
    "    if limit: files = files[:limit]\n",
    "    n_ok, n_skip = 0, 0\n",
    "    for p in tqdm(files, desc=f\"pool {src_dir.name} ‚Üí {dst_dir.name}\"):\n",
    "        out = dst_dir / (p.stem + \".npy\")\n",
    "        if out.exists(): \n",
    "            n_skip += 1\n",
    "            continue\n",
    "        try:\n",
    "            v = pool_clip_file(p)\n",
    "            atomic_save(out, v)\n",
    "            n_ok += 1\n",
    "        except Exception as e:\n",
    "            print(f\"[pool] skip {p.name} | {e}\")\n",
    "    print(f\"‚Üí {dst_dir}: wrote={n_ok} skipped={n_skip}\")\n",
    "\n",
    "def guess_generator(img_id: str) -> str | None:\n",
    "    \"\"\"\n",
    "    ‰æùÊ™îÂêç stem ÁöÑÂâçÁ∂¥Ôºà__ ÂâçÈù¢ÁöÑ dataset ÂêçÔºâÊé®Êñ∑ÁîüÊàêÂô®Ôºö\n",
    "      e.g. 'sd3__xxxx', 'midjourney-v6-llava__xxxx', 'flux__xxxx', 'dalle3__xxxx'\n",
    "    ÂõûÂÇ≥ 'sd3'/'midjourney'/'flux'/'dalle3' Êàñ NoneÔºàÂÖ∂‰ªñÔºâ\n",
    "    \"\"\"\n",
    "    # ÂèñÁ¨¨‰∏ÄÊÆµÂâçÁ∂¥\n",
    "    prefix = img_id.split(\"__\", 1)[0].lower()\n",
    "    # ÁßªÈô§ÈùûÂ≠óÊØçÊï∏Â≠óËàá - _\n",
    "    prefix = re.sub(r\"[^a-z0-9\\-_]+\", \"\", prefix)\n",
    "    for canon, aliases in GEN_CANON.items():\n",
    "        for a in aliases:\n",
    "            if prefix.startswith(a):\n",
    "                return canon\n",
    "    return None\n",
    "\n",
    "def stratified_split(real_ids, fake_ids, ratios=(0.8,0.1,0.1), seed=SEED):\n",
    "    \"\"\"‰∏ç‰æùË≥¥ sklearn ÁöÑÂàÜÂ±§ÂàáÂàÜÔºåÂõûÂÇ≥ dict: {'train':[...], 'val':[...], 'test':[...]}\"\"\"\n",
    "    assert abs(sum(ratios)-1.0) < 1e-6 and len(ratios)==3\n",
    "    r = list(real_ids); f = list(fake_ids)\n",
    "    rnd = random.Random(seed)\n",
    "    rnd.shuffle(r); rnd.shuffle(f)\n",
    "    def cut(arr):\n",
    "        n = len(arr)\n",
    "        n_tr = int(round(n*ratios[0]))\n",
    "        n_va = int(round(n*ratios[1]))\n",
    "        n_te = n - n_tr - n_va\n",
    "        return arr[:n_tr], arr[n_tr:n_tr+n_va], arr[n_tr+n_va:]\n",
    "    r_tr, r_va, r_te = cut(r)\n",
    "    f_tr, f_va, f_te = cut(f)\n",
    "    return {\n",
    "        \"train\": r_tr + f_tr,\n",
    "        \"val\":   r_va + f_va,\n",
    "        \"test\":  r_te + f_te,\n",
    "    }\n",
    "\n",
    "def summary(name, ids_dict):\n",
    "    for sp in [\"train\",\"val\",\"test\"]:\n",
    "        ids = ids_dict[sp]\n",
    "        n0 = sum(1 for i in ids if \"__\" in i and not guess_generator(i))  # ‰º∞ real by no-gen? (ÂÉÖ‰æõÂèÉËÄÉ)\n",
    "    # ÁúüÊ≠£ summary ÊàëÂÄëÁî®Ë∑ØÂæëÂ≠òÂú®ÊÄßÂà§ÂÆö\n",
    "\n",
    "# ===================== Step 1ÔºöÂéüÂßã CLIP ‚Üí Ê±†Âåñ per-file =====================\n",
    "print(\"== Step 1: Pool original CLIP to per-file 1024 ==\")\n",
    "assert CLIP_RAW_REAL.exists() and CLIP_RAW_FAKE.exists(), \"Êâæ‰∏çÂà∞ÂéüÂßã CLIP .npy Ë≥áÊñôÂ§æ\"\n",
    "pool_all_clip(CLIP_RAW_REAL, CLIP_POOL_REAL)\n",
    "pool_all_clip(CLIP_RAW_FAKE, CLIP_POOL_FAKE)\n",
    "\n",
    "# ===================== Step 2Ôºö‰∏âÊ®°ÊÖãÂèñ‰∫§ÈõÜ ‚Üí Áî¢Âá∫ splits =====================\n",
    "print(\"\\n== Step 2: Build unified splits (IID / OOD / smoke_10p) with tri-modal intersection ==\")\n",
    "\n",
    "# ‰∫§ÈõÜÔºàÂøÖÈ†à‰∏âÊ®°ÊÖãÈÉΩÊúâÔºâ\n",
    "ids_real = stem_set(CLIP_POOL_REAL) & stem_set(PRNU_REAL) & stem_set(ELA_REAL)\n",
    "ids_fake = stem_set(CLIP_POOL_FAKE) & stem_set(PRNU_FAKE) & stem_set(ELA_FAKE)\n",
    "print(f\"‰∫§ÈõÜÊï∏Èáè ‚Üí real: {len(ids_real)} | fake: {len(ids_fake)}\")\n",
    "\n",
    "# --- IIDÔºö8/1/1 ÂàÜÂ±§ÂàáÂàÜ ---\n",
    "iid = stratified_split(sorted(ids_real), sorted(ids_fake), ratios=IID_RATIO, seed=SEED)\n",
    "\n",
    "def count_split(ids_dict, ids_real_all, ids_fake_all):\n",
    "    def lab(i):\n",
    "        return 0 if i in ids_real_all else 1\n",
    "    for sp in [\"train\",\"val\",\"test\"]:\n",
    "        ids = ids_dict[sp]\n",
    "        n0 = sum(1 for i in ids if i in ids_real_all)\n",
    "        n1 = len(ids) - n0\n",
    "        print(f\"[{sp}] total={len(ids)} | real={n0} fake={n1}\")\n",
    "\n",
    "print(\"== IID summary ==\")\n",
    "count_split(iid, ids_real, ids_fake)\n",
    "\n",
    "# --- OODÔºöÂ∞çÊØèÂÄãÁîüÊàêÂô® gÔºåtrain/val ‰∏çÂê´ gÔºåtest ÂÖ®ÈÉ® gÔºà+ real ÁöÑ testÔºâ ---\n",
    "# ÂÖàÊää fake ‰æùÁîüÊàêÂô®ÂàÜÊ°∂\n",
    "fake_by_gen = {}\n",
    "for i in ids_fake:\n",
    "    g = guess_generator(i) or \"other\"\n",
    "    fake_by_gen.setdefault(g, []).append(i)\n",
    "\n",
    "def ood_split_for(gen_key: str):\n",
    "    # real Ë∑ü IID ‰ΩøÁî®Âêå‰∏ÄÂÄãÂàáÂàÜÔºàÁ¢∫‰øùÂêÑÁâàÊú¨‰∏ÄËá¥Ôºâ\n",
    "    r_tr = [i for i in iid[\"train\"] if i in ids_real]\n",
    "    r_va = [i for i in iid[\"val\"]   if i in ids_real]\n",
    "    r_te = [i for i in iid[\"test\"]  if i in ids_real]\n",
    "    # ÂÅáÂúñÔºöÈùû gen_key ÁöÑ ‚Üí Êåâ IID ÁöÑÂàÜÊ≥ïÊîæ train/val/testÔºõgen_key ÁöÑ ‚Üí ÂÖ®ÈÉ®ÈÄ≤ test\n",
    "    allowed = set().union(*[set(v) for k,v in fake_by_gen.items() if k != gen_key])\n",
    "    holdout = set(fake_by_gen.get(gen_key, []))\n",
    "    f_tr = [i for i in iid[\"train\"] if i in allowed]\n",
    "    f_va = [i for i in iid[\"val\"]   if i in allowed]\n",
    "    f_te = [i for i in iid[\"test\"]  if i in allowed] + sorted(list(holdout))\n",
    "    return {\"train\": r_tr + f_tr, \"val\": r_va + f_va, \"test\": r_te}\n",
    "\n",
    "ood_gen = {}\n",
    "for g in [\"sd3\",\"midjourney\",\"flux\",\"dalle3\"]:\n",
    "    sp = ood_split_for(g)\n",
    "    ood_gen[g] = sp\n",
    "    # ÊëòË¶Å\n",
    "    ntr = (sum(i in ids_real for i in sp[\"train\"]), sum(i in ids_fake for i in sp[\"train\"]))\n",
    "    nva = (sum(i in ids_real for i in sp[\"val\"]),   sum(i in ids_fake for i in sp[\"val\"]))\n",
    "    nte = (sum(i in ids_real for i in sp[\"test\"]),  sum(i in ids_fake for i in sp[\"test\"]))\n",
    "    print(f\"== OOD-{g} summary ==\")\n",
    "    print(f\"[train] total={len(sp['train'])} | real={ntr[0]} fake={ntr[1]}\")\n",
    "    print(f\"[val]   total={len(sp['val'])}   | real={nva[0]} fake={nva[1]}\")\n",
    "    # È°ØÁ§∫ test Ë£° holdout g ÁöÑÊï∏Èáè\n",
    "    n_g_test = sum(1 for i in sp[\"test\"] if guess_generator(i)==g)\n",
    "    print(f\"[test]  total={len(sp['test'])}  | real={nte[0]} fake={nte[1]} (holdout {g} in test: {n_g_test})\")\n",
    "\n",
    "# --- smoke_10pÔºöÂæû IID ÂêÑ split ÂêÑËá™Âèñ 10%ÔºàÂàÜÂ±§Èö®Ê©üÔºâ ---\n",
    "def take_frac(ids_list, frac, seed):\n",
    "    rnd = random.Random(seed)\n",
    "    ids_r = [i for i in ids_list if i in ids_real]\n",
    "    ids_f = [i for i in ids_list if i in ids_fake]\n",
    "    rnd.shuffle(ids_r); rnd.shuffle(ids_f)\n",
    "    kr = max(1, int(round(len(ids_r)*frac))) if ids_r else 0\n",
    "    kf = max(1, int(round(len(ids_f)*frac))) if ids_f else 0\n",
    "    return ids_r[:kr] + ids_f[:kf]\n",
    "\n",
    "smoke_10p = {\n",
    "    \"train\": take_frac(iid[\"train\"], SMOKE_FRAC, SEED),\n",
    "    \"val\":   take_frac(iid[\"val\"],   SMOKE_FRAC, SEED+1),\n",
    "    \"test\":  take_frac(iid[\"test\"],  SMOKE_FRAC, SEED+2),\n",
    "}\n",
    "print(\"== smoke_10p summary ==\")\n",
    "count_split(smoke_10p, ids_real, ids_fake)\n",
    "\n",
    "# ===================== ÂØ´Âá∫ JSONÔºàÊúÉ‰øùÁïôËàäÊ™îÔºåÂÜçË¶ÜËìãÔºâ =====================\n",
    "out = {\n",
    "    \"meta\": {\n",
    "        \"seed\": SEED,\n",
    "        \"created_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"tri_sync_modalities\": [\"clip_pooled(1024)\", \"prnu\", \"ela\"],\n",
    "        \"paths\": {\n",
    "            \"clip_pooled_real\": str(CLIP_POOL_REAL),\n",
    "            \"clip_pooled_fake\": str(CLIP_POOL_FAKE),\n",
    "            \"prnu_real\": str(PRNU_REAL), \"prnu_fake\": str(PRNU_FAKE),\n",
    "            \"ela_real\":  str(ELA_REAL),  \"ela_fake\":  str(ELA_FAKE),\n",
    "        },\n",
    "        \"iid_ratio\": IID_RATIO,\n",
    "        \"generators\": list(GEN_CANON.keys()),\n",
    "        \"note\": \"IDs are image stems without extension; splits contain tri-modal intersection only.\"\n",
    "    },\n",
    "    \"iid\": iid,\n",
    "    \"ood_gen\": ood_gen,\n",
    "    \"smoke_10p\": smoke_10p\n",
    "}\n",
    "\n",
    "ensure_dir(SPLIT_OUT.parent)\n",
    "# ÂÇô‰ªΩËàäÊ™î\n",
    "if SPLIT_OUT.exists():\n",
    "    bk = SPLIT_OUT.with_suffix(f\".bak_{int(time.time())}.json\")\n",
    "    SPLIT_OUT.replace(bk)\n",
    "    print(\"‚Üª backup old split ‚Üí\", bk)\n",
    "SPLIT_OUT.write_text(json.dumps(out, ensure_ascii=False, indent=2))\n",
    "print(\"‚úÖ saved:\", SPLIT_OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d64e57ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[clip_pooled_real_npy] fixed=0 removed_tmp=0\n",
      "[clip_pooled_fake_npy] fixed=60106 removed_tmp=0\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# ÂÖ©ÂÄãË≥áÊñôÂ§æÈÉΩ‰øÆ\n",
    "DIRS = [\n",
    "    Path(\"/home/yaya/ai-detect-proj/Script/features_256/clip_pooled_real_npy\"),\n",
    "    Path(\"/home/yaya/ai-detect-proj/Script/features_256/clip_pooled_fake_npy\"),\n",
    "]\n",
    "\n",
    "for root in DIRS:\n",
    "    if not root.exists(): \n",
    "        print(\"skip (not found):\", root); \n",
    "        continue\n",
    "    n_fix = n_drop = 0\n",
    "    for tmpf in root.glob(\"*.npy.tmp.npy\"):\n",
    "        # ËÆäÂõû„ÄåÊ≠£Á¢∫Ê™îÂêç„ÄçÔºöÊää \".npy.tmp.npy\" ‚Üí \".npy\"\n",
    "        dst = tmpf.with_name(tmpf.name.replace(\".npy.tmp.npy\", \".npy\"))\n",
    "        if dst.exists():\n",
    "            # ÁõÆÊ®ôÂ∑≤Â≠òÂú®ÔºöÂà™ÊéâÈÄôÂÄãÂ§öÈ§òÁöÑ .tmp Ê™î\n",
    "            tmpf.unlink()\n",
    "            n_drop += 1\n",
    "        else:\n",
    "            os.replace(tmpf, dst)\n",
    "            n_fix += 1\n",
    "    print(f\"[{root.name}] fixed={n_fix} removed_tmp={n_drop}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3e87e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLUX__0000_00018124.npy (1024,)\n",
      "SD3__0000_00049062.npy (1024,)\n",
      "SD3__0000_00021448.npy (1024,)\n",
      "dalle3__008127.npy (1024,)\n",
      "SD3__0000_00047005.npy (1024,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, random\n",
    "check_dirs = [Path(\"/home/yaya/ai-detect-proj/Script/features_256/clip_pooled_fake_npy\")]\n",
    "for d in check_dirs:\n",
    "    files = list(d.glob(\"*.npy\"))\n",
    "    for p in random.sample(files, min(5, len(files))):\n",
    "        arr = np.load(p, allow_pickle=False)\n",
    "        print(p.name, arr.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgfeat (PyTorch)",
   "language": "python",
   "name": "imgfeat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
