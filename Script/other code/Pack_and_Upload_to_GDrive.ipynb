{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841ce943",
   "metadata": {},
   "source": [
    "# Pack & Upload (Split Tar+Zstd → Google Drive)\n",
    "\n",
    "這份 notebook 會：\n",
    "\n",
    "1. 安裝需要的套件（`zstandard`, `tqdm`, `pydrive2`）。\n",
    "2. 以「**tar 串流 + zstd**」壓縮大量檔案，並**自動分卷**（例：1.5GB/卷）。\n",
    "3. 產生 **SHA256SUMS** 與 **MANIFEST**（紀錄每一卷的大小與雜湊）。\n",
    "4. （可選）使用 **PyDrive2** 上傳到 **Google Drive** 指定資料夾。\n",
    "\n",
    "> 若你的系統啟用了 PEP 668（阻擋 pip 寫入系統 site-packages），\n",
    "> 下面的安裝步驟會自動使用 `--break-system-packages` 做 fallback。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb75ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 依賴安裝（自動處理 PEP 668 的限制） ===\n",
    "import sys, subprocess\n",
    "\n",
    "def safe_pip_install(pkgs):\n",
    "    try:\n",
    "        print(\"[pip] Installing:\", pkgs)\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *pkgs])\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"[pip] Normal install failed, retry with --break-system-packages ...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--break-system-packages\", *pkgs])\n",
    "\n",
    "safe_pip_install([\"zstandard\", \"tqdm\", \"pydrive2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b02262c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 核心工具（分卷 writer、打包、校驗、上傳） ===\n",
    "import os, sys, time, json, tarfile, hashlib, argparse\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import zstandard as zstd\n",
    "\n",
    "try:\n",
    "    from pydrive2.auth import GoogleAuth\n",
    "    from pydrive2.drive import GoogleDrive\n",
    "    _HAS_PYDRIVE2 = True\n",
    "except Exception:\n",
    "    _HAS_PYDRIVE2 = False\n",
    "\n",
    "def parse_size(s: str) -> int:\n",
    "    s = s.strip().upper()\n",
    "    if s.endswith(\"G\"):\n",
    "        return int(float(s[:-1]) * (1024**3))\n",
    "    if s.endswith(\"M\"):\n",
    "        return int(float(s[:-1]) * (1024**2))\n",
    "    if s.endswith(\"K\"):\n",
    "        return int(float(s[:-1]) * 1024)\n",
    "    return int(s)\n",
    "\n",
    "def human_bytes(n: int) -> str:\n",
    "    for unit in [\"B\",\"KiB\",\"MiB\",\"GiB\",\"TiB\"]:\n",
    "        if abs(n) < 1024.0:\n",
    "            return f\"{n:3.1f} {unit}\"\n",
    "        n /= 1024.0\n",
    "    return f\"{n:.1f} PiB\"\n",
    "\n",
    "class SplitWriter:\n",
    "    def __init__(self, base_path: Path, volume_size: int):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.volume_size = volume_size\n",
    "        self.part_idx = 0\n",
    "        self.cur_fp = None\n",
    "        self.cur_written = 0\n",
    "        self.sha256 = hashlib.sha256()\n",
    "        self.parts_info = []\n",
    "        self._open_next()\n",
    "\n",
    "    def _open_next(self):\n",
    "        if self.cur_fp:\n",
    "            self.cur_fp.flush(); self.cur_fp.close()\n",
    "            self.parts_info.append({\n",
    "                \"path\": str(self.cur_path),\n",
    "                \"size\": self.cur_written,\n",
    "                \"sha256\": self.sha256.hexdigest()\n",
    "            })\n",
    "        self.part_idx += 1\n",
    "        self.cur_path = Path(f\"{self.base_path}.part-{self.part_idx:04d}\")\n",
    "        self.cur_fp = open(self.cur_path, \"wb\")\n",
    "        self.cur_written = 0\n",
    "        self.sha256 = hashlib.sha256()\n",
    "\n",
    "    def write(self, data: bytes):\n",
    "        mv = memoryview(data)\n",
    "        offset = 0\n",
    "        remaining = len(mv)\n",
    "        while remaining > 0:\n",
    "            room = self.volume_size - self.cur_written\n",
    "            if room == 0:\n",
    "                self._open_next()\n",
    "                room = self.volume_size\n",
    "            chunk_len = remaining if remaining <= room else room\n",
    "            chunk = mv[offset:offset+chunk_len]\n",
    "            self.cur_fp.write(chunk)\n",
    "            self.sha256.update(chunk)\n",
    "            self.cur_written += chunk_len\n",
    "            offset += chunk_len\n",
    "            remaining -= chunk_len\n",
    "\n",
    "    def flush(self):\n",
    "        if self.cur_fp:\n",
    "            self.cur_fp.flush()\n",
    "\n",
    "    def close(self):\n",
    "        if self.cur_fp:\n",
    "            self.cur_fp.flush(); self.cur_fp.close()\n",
    "            self.parts_info.append({\n",
    "                \"path\": str(self.cur_path),\n",
    "                \"size\": self.cur_written,\n",
    "                \"sha256\": self.sha256.hexdigest()\n",
    "            })\n",
    "            self.cur_fp = None\n",
    "\n",
    "    def writable(self): return True\n",
    "\n",
    "def load_filelist(path: Path):\n",
    "    files = []\n",
    "    missing = 0\n",
    "    total_bytes = 0\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            p = line.strip()\n",
    "            if not p: continue\n",
    "            ap = Path(p).expanduser().resolve()\n",
    "            if ap.is_file():\n",
    "                files.append(ap)\n",
    "                try:\n",
    "                    total_bytes += ap.stat().st_size\n",
    "                except Exception:\n",
    "                    pass\n",
    "            else:\n",
    "                print(f\"[WARN] 檔案不存在，忽略：{p}\", file=sys.stderr)\n",
    "                missing += 1\n",
    "    return files, total_bytes, missing\n",
    "\n",
    "def common_base(files):\n",
    "    try:\n",
    "        return Path(os.path.commonpath([str(p) for p in files]))\n",
    "    except Exception:\n",
    "        prefix = os.path.commonprefix([str(p) for p in files])\n",
    "        return Path(prefix).resolve().parent\n",
    "\n",
    "def build_manifest(pack_name, out_dir: Path, filelist_path: Path,\n",
    "                   parts_info, total_src_files, total_src_bytes, volume_size):\n",
    "    ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    manifest = {\n",
    "        \"pack_name\": pack_name,\n",
    "        \"created_at\": ts,\n",
    "        \"filelist\": str(filelist_path),\n",
    "        \"out_dir\": str(out_dir),\n",
    "        \"volume_size\": volume_size,\n",
    "        \"total_source_files\": total_src_files,\n",
    "        \"total_source_bytes\": total_src_bytes,\n",
    "        \"parts\": parts_info,\n",
    "    }\n",
    "    return manifest\n",
    "\n",
    "def ensure_folder(drive, parent_id, name):\n",
    "    q = f'title=\"{name}\" and mimeType=\"application/vnd.google-apps.folder\" and trashed=false and \"{parent_id}\" in parents'\n",
    "    flist = drive.ListFile({'q': q}).GetList()\n",
    "    if flist:\n",
    "        return flist[0]['id']\n",
    "    folder = drive.CreateFile({\n",
    "        'title': name,\n",
    "        'mimeType': 'application/vnd.google-apps.folder',\n",
    "        'parents': [{'id': parent_id}]\n",
    "    })\n",
    "    folder.Upload()\n",
    "    return folder['id']\n",
    "\n",
    "def upload_files_to_drive(local_paths, drive_folder_path, client_secrets=\"client_secrets.json\"):\n",
    "    if not _HAS_PYDRIVE2:\n",
    "        raise RuntimeError(\"未安裝 PyDrive2，請先安裝 pydrive2 套件\")\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.LoadClientConfigFile(client_secrets)\n",
    "    gauth.LoadCredentialsFile(\"token.json\")\n",
    "    if gauth.credentials is None:\n",
    "        gauth.LocalWebserverAuth()\n",
    "    elif gauth.access_token_expired:\n",
    "        gauth.Refresh()\n",
    "    else:\n",
    "        gauth.Authorize()\n",
    "    gauth.SaveCredentialsFile(\"token.json\")\n",
    "\n",
    "    drive = GoogleDrive(gauth)\n",
    "    parent = 'root'\n",
    "    if drive_folder_path.strip():\n",
    "        for seg in drive_folder_path.strip(\"/\").split(\"/\"):\n",
    "            parent = ensure_folder(drive, parent, seg)\n",
    "\n",
    "    for p in local_paths:\n",
    "        f = drive.CreateFile({'title': Path(p).name, 'parents': [{'id': parent}]})\n",
    "        f.SetContentFile(p)\n",
    "        f.Upload()\n",
    "        print(f\"[GDrive] Uploaded: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f5ae31",
   "metadata": {},
   "source": [
    "## 參數設定\n",
    "\n",
    "- `FILELIST`: 每行一個**絕對路徑**檔案（建議用你的產生清單腳本）  \n",
    "- `PACK_NAME`: 分卷前綴名（不含副檔名）  \n",
    "- `VOLUME_SIZE`: 每卷大小，例：`\"1500M\"`、`\"2G\"`、`\"800M\"`  \n",
    "- `OUT_DIR`: 產物輸出目錄（預設在清單旁的 `packs/`）  \n",
    "- `UPLOAD`: 是否上傳到 Google Drive  \n",
    "- `DRIVE_FOLDER`: Drive 目的資料夾（於 **我的雲端硬碟** 下的路徑）  \n",
    "- `CLIENT_SECRETS`: Google OAuth `client_secrets.json` 路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e342086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 修改這裡 ===\n",
    "FILELIST = \"/home/yaya/ai-detect-proj/Script/upload_lists/filelist_prnu.txt\"\n",
    "PACK_NAME = \"pack_prnu256\"\n",
    "VOLUME_SIZE = \"1500M\"                 # \"1500M\" / \"2G\" / \"800M\" ...\n",
    "OUT_DIR = None                        # None -> 產物放在 filelist 同層的 packs/\n",
    "UPLOAD = False                        # True -> 上傳到 Google Drive\n",
    "DRIVE_FOLDER = \"ai-detect-proj/features\"\n",
    "CLIENT_SECRETS = \"./client_secrets.json\"  # 放 notebook 同目錄或填絕對路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b74414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 執行打包（tar+zstd 串流→自動分卷） ===\n",
    "from pathlib import Path\n",
    "\n",
    "filelist_path = Path(FILELIST).expanduser().resolve()\n",
    "if OUT_DIR:\n",
    "    out_dir = Path(OUT_DIR).expanduser().resolve()\n",
    "else:\n",
    "    out_dir = filelist_path.parent / \"packs\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "vol_bytes = parse_size(VOLUME_SIZE)\n",
    "pack_base = out_dir / PACK_NAME\n",
    "part_prefix = f\"{pack_base}.tar.zst\"\n",
    "\n",
    "files, total_src_bytes, missing = load_filelist(filelist_path)\n",
    "if not files:\n",
    "    raise SystemExit(\"清單中沒有可用檔案\")\n",
    "\n",
    "print(f\"== 準備打包 ==\")\n",
    "print(f\"  檔案清單：{filelist_path}\")\n",
    "print(f\"  輸出前綴：{part_prefix}.part-0001 ...\")\n",
    "print(f\"  分卷大小：{VOLUME_SIZE} ({vol_bytes} bytes)\")\n",
    "print(f\"  檔案數量：{len(files)}（忽略缺檔 {missing}）\")\n",
    "print(f\"  原檔總量：{human_bytes(total_src_bytes)}\")\n",
    "print(f\"  輸出目錄：{out_dir}\")\n",
    "\n",
    "base_dir = common_base(files)\n",
    "print(f\"  Tar 相對根：{base_dir}\")\n",
    "\n",
    "splitter = SplitWriter(Path(part_prefix), vol_bytes)\n",
    "zc = zstd.ZstdCompressor(level=6, threads=-1)\n",
    "with zc.stream_writer(splitter) as zfh:\n",
    "    with tarfile.open(mode=\"w|\", fileobj=zfh, format=tarfile.GNU_FORMAT) as tar:\n",
    "        pbar = tqdm(total=len(files), desc=\"Packing\", unit=\"file\")\n",
    "        for src in files:\n",
    "            try:\n",
    "                arcname = os.path.relpath(src, base_dir)\n",
    "            except Exception:\n",
    "                arcname = Path(src).name\n",
    "            tar.add(src, arcname=arcname, recursive=False)\n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "\n",
    "splitter.close()\n",
    "parts_info = splitter.parts_info\n",
    "\n",
    "ts = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "manifest_path = out_dir / f\"{PACK_NAME}_MANIFEST_{ts}.json\"\n",
    "sums_path = out_dir / f\"{PACK_NAME}_SHA256SUMS_{ts}.txt\"\n",
    "\n",
    "manifest = build_manifest(PACK_NAME, out_dir, filelist_path,\n",
    "                          parts_info, len(files), total_src_bytes, VOLUME_SIZE)\n",
    "\n",
    "with open(manifest_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(manifest, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(sums_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for pi in parts_info:\n",
    "        f.write(f\"{pi['sha256']}  {os.path.basename(pi['path'])}\\n\")\n",
    "\n",
    "print(\"\\n== 產物 ==\")\n",
    "tot_packed = sum(p[\"size\"] for p in parts_info)\n",
    "for pi in parts_info[:10]:\n",
    "    print(f\"  {os.path.basename(pi['path'])}  {human_bytes(pi['size'])}  sha256={pi['sha256'][:12]}...\")\n",
    "if len(parts_info) > 10:\n",
    "    print(f\"  ...（共 {len(parts_info)} 卷）\")\n",
    "print(f\"  合計串流大小：{human_bytes(tot_packed)}\")\n",
    "print(f\"  MANIFEST：{manifest_path.name}\")\n",
    "print(f\"  SHA256SUMS：{sums_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05292f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === （可選）上傳到 Google Drive ===\n",
    "if UPLOAD:\n",
    "    if not _HAS_PYDRIVE2:\n",
    "        raise RuntimeError(\"未安裝 pydrive2，請先在上面安裝後再重跑。\")\n",
    "    to_upload = [pi[\"path\"] for pi in parts_info] + [str(manifest_path), str(sums_path)]\n",
    "    print(f\"== 上傳至 Google Drive: {DRIVE_FOLDER} ==\")\n",
    "    upload_files_to_drive(to_upload, DRIVE_FOLDER, client_secrets=CLIENT_SECRETS)\n",
    "    print(\"✅ 上傳完成\")\n",
    "else:\n",
    "    print(\"（UPLOAD=False，略過上傳）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f601c7",
   "metadata": {},
   "source": [
    "## 在 Colab / 另一台機器還原分卷\n",
    "\n",
    "把分卷檔下載到同一個資料夾後：\n",
    "\n",
    "```bash\n",
    "cat PACK_NAME.tar.zst.part-* > PACK_NAME.tar.zst\n",
    "tar -I zstd -xf PACK_NAME.tar.zst -C <輸出資料夾>\n",
    "```\n",
    "\n",
    "或在 Colab：\n",
    "\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "!mkdir -p /content/packs\n",
    "!cp /content/drive/MyDrive/ai-detect-proj/features/PACK_NAME.tar.zst.part-* /content/packs/\n",
    "\n",
    "!cat /content/packs/PACK_NAME.tar.zst.part-* > /content/PACK_NAME.tar.zst\n",
    "!tar -I zstd -xf /content/PACK_NAME.tar.zst -C /content/output\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgfeat (PyTorch)",
   "language": "python",
   "name": "imgfeat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
