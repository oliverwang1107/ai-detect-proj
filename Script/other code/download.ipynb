{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd148f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DownloadConfig\n",
    "import os, shutil, random, io\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d920db7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2667755865.py, line 45)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(f\"✅ 下載完成，共 {done+saved}/{TARGET} 張位於 {DEST}\"# ╔═╗  Download lehduong/flux_generated  ═══════════════════════════════╗\u001b[39m\n                                                                                                                               ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# download_20k.py  ── 抓 20 000 張 ImageNet，已存在就跳過\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pathlib, os, io, random, hashlib\n",
    "\n",
    "DATASET = \"jovianzm/Pexels-400k\"\n",
    "SPLIT   = \"train\"\n",
    "TARGET  = 50_000                       # 最終要湊滿的張數\n",
    "DEST    = pathlib.Path(\"data/raw/pexels\")\n",
    "DEST.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ① 先統計已經有多少張\n",
    "exist = {p.name for p in DEST.glob(\"*.jpg\")}\n",
    "done  = len(exist)\n",
    "print(f\"已存在 {done} 張，目標 {TARGET}\")\n",
    "\n",
    "if done >= TARGET:\n",
    "    print(\"✓ 目標已滿，無需下載\"); exit()\n",
    "\n",
    "# ② streaming + shuffle\n",
    "ds = load_dataset(DATASET, split=SPLIT, streaming=True)\n",
    "stream = ds.shuffle(seed=42, buffer_size=20_000)\n",
    "\n",
    "# ③ 邊串流邊存檔，檔名重複就 continue\n",
    "saved = 0\n",
    "for ex in tqdm(stream, unit=\"img\"):\n",
    "    if done + saved >= TARGET:\n",
    "        break\n",
    "\n",
    "    img = ex[\"image\"]\n",
    "    if isinstance(img, bytes):\n",
    "        img = Image.open(io.BytesIO(img))\n",
    "    img = img.convert(\"RGB\")\n",
    "\n",
    "    # 檔名：<label>_<序號>.jpg ；重複檢查只看檔名（速度最快）\n",
    "    fname = f\"{ex['label']:04d}_{done+saved:08d}.jpg\"\n",
    "    if fname in exist:\n",
    "        continue\n",
    "\n",
    "    img.save(DEST / fname, quality=95)\n",
    "    exist.add(fname)\n",
    "    saved += 1\n",
    "\n",
    "print(f\"✅ 下載完成，共 {done+saved}/{TARGET} 張位於 {DEST}\"# ╔═╗  Download lehduong/flux_generated  ═══════════════════════════════╗\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f05a6af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yaya/miniforge3/envs/imgfeat/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已有 0 張，開始補到 50000…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0img [00:03, ?img/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# 讀到 PIL.Image\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m img = \u001b[43mex\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m     48\u001b[39m     img = Image.open(io.BytesIO(img))\n",
      "\u001b[31mKeyError\u001b[39m: 'image'"
     ]
    }
   ],
   "source": [
    "# 參數：自行修改\n",
    "DATASET   = \"jovianzm/Pexels-400k\"   # HF 資料集名稱\n",
    "SPLIT     = \"train\"                     # 試過若無 train 可改 \"default\"\n",
    "TARGET    = 50_000                      # 想要抓的總張數\n",
    "DEST      = \"data/raw/fake/pexels\"\n",
    "BUFFER    = 12_000                      # shuffle 緩衝\n",
    "SEED      = 42\n",
    "USE_HASH  = False                       # 遇到相同檔名就跳過；True ➜ 用 SHA-1 去重\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "import pathlib, os, io, hashlib, warnings\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"PIL.\")\n",
    "\n",
    "dest = pathlib.Path(DEST)\n",
    "dest.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1️⃣ 先統計已存檔\n",
    "exist = {p.name for p in dest.glob(\"*.jpg\")}\n",
    "done  = len(exist)\n",
    "if done >= TARGET:\n",
    "    print(f\"✓ 目前 {done}/{TARGET}，已達標\") ; raise SystemExit\n",
    "\n",
    "print(f\"已有 {done} 張，開始補到 {TARGET}…\")\n",
    "\n",
    "# 2️⃣ 取得 streaming Dataset\n",
    "ds = load_dataset(DATASET, split=SPLIT, streaming=True)\n",
    "stream = ds.shuffle(seed=SEED, buffer_size=BUFFER)\n",
    "\n",
    "def make_key(img, label, idx):\n",
    "    if USE_HASH:\n",
    "        h = hashlib.sha1(img.tobytes()).hexdigest()\n",
    "        return f\"{h}.jpg\"\n",
    "    else:\n",
    "        return f\"{label:04d}_{idx:08d}.jpg\"\n",
    "\n",
    "saved = 0\n",
    "for ex in tqdm(stream, unit=\"img\"):\n",
    "    if done + saved >= TARGET:\n",
    "        break\n",
    "\n",
    "    # 讀到 PIL.Image\n",
    "    img = ex[\"image\"]\n",
    "    if isinstance(img, bytes):\n",
    "        img = Image.open(io.BytesIO(img))\n",
    "    img = img.convert(\"RGB\")\n",
    "\n",
    "    key = make_key(img, ex.get(\"label\", 0), done + saved)\n",
    "    if key in exist:\n",
    "        continue\n",
    "\n",
    "    img.save(dest / key, quality=95)\n",
    "    exist.add(key)\n",
    "    saved += 1\n",
    "\n",
    "print(f\"✅ 新增 {saved} 張，總計 {len(exist)}/{TARGET}\")\n",
    "# ╚════════════════════════════════════════════════════════════════════╝\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b73fe33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已有 0 張，目標 50000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7c574fc67e489697ca195c024a16c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2334927da4364781b130234da11b0981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90416fc065df42ab9eefcafe8d30272e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?img/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (hashlib.sha1(img.tobytes()).hexdigest() \u001b[38;5;28;01mif\u001b[39;00m USE_HASH\n\u001b[32m     32\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m04d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m08d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[33m.jpg\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     34\u001b[39m saved = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTARGET\u001b[49m\u001b[43m-\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mTARGET\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/tqdm/notebook.py:250\u001b[39m, in \u001b[36mtqdm_notebook.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    249\u001b[39m     it = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__iter__\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/datasets/iterable_dataset.py:2361\u001b[39m, in \u001b[36mIterableDataset.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2358\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m formatter.format_row(pa_table)\n\u001b[32m   2359\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2361\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mex_iterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2362\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# no need to format thanks to FormattedExamplesIterable\u001b[39;49;00m\n\u001b[32m   2363\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/datasets/iterable_dataset.py:1882\u001b[39m, in \u001b[36mFormattedExamplesIterable.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1875\u001b[39m     formatter = get_formatter(\n\u001b[32m   1876\u001b[39m         \u001b[38;5;28mself\u001b[39m.formatting.format_type,\n\u001b[32m   1877\u001b[39m         features=\u001b[38;5;28mself\u001b[39m._features \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ex_iterable.is_typed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1878\u001b[39m         token_per_repo_id=\u001b[38;5;28mself\u001b[39m.token_per_repo_id,\n\u001b[32m   1879\u001b[39m     )\n\u001b[32m   1880\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ex_iterable.iter_arrow:\n\u001b[32m   1881\u001b[39m     \u001b[38;5;66;03m# feature casting (inc column addition) handled within self._iter_arrow()\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1882\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_arrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_batch_to_examples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/datasets/iterable_dataset.py:1905\u001b[39m, in \u001b[36mFormattedExamplesIterable._iter_arrow\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1903\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.features:\n\u001b[32m   1904\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ex_iterable._iter_arrow()\n\u001b[32m-> \u001b[39m\u001b[32m1905\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mex_iterable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_iter_arrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumn_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1907\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43marrow_schema\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/datasets/iterable_dataset.py:499\u001b[39m, in \u001b[36mRebatchedArrowExamplesIterable._iter_arrow\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    497\u001b[39m     previous_state = \u001b[38;5;28mself\u001b[39m.ex_iterable.state_dict()\n\u001b[32m    498\u001b[39m     \u001b[38;5;28mself\u001b[39m._state_dict[\u001b[33m\"\u001b[39m\u001b[33mprevious_state\u001b[39m\u001b[33m\"\u001b[39m] = previous_state\n\u001b[32m--> \u001b[39m\u001b[32m499\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnum_chunks_since_previous_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_reader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_chunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnum_chunks_to_skip\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/datasets/iterable_dataset.py:151\u001b[39m, in \u001b[36m_convert_to_arrow\u001b[39m\u001b[34m(iterable, batch_size, drop_last_batch)\u001b[39m\n\u001b[32m    149\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    150\u001b[39m iterator = \u001b[38;5;28miter\u001b[39m(iterable)\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43miterator_batch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_examples_list\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/datasets/iterable_dataset.py:1558\u001b[39m, in \u001b[36mBufferShuffledExamplesIterable.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1556\u001b[39m \u001b[38;5;66;03m# this is the shuffle buffer that we keep in memory\u001b[39;00m\n\u001b[32m   1557\u001b[39m mem_buffer = []\n\u001b[32m-> \u001b[39m\u001b[32m1558\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mex_iterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1559\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmem_buffer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# if the buffer is full, pick and example from it\u001b[39;49;00m\n\u001b[32m   1560\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindices_iterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/datasets/iterable_dataset.py:288\u001b[39m, in \u001b[36mShuffledDataSourcesExamplesIterable.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m gen_kwags \u001b[38;5;129;01min\u001b[39;00m islice(\n\u001b[32m    285\u001b[39m     _split_gen_kwargs(kwargs_with_shuffled_shards, max_num_jobs=\u001b[38;5;28mself\u001b[39m.num_shards), shard_idx_start, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    286\u001b[39m ):\n\u001b[32m    287\u001b[39m     shard_example_idx_start = \u001b[38;5;28mself\u001b[39m._state_dict[\u001b[33m\"\u001b[39m\u001b[33mshard_example_idx\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state_dict \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey_example\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_examples_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgen_kwags\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshard_example_idx_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_state_dict\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_state_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshard_example_idx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/datasets/packaged_modules/webdataset/webdataset.py:122\u001b[39m, in \u001b[36mWebDataset._generate_examples\u001b[39m\u001b[34m(self, tar_paths, tar_iterators)\u001b[39m\n\u001b[32m    120\u001b[39m all_field_names = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.info.features.keys())\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tar_idx, (tar_path, tar_iterator) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(tar_paths, tar_iterators)):\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_pipeline_from_tar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtar_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtar_iterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mall_field_names\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/datasets/packaged_modules/webdataset/webdataset.py:44\u001b[39m, in \u001b[36mWebDataset._get_pipeline_from_tar\u001b[39m\u001b[34m(cls, tar_path, tar_iterator)\u001b[39m\n\u001b[32m     42\u001b[39m current_example[\u001b[33m\"\u001b[39m\u001b[33m__key__\u001b[39m\u001b[33m\"\u001b[39m] = example_key\n\u001b[32m     43\u001b[39m current_example[\u001b[33m\"\u001b[39m\u001b[33m__url__\u001b[39m\u001b[33m\"\u001b[39m] = tar_path\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m current_example[field_name.lower()] = \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m field_name.split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m SINGLE_FILE_COMPRESSION_EXTENSION_TO_PROTOCOL:\n\u001b[32m     46\u001b[39m     fs.write_bytes(filename, current_example[field_name.lower()])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/tarfile.py:691\u001b[39m, in \u001b[36m_FileInFile.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    689\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m    690\u001b[39m     \u001b[38;5;28mself\u001b[39m.fileobj.seek(offset + (\u001b[38;5;28mself\u001b[39m.position - start))\n\u001b[32m--> \u001b[39m\u001b[32m691\u001b[39m     b = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(b) != length:\n\u001b[32m    693\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ReadError(\u001b[33m\"\u001b[39m\u001b[33munexpected end of data\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/tarfile.py:528\u001b[39m, in \u001b[36m_Stream.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    526\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the next size number of bytes from the stream.\"\"\"\u001b[39;00m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m528\u001b[39m buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[38;5;28mself\u001b[39m.pos += \u001b[38;5;28mlen\u001b[39m(buf)\n\u001b[32m    530\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m buf\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/tarfile.py:536\u001b[39m, in \u001b[36m_Stream._read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return size bytes from the stream.\u001b[39;00m\n\u001b[32m    534\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.comptype == \u001b[33m\"\u001b[39m\u001b[33mtar\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__read\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    538\u001b[39m c = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.dbuf)\n\u001b[32m    539\u001b[39m t = [\u001b[38;5;28mself\u001b[39m.dbuf]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/tarfile.py:566\u001b[39m, in \u001b[36m_Stream.__read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    564\u001b[39m t = [\u001b[38;5;28mself\u001b[39m.buf]\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m c < size:\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m buf:\n\u001b[32m    568\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/datasets/utils/file_utils.py:807\u001b[39m, in \u001b[36m_add_retries_to_file_obj_read_method.<locals>.read_with_retries\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    805\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m retry \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, max_retries + \u001b[32m1\u001b[39m):\n\u001b[32m    806\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m807\u001b[39m         out = \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    808\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    809\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[32m    810\u001b[39m         _AiohttpClientError,\n\u001b[32m    811\u001b[39m         asyncio.TimeoutError,\n\u001b[32m    812\u001b[39m         requests.exceptions.ConnectionError,\n\u001b[32m    813\u001b[39m         requests.exceptions.Timeout,\n\u001b[32m    814\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:1015\u001b[39m, in \u001b[36mHfFileSystemFile.read\u001b[39m\u001b[34m(self, length)\u001b[39m\n\u001b[32m   1013\u001b[39m         \u001b[38;5;28mself\u001b[39m.loc += \u001b[38;5;28mlen\u001b[39m(out)\n\u001b[32m   1014\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m-> \u001b[39m\u001b[32m1015\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/fsspec/spec.py:1941\u001b[39m, in \u001b[36mAbstractBufferedFile.read\u001b[39m\u001b[34m(self, length)\u001b[39m\n\u001b[32m   1938\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m length == \u001b[32m0\u001b[39m:\n\u001b[32m   1939\u001b[39m     \u001b[38;5;66;03m# don't even bother calling fetch\u001b[39;00m\n\u001b[32m   1940\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1941\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fetch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1943\u001b[39m logger.debug(\n\u001b[32m   1944\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m read: \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1945\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1948\u001b[39m     \u001b[38;5;28mself\u001b[39m.cache._log_stats(),\n\u001b[32m   1949\u001b[39m )\n\u001b[32m   1950\u001b[39m \u001b[38;5;28mself\u001b[39m.loc += \u001b[38;5;28mlen\u001b[39m(out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/fsspec/caching.py:234\u001b[39m, in \u001b[36mReadAheadCache._fetch\u001b[39m\u001b[34m(self, start, end)\u001b[39m\n\u001b[32m    232\u001b[39m end = \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m.size, end + \u001b[38;5;28mself\u001b[39m.blocksize)\n\u001b[32m    233\u001b[39m \u001b[38;5;28mself\u001b[39m.total_requested_bytes += end - start\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m \u001b[38;5;28mself\u001b[39m.cache = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfetcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# new block replaces old\u001b[39;00m\n\u001b[32m    235\u001b[39m \u001b[38;5;28mself\u001b[39m.start = start\n\u001b[32m    236\u001b[39m \u001b[38;5;28mself\u001b[39m.end = \u001b[38;5;28mself\u001b[39m.start + \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.cache)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:969\u001b[39m, in \u001b[36mHfFileSystemFile._fetch_range\u001b[39m\u001b[34m(self, start, end)\u001b[39m\n\u001b[32m    958\u001b[39m headers = {\n\u001b[32m    959\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrange\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbytes=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    960\u001b[39m     **\u001b[38;5;28mself\u001b[39m.fs._api._build_hf_headers(),\n\u001b[32m    961\u001b[39m }\n\u001b[32m    962\u001b[39m url = hf_hub_url(\n\u001b[32m    963\u001b[39m     repo_id=\u001b[38;5;28mself\u001b[39m.resolved_path.repo_id,\n\u001b[32m    964\u001b[39m     revision=\u001b[38;5;28mself\u001b[39m.resolved_path.revision,\n\u001b[32m   (...)\u001b[39m\u001b[32m    967\u001b[39m     endpoint=\u001b[38;5;28mself\u001b[39m.fs.endpoint,\n\u001b[32m    968\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m r = \u001b[43mhttp_backoff\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_on_status_codes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m502\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m503\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m504\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHF_HUB_DOWNLOAD_TIMEOUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    976\u001b[39m hf_raise_for_status(r)\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:310\u001b[39m, in \u001b[36mhttp_backoff\u001b[39m\u001b[34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m].seek(io_obj_initial_pos)\n\u001b[32m    309\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m response = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m retry_on_status_codes:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:96\u001b[39m, in \u001b[36mUniqueRequestIdAdapter.send\u001b[39m\u001b[34m(self, request, *args, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m     logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_curlify(request)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.RequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     98\u001b[39m     request_id = request.headers.get(X_AMZN_TRACE_ID)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/aigen/.venv/lib/python3.12/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:1428\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1426\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1427\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1428\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1430\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1252\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1250\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1251\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ╔═ Notebook-friendly Downloader ═╗\n",
    "DATASET = \"ProGamerGov/synthetic-dataset-1m-dalle3-high-quality-captions\"\n",
    "SPLIT   = \"train\"\n",
    "TARGET  = 50_000\n",
    "DEST    = \"/home/yaya/aigen/data/raw/fake/dalle3\"   # ← 用絕對路徑\n",
    "BUFFER  = 12_000\n",
    "SEED    = 42\n",
    "USE_HASH= False\n",
    "\n",
    "import pathlib, os, io, hashlib, warnings, itertools\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm            # ✅\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"PIL.\")\n",
    "\n",
    "dest = pathlib.Path(DEST)\n",
    "dest.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "exist = {p.name for p in dest.glob(\"*.jpg\")}\n",
    "done  = len(exist)\n",
    "print(f\"已有 {done} 張，目標 {TARGET}\")\n",
    "\n",
    "if done >= TARGET:\n",
    "    print(\"✓ 已達標！\"); raise SystemExit\n",
    "\n",
    "ds      = load_dataset(DATASET, split=SPLIT, streaming=True)\n",
    "stream  = ds.shuffle(seed=SEED, buffer_size=BUFFER)\n",
    "\n",
    "def make_key(img, label, idx):\n",
    "    return (hashlib.sha1(img.tobytes()).hexdigest() if USE_HASH\n",
    "            else f\"{label:04d}_{idx:08d}\") + \".jpg\"\n",
    "\n",
    "saved = 0\n",
    "for ex in tqdm(stream, unit=\"img\", total=TARGET-done):\n",
    "    if done + saved >= TARGET:\n",
    "        break\n",
    "    img = ex[\"image\"]\n",
    "    if isinstance(img, bytes):\n",
    "        img = Image.open(io.BytesIO(img))\n",
    "    img = img.convert(\"RGB\")\n",
    "\n",
    "    key = make_key(img, ex.get(\"label\",0), done+saved)\n",
    "    if key in exist:           # 跳重複\n",
    "        continue\n",
    "\n",
    "    img.save(dest / key, quality=95)\n",
    "    exist.add(key); saved += 1\n",
    "\n",
    "print(f\"✅ 新增 {saved} 張，總計 {len(exist)}/{TARGET}\")\n",
    "# ╚═══════════════════════════════╝\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be1aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ProGamerGov/synthetic-dataset-1m-dalle3-high-quality-captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b8e7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已有 0 張，目標 50000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1f7ddf93674b1395d72c5ca6adbc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a191c412e348b1890742d8114e2635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699039aea315446fa2d8c61414e60c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?img/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ╔═ Notebook-friendly Downloader (v2) ═╗\n",
    "DATASET   = \"OpenDatasets/dalle-3-dataset\"\n",
    "SPLIT     = \"train\"\n",
    "TARGET    = 50_000\n",
    "DEST      = \"/home/yaya/aigen/data/raw/fake/dalle3\"\n",
    "BUFFER    = 12_000\n",
    "SEED      = 42\n",
    "USE_HASH  = False          # True → 用 SHA-1 去重\n",
    "SAVE_CAP  = False          # True → 同名 .txt 存 caption\n",
    "FLUSH_EVERY = 1_000        # 每抓 N 張 flush 一次\n",
    "\n",
    "# ──────────────────────────────────────\n",
    "import pathlib, os, io, hashlib, warnings, time\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"PIL.\")\n",
    "dest = pathlib.Path(DEST); dest.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1️⃣ 讀續跑紀錄\n",
    "done_file = dest / \"done.txt\"\n",
    "if done_file.exists():\n",
    "    with done_file.open() as f:\n",
    "        exist = set(line.strip() for line in f)\n",
    "else:\n",
    "    exist = set()\n",
    "\n",
    "done = len(exist)\n",
    "print(f\"已有 {done} 張，目標 {TARGET}\")\n",
    "if done >= TARGET:\n",
    "    print(\"✓ 已達標！\"); raise SystemExit\n",
    "\n",
    "# 2️⃣ 建立 streaming dataset\n",
    "ds = load_dataset(DATASET, split=SPLIT, streaming=True)\n",
    "stream = ds.shuffle(seed=SEED, buffer_size=BUFFER)\n",
    "\n",
    "def make_key(img, label, idx):\n",
    "    if USE_HASH:\n",
    "        h = hashlib.sha1(img.tobytes()).hexdigest()\n",
    "        return f\"{h}.jpg\"\n",
    "    else:\n",
    "        return f\"{label:04d}_{idx:08d}.jpg\"\n",
    "\n",
    "saved = 0; tic = time.time()\n",
    "bar = tqdm(total=TARGET-done, unit=\"img\")\n",
    "out_f = done_file.open(\"a\")\n",
    "\n",
    "for ex in stream:\n",
    "    if done + saved >= TARGET:\n",
    "        break\n",
    "\n",
    "    img = ex[\"image\"]\n",
    "    if isinstance(img, bytes):\n",
    "        img = Image.open(io.BytesIO(img))\n",
    "    img = img.convert(\"RGB\")\n",
    "\n",
    "    key = make_key(img, ex.get(\"label\", 0), done + saved)\n",
    "    if key in exist:\n",
    "        continue\n",
    "\n",
    "    # 3️⃣ 儲存圖片 (+ caption)\n",
    "    img.save(dest / key, quality=95)\n",
    "    if SAVE_CAP:\n",
    "        cap_path = dest / f\"{key[:-4]}.txt\"\n",
    "        cap_path.write_text(ex.get(\"text\", \"\"), encoding=\"utf-8\")\n",
    "\n",
    "    exist.add(key); out_f.write(key + \"\\n\"); saved += 1\n",
    "    bar.update(1)\n",
    "\n",
    "    # 4️⃣ 每 N 張 flush + 顯示速率\n",
    "    if saved % FLUSH_EVERY == 0:\n",
    "        out_f.flush(); os.fsync(out_f.fileno())\n",
    "        speed = saved / (time.time() - tic)\n",
    "        bar.set_postfix_str(f\"{speed:.1f} img/s\")\n",
    "\n",
    "out_f.close(); bar.close()\n",
    "print(f\"✅ 新增 {saved} 張，總計 {len(exist)}/{TARGET}\")\n",
    "# ╚════════════════════════════════════╝\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f3f8f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到 50,000 張影像，開始打包…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "img_0000.zip: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:33<00:00, 107.25img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ img_0000.zip 完成（10000 張）\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "img_0001.zip: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:33<00:00, 106.45img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ img_0001.zip 完成（10000 張）\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "img_0002.zip: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:33<00:00, 107.09img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ img_0002.zip 完成（10000 張）\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "img_0003.zip: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:33<00:00, 106.79img/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ img_0003.zip 完成（10000 張）\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "img_0004.zip: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:34<00:00, 105.47img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ img_0004.zip 完成（10000 張）\n",
      "🎉 全部批次壓縮完成！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ╔═╗  batch-zip-to-10k ─ 每 1萬 張圖片一包 ══════════════════════════════╗\n",
    "# 設定區 ── 改成自己的路徑 / 參數\n",
    "SRC_DIR  = \"data/raw/fake/midjourney-v6-llava\"   # 放圖片的資料夾（所有圖平放）\n",
    "DST_DIR  = \"data/zips/midjourney-v6-llava\"               # 壓縮檔要存哪\n",
    "CHUNK    = 10_000                    # 每 ZIP 裡放多少張\n",
    "EXTS     = [\".jpg\", \".jpeg\", \".png\", \".webp\", \".bmp\"]  # 要抓的副檔名\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────\n",
    "import pathlib, zipfile, tqdm, os\n",
    "\n",
    "src = pathlib.Path(SRC_DIR)\n",
    "dst = pathlib.Path(DST_DIR); dst.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "imgs = sorted([p for p in src.iterdir() if p.suffix.lower() in EXTS])\n",
    "total = len(imgs)\n",
    "print(f\"找到 {total:,} 張影像，開始打包…\")\n",
    "\n",
    "batches = [imgs[i:i+CHUNK] for i in range(0, total, CHUNK)]\n",
    "\n",
    "for idx, batch in enumerate(batches):\n",
    "    zip_path = dst / f\"img_{idx:04d}.zip\"\n",
    "    if zip_path.exists():\n",
    "        print(f\"✓ {zip_path.name} 已存在，跳過\")\n",
    "        continue\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "        for p in tqdm.tqdm(batch, desc=zip_path.name, unit=\"img\"):\n",
    "            zf.write(p, arcname=p.name)   # 只存檔名，不帶資料夾層\n",
    "    print(f\"✅ {zip_path.name} 完成（{len(batch)} 張）\")\n",
    "\n",
    "print(\"🎉 全部批次壓縮完成！\")\n",
    "# ╚════════════════════════════════════════════════════════════════════╝\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31fa314",
   "metadata": {},
   "source": [
    "rafaelpadilla/coco2017\n",
    "ProGamerGov/synthetic-dataset-1m-dalle3-high-quality-captions\n",
    "brivangl/midjourney-v6-llava"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a69b2be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共有 25002 張照片的紀錄\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo_id</th>\n",
       "      <th>photo_url</th>\n",
       "      <th>photo_image_url</th>\n",
       "      <th>photo_submitted_at</th>\n",
       "      <th>photo_featured</th>\n",
       "      <th>photo_width</th>\n",
       "      <th>photo_height</th>\n",
       "      <th>photo_aspect_ratio</th>\n",
       "      <th>photo_description</th>\n",
       "      <th>photographer_username</th>\n",
       "      <th>...</th>\n",
       "      <th>photo_location_city</th>\n",
       "      <th>stats_views</th>\n",
       "      <th>stats_downloads</th>\n",
       "      <th>ai_description</th>\n",
       "      <th>ai_primary_landmark_name</th>\n",
       "      <th>ai_primary_landmark_latitude</th>\n",
       "      <th>ai_primary_landmark_longitude</th>\n",
       "      <th>ai_primary_landmark_confidence</th>\n",
       "      <th>blur_hash</th>\n",
       "      <th>[ZoneTransfer]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oSf8ePoG9NU</td>\n",
       "      <td>https://unsplash.com/photos/oSf8ePoG9NU</td>\n",
       "      <td>https://images.unsplash.com/20/frozen-grass.JPG</td>\n",
       "      <td>2013-12-04 14:58:49</td>\n",
       "      <td>t</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>2667.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>andrekoch</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4296224.0</td>\n",
       "      <td>30072.0</td>\n",
       "      <td>black road in between white and brown grass ac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LPBM;~RkM|of~VRkNHof%1RjRkof</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DlsOa5moK4w</td>\n",
       "      <td>https://unsplash.com/photos/DlsOa5moK4w</td>\n",
       "      <td>https://images.unsplash.com/reserve/dRA4UuMBR2...</td>\n",
       "      <td>2014-07-10 17:19:38</td>\n",
       "      <td>t</td>\n",
       "      <td>5184.0</td>\n",
       "      <td>3456.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Fresh blueberries</td>\n",
       "      <td>majkmmiklavc</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8731049.0</td>\n",
       "      <td>26411.0</td>\n",
       "      <td>selective focus of blueberry plant</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LiJ+M4s=-pj;~qx]RpbXx1ogRkob</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XBGacbT3vXI</td>\n",
       "      <td>https://unsplash.com/photos/XBGacbT3vXI</td>\n",
       "      <td>https://images.unsplash.com/photo-143633523196...</td>\n",
       "      <td>2015-07-08 05:54:38.486126</td>\n",
       "      <td>t</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shooshanig</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2224540.0</td>\n",
       "      <td>19250.0</td>\n",
       "      <td>photography of calm beach side</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LSL}HBR*a{fP_NWVoej[x^s.j[ay</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FjikPptEbZg</td>\n",
       "      <td>https://unsplash.com/photos/FjikPptEbZg</td>\n",
       "      <td>https://images.unsplash.com/flagged/photo-1441...</td>\n",
       "      <td>2015-08-31 07:12:27.700568</td>\n",
       "      <td>f</td>\n",
       "      <td>3008.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>websanya</td>\n",
       "      <td>...</td>\n",
       "      <td>Saint-Étienne-de-Tinée</td>\n",
       "      <td>45536.0</td>\n",
       "      <td>421.0</td>\n",
       "      <td>green trees on mountain under white clouds dur...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LyF7Cux[M{kB?^t6azbHRjjrt7ae</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PXdBkNF8rlk</td>\n",
       "      <td>https://unsplash.com/photos/PXdBkNF8rlk</td>\n",
       "      <td>https://images.unsplash.com/photo-144596683821...</td>\n",
       "      <td>2015-10-27 17:30:25.724092</td>\n",
       "      <td>t</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Icebergs of Iceland’s Vatnajokull</td>\n",
       "      <td>andersjilden</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7394191.0</td>\n",
       "      <td>43442.0</td>\n",
       "      <td>icebergs floating on body of water during daytime</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LQG]];?b~qayBtIU9Ft79xj[tRM|</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      photo_id                                photo_url  \\\n",
       "0  oSf8ePoG9NU  https://unsplash.com/photos/oSf8ePoG9NU   \n",
       "1  DlsOa5moK4w  https://unsplash.com/photos/DlsOa5moK4w   \n",
       "2  XBGacbT3vXI  https://unsplash.com/photos/XBGacbT3vXI   \n",
       "3  FjikPptEbZg  https://unsplash.com/photos/FjikPptEbZg   \n",
       "4  PXdBkNF8rlk  https://unsplash.com/photos/PXdBkNF8rlk   \n",
       "\n",
       "                                     photo_image_url  \\\n",
       "0    https://images.unsplash.com/20/frozen-grass.JPG   \n",
       "1  https://images.unsplash.com/reserve/dRA4UuMBR2...   \n",
       "2  https://images.unsplash.com/photo-143633523196...   \n",
       "3  https://images.unsplash.com/flagged/photo-1441...   \n",
       "4  https://images.unsplash.com/photo-144596683821...   \n",
       "\n",
       "           photo_submitted_at photo_featured  photo_width  photo_height  \\\n",
       "0         2013-12-04 14:58:49              t       4000.0        2667.0   \n",
       "1         2014-07-10 17:19:38              t       5184.0        3456.0   \n",
       "2  2015-07-08 05:54:38.486126              t       6000.0        4000.0   \n",
       "3  2015-08-31 07:12:27.700568              f       3008.0        2008.0   \n",
       "4  2015-10-27 17:30:25.724092              t       3000.0        2000.0   \n",
       "\n",
       "   photo_aspect_ratio                  photo_description  \\\n",
       "0                 1.5                                NaN   \n",
       "1                 1.5                  Fresh blueberries   \n",
       "2                 1.5                                NaN   \n",
       "3                 1.5                                NaN   \n",
       "4                 1.5  Icebergs of Iceland’s Vatnajokull   \n",
       "\n",
       "  photographer_username  ...     photo_location_city stats_views  \\\n",
       "0             andrekoch  ...                     NaN   4296224.0   \n",
       "1          majkmmiklavc  ...                     NaN   8731049.0   \n",
       "2            shooshanig  ...                     NaN   2224540.0   \n",
       "3              websanya  ...  Saint-Étienne-de-Tinée     45536.0   \n",
       "4          andersjilden  ...                     NaN   7394191.0   \n",
       "\n",
       "  stats_downloads                                     ai_description  \\\n",
       "0         30072.0  black road in between white and brown grass ac...   \n",
       "1         26411.0                 selective focus of blueberry plant   \n",
       "2         19250.0                     photography of calm beach side   \n",
       "3           421.0  green trees on mountain under white clouds dur...   \n",
       "4         43442.0  icebergs floating on body of water during daytime   \n",
       "\n",
       "   ai_primary_landmark_name ai_primary_landmark_latitude  \\\n",
       "0                       NaN                          NaN   \n",
       "1                       NaN                          NaN   \n",
       "2                       NaN                          NaN   \n",
       "3                       NaN                          NaN   \n",
       "4                       NaN                          NaN   \n",
       "\n",
       "  ai_primary_landmark_longitude ai_primary_landmark_confidence  \\\n",
       "0                           NaN                            NaN   \n",
       "1                           NaN                            NaN   \n",
       "2                           NaN                            NaN   \n",
       "3                           NaN                            NaN   \n",
       "4                           NaN                            NaN   \n",
       "\n",
       "                      blur_hash  [ZoneTransfer]  \n",
       "0  LPBM;~RkM|of~VRkNHof%1RjRkof             NaN  \n",
       "1  LiJ+M4s=-pj;~qx]RpbXx1ogRkob             NaN  \n",
       "2  LSL}HBR*a{fP_NWVoej[x^s.j[ay             NaN  \n",
       "3  LyF7Cux[M{kB?^t6azbHRjjrt7ae             NaN  \n",
       "4  LQG]];?b~qayBtIU9Ft79xj[tRM|             NaN  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell 1 ── 載入資料表\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"/home/yaya/ai-detect-proj/unsplash-research-dataset-lite-latest\").expanduser()\n",
    "\n",
    "# Lite 版的表被切成 photos.csv000、photos.csv001 ...\n",
    "photo_parts = sorted(DATA_DIR.glob(\"photos.csv*\"))\n",
    "df_photos = pd.concat(\n",
    "    [pd.read_csv(p, sep='\\t', compression='infer', low_memory=False)  # 檔案實際是 TSV\n",
    "     for p in photo_parts],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "print(\"共有\", len(df_photos), \"張照片的紀錄\")\n",
    "df_photos.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549a81c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 11219/25000 [00:00<00:00, 38962.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ rsJtMXn3p_c HTTPSConnectionPool(host='images.unsplash.com-grass-sun.jpg', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x72683e22ba50>: Failed to resolve 'images.unsplash.com-grass-sun.jpg' ([Errno -2] Name or service not known)\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15124/25000 [00:00<00:00, 37169.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ vigsqYux_-8 HTTPSConnectionPool(host='images.unsplash.com_thebeach.jpg', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x72683c8be5d0>: Failed to resolve 'images.unsplash.com_thebeach.jpg' ([Errno -2] Name or service not known)\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 16381/25000 [10:38<1:18:55,  1.82it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ 9_9hzZVjV8s HTTPSConnectionPool(host='images.unsplash.company', port=443): Max retries exceeded with url: / (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x72683c8d7f10>: Failed to resolve 'images.unsplash.company' ([Errno -2] Name or service not known)\"))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 16790/25000 [16:42<1:34:36,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ 5zcMJqXnjwo HTTPSConnectionPool(host='images.unsplash.com', port=443): Max retries exceeded with url: /photo-1563533538587-143606e03edd (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x72683c8d5d10>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18035/25000 [34:23<2:06:46,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ emI7VUcvLi0 HTTPSConnectionPool(host='images.unsplash.com', port=443): Max retries exceeded with url: /photo-1570117267971-85d1ec8ffb45 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x72683c6e7150>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 19788/25000 [59:00<1:43:23,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ F_IqJEZZGvo HTTPSConnectionPool(host='images.unsplash.com', port=443): Max retries exceeded with url: /photo-1418154388337-cb9d36a0cd98 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x72683c6e71d0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 19797/25000 [59:06<59:26,  1.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ LIlG2UO71TY HTTPSConnectionPool(host='images.unsplash.com', port=443): Max retries exceeded with url: /photo-1557296691-2cc94cf82845 (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x72683c8cca90>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 22006/25000 [1:28:30<34:24,  1.45it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ nan Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 22565/25000 [1:36:02<40:12,  1.01it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✗ nan Invalid URL 'nan': No scheme supplied. Perhaps you meant https://nan?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [2:09:04<00:00,  3.23it/s]  \n"
     ]
    }
   ],
   "source": [
    "# cell 2 ── 批次下載\n",
    "import requests, shutil, time, tqdm, os\n",
    "\n",
    "SAVE_DIR = Path(\"/home/yaya/ai-detect-proj/data/raw/real/unsplash\")\n",
    "SAVE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# 建議用 raw_url；若想配合 Unsplash 的下載統計，改用 download_location\n",
    "subset = df_photos.sample(25000, random_state=42)   # 先隨機抓 200 張試跑\n",
    "\n",
    "for _, row in tqdm.tqdm(subset.iterrows(), total=len(subset)):\n",
    "    url  = row['photo_image_url']            # 或 row['download_location']\n",
    "    pid  = row['photo_id']\n",
    "    ext  = \".jpg\"                    # Unsplash 皆為 JPEG\n",
    "    dest = SAVE_DIR / f\"{pid}{ext}\"\n",
    "    if dest.exists(): \n",
    "        continue                     # 已下載過就略過\n",
    "    try:\n",
    "        with requests.get(url, stream=True, timeout=30) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(dest, 'wb') as f:\n",
    "                shutil.copyfileobj(r.raw, f)\n",
    "        time.sleep(0.3)              # 避免對伺服器造成過大負載\n",
    "    except Exception as e:\n",
    "        print(\"✗\", pid, e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4173215b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yaya/miniforge3/envs/imgfeat/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`trust_remote_code` is not supported anymore.\n",
      "Please check that the Hugging Face dataset 'wtcherr/unsplash_20k' isn't based on a loading script and remove `trust_remote_code`.\n",
      "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'IterableDataset' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 讀取 train split（只有 train 這一個 split）\u001b[39;00m\n\u001b[32m      4\u001b[39m ds = load_dataset(\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mwtcherr/unsplash_20k\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     split=\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     streaming=\u001b[38;5;28;01mTrue\u001b[39;00m,     \u001b[38;5;66;03m# 若想邊用邊載可改成 True\u001b[39;00m\n\u001b[32m      8\u001b[39m     trust_remote_code=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      9\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m共有\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33m筆\u001b[39m\u001b[33m\"\u001b[39m)       \u001b[38;5;66;03m# 約 19000\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(ds.column_names)            \u001b[38;5;66;03m# ['caption', 'image', 'link', ...]\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'IterableDataset' has no len()"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 讀取 train split（只有 train 這一個 split）\n",
    "ds = load_dataset(\n",
    "    \"wtcherr/unsplash_20k\",\n",
    "    split=\"train\",\n",
    "    streaming=True,     # 若想邊用邊載可改成 True\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(\"共有\", len(ds), \"筆\")       # 約 19000\n",
    "print(ds.column_names)            # ['caption', 'image', 'link', ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c05b542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "save png: 837it [08:27,  1.65it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/imgfeat/lib/python3.11/site-packages/PIL/ImageFile.py:644\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(im, fp, tile, bufsize)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     fh = \u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfileno\u001b[49m()\n\u001b[32m    645\u001b[39m     fp.flush()\n",
      "\u001b[31mAttributeError\u001b[39m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(ds.take(MAX_IMAGES), desc=\u001b[33m\"\u001b[39m\u001b[33msave png\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m     13\u001b[39m     img = row[\u001b[33m\"\u001b[39m\u001b[33mimage\u001b[39m\u001b[33m\"\u001b[39m]        \u001b[38;5;66;03m# PIL.Image 物件\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43midx\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[33;43m06d\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.png\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPNG\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompress_level\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# 0~9，數字越大壓縮越高（預設 6）\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/imgfeat/lib/python3.11/site-packages/PIL/Image.py:2588\u001b[39m, in \u001b[36mImage.save\u001b[39m\u001b[34m(self, fp, format, **params)\u001b[39m\n\u001b[32m   2585\u001b[39m     fp = cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n\u001b[32m   2587\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2588\u001b[39m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2589\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   2590\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/imgfeat/lib/python3.11/site-packages/PIL/PngImagePlugin.py:1495\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(im, fp, filename, chunk, save_all)\u001b[39m\n\u001b[32m   1491\u001b[39m     single_im = _write_multiple_frames(\n\u001b[32m   1492\u001b[39m         im, fp, chunk, mode, rawmode, default_image, append_images\n\u001b[32m   1493\u001b[39m     )\n\u001b[32m   1494\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m single_im:\n\u001b[32m-> \u001b[39m\u001b[32m1495\u001b[39m     \u001b[43mImageFile\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1496\u001b[39m \u001b[43m        \u001b[49m\u001b[43msingle_im\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIO\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_idat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1498\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mImageFile\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Tile\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mzip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_im\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[32m   1502\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m info_chunk \u001b[38;5;129;01min\u001b[39;00m info.chunks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/imgfeat/lib/python3.11/site-packages/PIL/ImageFile.py:648\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(im, fp, tile, bufsize)\u001b[39m\n\u001b[32m    646\u001b[39m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[32m    647\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io.UnsupportedOperation) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m     \u001b[43m_encode_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[33m\"\u001b[39m\u001b[33mflush\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    650\u001b[39m     fp.flush()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/imgfeat/lib/python3.11/site-packages/PIL/ImageFile.py:674\u001b[39m, in \u001b[36m_encode_tile\u001b[39m\u001b[34m(im, fp, tile, bufsize, fh, exc)\u001b[39m\n\u001b[32m    671\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exc:\n\u001b[32m    672\u001b[39m     \u001b[38;5;66;03m# compress to Python file-compatible object\u001b[39;00m\n\u001b[32m    673\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m674\u001b[39m         errcode, data = \u001b[43mencoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m:]\n\u001b[32m    675\u001b[39m         fp.write(data)\n\u001b[32m    676\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m errcode:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. 目的資料夾\n",
    "out_dir = Path(\"/home/yaya/ai-detect-proj/data/raw/fake/dalle3_png\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. 下載與儲存（最多 20 000 張）\n",
    "MAX_IMAGES = 20000\n",
    "\n",
    "for idx, row in enumerate(tqdm(ds.take(MAX_IMAGES), desc=\"save png\")):\n",
    "    img = row[\"image\"]        # PIL.Image 物件\n",
    "    img.save(\n",
    "        out_dir / f\"{idx:06d}.png\",\n",
    "        format=\"PNG\",\n",
    "        compress_level=6       # 0~9，數字越大壓縮越高（預設 6）\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9432f75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yaya/miniforge3/envs/imgfeat/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "ok-only (train):   0%|          | 79/50000 [53:49<503:04:41, 36.28s/it]  "
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import requests, os, time, random, threading\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed, wait, FIRST_COMPLETED\n",
    "\n",
    "# ========= 參數 =========\n",
    "DATASET_ID    = \"bitmind/open-images-v7\"\n",
    "SPLIT         = \"train\"                 # \"train\" | \"validation\" | \"test\"\n",
    "TARGET_GOOD   = 50000                   # 你想要的「合格」張數（進度條看這個）\n",
    "OUT_DIR       = Path(\"/home/yaya/ai-detect-proj/data/raw/real/open-images-v7\")\n",
    "SEED          = 72\n",
    "SHUF_BUFFER   = 200_000\n",
    "TIMEOUT       = 25\n",
    "RETRIES       = 3\n",
    "SLEEP_BASE    = 1.0\n",
    "VERIFY_IMAGE  = True\n",
    "MIN_SIDE      = 512                     # 小於此值視為不合格（skip_small）\n",
    "SAVE_AS_PNG   = False\n",
    "MAX_WORKERS   = 32                      # 併發\n",
    "MAX_INFLIGHT  = MAX_WORKERS * 4         # 同時在跑/排隊的任務上限，減少超量下載\n",
    "\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "random.seed(SEED)\n",
    "\n",
    "# ========= 工具 =========\n",
    "def _ext_from_url(u: str) -> str:\n",
    "    ext = os.path.splitext(urlparse(u).path)[1].lower()\n",
    "    return ext if ext in [\".jpg\", \".jpeg\", \".png\", \".webp\", \".bmp\"] else \".jpg\"\n",
    "\n",
    "def _build_path(idx: int, url: str) -> Path:\n",
    "    return OUT_DIR / (f\"{idx:06d}.png\" if SAVE_AS_PNG else f\"{idx:06d}{_ext_from_url(url)}\")\n",
    "\n",
    "def _save_bytes_as_img(data: bytes, path: Path):\n",
    "    tmp = path.with_suffix(path.suffix + \".part\")\n",
    "    if SAVE_AS_PNG:\n",
    "        img = Image.open(BytesIO(data)).convert(\"RGB\")\n",
    "        img.save(tmp, format=\"PNG\", compress_level=6)\n",
    "        os.replace(tmp, path)\n",
    "    else:\n",
    "        with open(tmp, \"wb\") as f:\n",
    "            f.write(data)\n",
    "        os.replace(tmp, path)\n",
    "\n",
    "_thread_local = threading.local()\n",
    "def _get_session() -> requests.Session:\n",
    "    s = getattr(_thread_local, \"session\", None)\n",
    "    if s is None:\n",
    "        s = requests.Session()\n",
    "        s.headers.update({\"User-Agent\": \"Mozilla/5.0 (compatible; open-images-downloader)\"})\n",
    "        _thread_local.session = s\n",
    "    return s\n",
    "\n",
    "def _download_one(idx: int, url: str):\n",
    "    \"\"\"回傳: ('ok' | 'skip_exists' | 'skip_small' | 'bad_verify' | 'bad_fail', msg)\"\"\"\n",
    "    if not url:\n",
    "        return (\"bad_fail\", \"no_url\")\n",
    "\n",
    "    out_path = _build_path(idx, url)\n",
    "    if out_path.exists():\n",
    "        return (\"skip_exists\", \"exists\")\n",
    "\n",
    "    backoff = SLEEP_BASE\n",
    "    for attempt in range(1, RETRIES + 1):\n",
    "        try:\n",
    "            r = _get_session().get(url, timeout=TIMEOUT)\n",
    "            if r.status_code != 200:\n",
    "                raise RuntimeError(f\"http {r.status_code}\")\n",
    "            data = r.content\n",
    "\n",
    "            if VERIFY_IMAGE or MIN_SIDE > 0 or SAVE_AS_PNG:\n",
    "                try:\n",
    "                    img = Image.open(BytesIO(data))\n",
    "                    img.verify()\n",
    "                    img = Image.open(BytesIO(data))\n",
    "                    if MIN_SIDE > 0:\n",
    "                        w, h = img.size\n",
    "                        if min(w, h) < MIN_SIDE:\n",
    "                            return (\"skip_small\", f\"{w}x{h}\")\n",
    "                except Exception as e:\n",
    "                    return (\"bad_verify\", str(e))\n",
    "\n",
    "            _save_bytes_as_img(data, out_path)\n",
    "            return (\"ok\", \"saved\")\n",
    "        except Exception as e:\n",
    "            if attempt >= RETRIES:\n",
    "                return (\"bad_fail\", str(e))\n",
    "            time.sleep(backoff)\n",
    "            backoff *= 2.0\n",
    "\n",
    "# ========= 準備資料（串流 + 打散）=========\n",
    "ds = load_dataset(DATASET_ID, split=SPLIT, streaming=True)\n",
    "ds = ds.shuffle(seed=SEED, buffer_size=SHUF_BUFFER)\n",
    "it = iter(ds)\n",
    "\n",
    "# 取資料時的索引（用來命名檔案）\n",
    "next_idx = 0\n",
    "\n",
    "def _next_task():\n",
    "    \"\"\"讀取下一筆 (idx, url)，若無法再取回傳 None\"\"\"\n",
    "    global next_idx\n",
    "    while True:\n",
    "        try:\n",
    "            row = next(it)   # 可能 StopIteration\n",
    "        except StopIteration:\n",
    "            return None\n",
    "        url = row.get(\"url\") or row.get(\"URL\")\n",
    "        # 先把已存在的檔案過濾掉，不丟進執行緒池（不影響進度條 total）\n",
    "        path = _build_path(next_idx, url if url else \"\")\n",
    "        if url and not path.exists():\n",
    "            idx = next_idx\n",
    "            next_idx += 1\n",
    "            return (idx, url)\n",
    "        else:\n",
    "            next_idx += 1\n",
    "            # 單純略過已存在／無 URL 的案例，繼續抓下一筆\n",
    "\n",
    "# ========= 併發下載（進度條只計「ok」）=========\n",
    "ok = skip_exists = skip_small = bad_verify = bad_fail = 0\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "    futures = set()\n",
    "\n",
    "    # 先灌一批任務\n",
    "    while len(futures) < MAX_INFLIGHT:\n",
    "        task = _next_task()\n",
    "        if task is None:\n",
    "            break\n",
    "        futures.add(ex.submit(_download_one, *task))\n",
    "\n",
    "    with tqdm(total=TARGET_GOOD, desc=f\"ok-only ({SPLIT})\") as pbar:\n",
    "        while futures and ok < TARGET_GOOD:\n",
    "            done, futures = wait(futures, return_when=FIRST_COMPLETED)\n",
    "            for fut in done:\n",
    "                status, _ = fut.result()\n",
    "                if status == \"ok\":\n",
    "                    ok += 1\n",
    "                    pbar.update(1)                 # ★ 只在 ok 時更新進度條\n",
    "                elif status == \"skip_exists\":\n",
    "                    skip_exists += 1\n",
    "                elif status == \"skip_small\":\n",
    "                    skip_small += 1\n",
    "                elif status == \"bad_verify\":\n",
    "                    bad_verify += 1\n",
    "                else:\n",
    "                    bad_fail += 1\n",
    "\n",
    "                # 補進新的任務，維持 in-flight 數量\n",
    "                if ok < TARGET_GOOD:\n",
    "                    task = _next_task()\n",
    "                    if task is not None:\n",
    "                        futures.add(ex.submit(_download_one, *task))\n",
    "\n",
    "        # 如果還有未完成但我們已經達標，就嘗試取消\n",
    "        if ok >= TARGET_GOOD:\n",
    "            ex.shutdown(wait=False, cancel_futures=True)\n",
    "\n",
    "print(f\"Done. ok={ok}, skip_exists={skip_exists}, skip_small={skip_small}, \"\n",
    "      f\"bad_verify={bad_verify}, bad_fail={bad_fail}\")\n",
    "print(\"Saved to:\", OUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgfeat (PyTorch)",
   "language": "python",
   "name": "imgfeat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
