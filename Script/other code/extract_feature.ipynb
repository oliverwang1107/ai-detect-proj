{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30d3655c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using splits: /home/yaya/ai-detect-proj/Script/saved_models/splits_clip_feature_iid_ood.json\n",
      "device = cuda\n",
      "[val] CLIP=18000 | ELA=18000(miss 0) | PRNU=18000(miss 0)\n",
      "[test_iid] CLIP=18000 | ELA=18000(miss 0) | PRNU=18000(miss 0)\n",
      "[test_ood] CLIP=43989 | ELA=43989(miss 0) | PRNU=43989(miss 0)\n",
      "CLIP SVM: /home/yaya/ai-detect-proj/Script/saved_models/clip_linear_svm_feature_20250815_170428.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CLIP load: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18000/18000 [00:09<00:00, 1812.67it/s]\n",
      "/home/yaya/miniforge3/envs/imgfeat/lib/python3.11/site-packages/sklearn/calibration.py:330: FutureWarning: The `cv='prefit'` option is deprecated in 1.6 and will be removed in 1.8. You can use CalibratedClassifierCV(FrozenEstimator(estimator)) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELA model: /home/yaya/ai-detect-proj/Script/saved_models/ela_fromnpy_cnn_best_20250815_172022.pt\n",
      "PRNU model: /home/yaya/ai-detect-proj/Script/saved_models/prnu_cnn_i8_best_20250815_183635.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ELA infer: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 141/141 [01:52<00:00,  1.25it/s]\n",
      "PRNU infer: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 141/141 [00:41<00:00,  3.40it/s]\n",
      "CLIP load: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18000/18000 [00:05<00:00, 3052.24it/s]\n",
      "ELA infer: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 141/141 [02:46<00:00,  1.18s/it]\n",
      "PRNU infer: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 141/141 [00:42<00:00,  3.35it/s]\n",
      "CLIP load: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43989/43989 [00:16<00:00, 2676.14it/s]\n",
      "ELA infer: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 344/344 [07:10<00:00,  1.25s/it]\n",
      "PRNU infer: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 344/344 [01:35<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion weights: [[7.38651767 2.42389983 0.25492934]] bias: [-4.71015858]\n",
      "[Val Fused] AUC=0.9892 | thr_youden=0.733 | thr_fpr@5%=0.101\n",
      "\n",
      "[Val (Youden)] acc@thr=0.9779 | auc=0.9892 | thr=0.733\n",
      "[[ 5958    42]\n",
      " [  356 11644]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9436    0.9930    0.9677      6000\n",
      "           1     0.9964    0.9703    0.9832     12000\n",
      "\n",
      "    accuracy                         0.9779     18000\n",
      "   macro avg     0.9700    0.9817    0.9754     18000\n",
      "weighted avg     0.9788    0.9779    0.9780     18000\n",
      "\n",
      "\n",
      "[Test-IID (Youden)] acc@thr=0.9793 | auc=0.9904 | thr=0.733\n",
      "[[ 5961    39]\n",
      " [  334 11666]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9469    0.9935    0.9697      6000\n",
      "           1     0.9967    0.9722    0.9843     12000\n",
      "\n",
      "    accuracy                         0.9793     18000\n",
      "   macro avg     0.9718    0.9828    0.9770     18000\n",
      "weighted avg     0.9801    0.9793    0.9794     18000\n",
      "\n",
      "\n",
      "[Test-OOD (Youden)] acc@thr=0.4818 | auc=0.8806 | thr=0.733\n",
      "[[ 2218 22771]\n",
      " [   23 18977]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9897    0.0888    0.1629     24989\n",
      "           1     0.4546    0.9988    0.6248     19000\n",
      "\n",
      "    accuracy                         0.4818     43989\n",
      "   macro avg     0.7221    0.5438    0.3938     43989\n",
      "weighted avg     0.7586    0.4818    0.3624     43989\n",
      "\n",
      "\n",
      "[Val (FPR@5%)] acc@thr=0.9688 | auc=0.9892 | thr=0.101\n",
      "[[ 5701   299]\n",
      " [  263 11737]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9559    0.9502    0.9530      6000\n",
      "           1     0.9752    0.9781    0.9766     12000\n",
      "\n",
      "    accuracy                         0.9688     18000\n",
      "   macro avg     0.9655    0.9641    0.9648     18000\n",
      "weighted avg     0.9687    0.9688    0.9688     18000\n",
      "\n",
      "\n",
      "[Test-IID (FPR@5%)] acc@thr=0.9709 | auc=0.9904 | thr=0.101\n",
      "[[ 5707   293]\n",
      " [  230 11770]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9613    0.9512    0.9562      6000\n",
      "           1     0.9757    0.9808    0.9783     12000\n",
      "\n",
      "    accuracy                         0.9709     18000\n",
      "   macro avg     0.9685    0.9660    0.9672     18000\n",
      "weighted avg     0.9709    0.9709    0.9709     18000\n",
      "\n",
      "\n",
      "[Test-OOD (FPR@5%)] acc@thr=0.4512 | auc=0.8806 | thr=0.101\n",
      "[[  849 24140]\n",
      " [    0 19000]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0340    0.0657     24989\n",
      "           1     0.4404    1.0000    0.6115     19000\n",
      "\n",
      "    accuracy                         0.4512     43989\n",
      "   macro avg     0.7202    0.5170    0.3386     43989\n",
      "weighted avg     0.7583    0.4512    0.3015     43989\n",
      "\n",
      "\n",
      "[OOD breakdown @ FPR@5%]\n",
      "\n",
      "== OOD per-dataset ==\n",
      "- unsplash   n=24989 | acc=0.0340 | auc=nan\n",
      "[[  849 24140]\n",
      " [    0     0]]\n",
      "\n",
      "- dalle3     n=19000 | acc=1.0000 | auc=nan\n",
      "[[19000]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yaya/miniforge3/envs/imgfeat/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/yaya/miniforge3/envs/imgfeat/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n",
      "/home/yaya/miniforge3/envs/imgfeat/lib/python3.11/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ä¸‰ç‰¹å¾µèåˆï¼ˆCLIP + ELA + PRNUï¼‰â†’ OOD è©•ä¼°\n",
    "# - è‡ªå‹•æŠ“æœ€æ–°æ¨¡å‹\n",
    "# - ç”¨åŒä¸€ä»½ splits_*.json å°é½Šæ¨£æœ¬\n",
    "# - Val ä¸Šè¨“ç·´èåˆå™¨ï¼ˆLogRegï¼‰ï¼Œæ¸¬ Val/Test-IID/Test-OOD\n",
    "# ==========================================\n",
    "import os, json, glob, math, re, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, classification_report, roc_curve\n",
    "import joblib\n",
    "\n",
    "# ---------- è·¯å¾‘è¨­å®š ----------\n",
    "SCRIPT_ROOT = \"/home/yaya/ai-detect-proj/Script\"\n",
    "OUTPUT_DIR  = os.path.join(SCRIPT_ROOT, \"saved_models\")\n",
    "SPLITS_CAND = [\n",
    "    os.path.join(OUTPUT_DIR, \"splits_fewshot_iid_ood.json\"),\n",
    "    os.path.join(OUTPUT_DIR, \"splits_clip_feature_iid_ood.json\"),\n",
    "]\n",
    "SPLITS_JSON = next((p for p in SPLITS_CAND if os.path.isfile(p)), None)\n",
    "assert SPLITS_JSON, \"æ‰¾ä¸åˆ° splits JSONï¼Œè«‹å…ˆç”¢ç”Ÿï¼ˆfewshot æˆ– clip_featureï¼‰\"\n",
    "print(\"Using splits:\", SPLITS_JSON)\n",
    "\n",
    "# è³‡æ–™ç›®éŒ„\n",
    "CLIP_REAL_DIR = os.path.join(SCRIPT_ROOT, \"features_npy\", \"clip_real_npy\")\n",
    "CLIP_FAKE_DIR = os.path.join(SCRIPT_ROOT, \"features_npy\", \"clip_fake_npy\")\n",
    "ELA_REAL_DIR  = os.path.join(SCRIPT_ROOT, \"features_npy\", \"ela_real_npy\")\n",
    "ELA_FAKE_DIR  = os.path.join(SCRIPT_ROOT, \"features_npy\", \"ela_fake_npy\")\n",
    "PRNU_REAL_I8  = os.path.join(SCRIPT_ROOT, \"features_quant\", \"prnu_real_i8\")\n",
    "PRNU_FAKE_I8  = os.path.join(SCRIPT_ROOT, \"features_quant\", \"prnu_fake_i8\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"device =\", device)\n",
    "\n",
    "# ---------- è®€ splits ----------\n",
    "with open(SPLITS_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    SPLITS = json.load(f)[\"splits\"]\n",
    "\n",
    "def is_real_clip(p: str) -> bool:\n",
    "    s = Path(p).as_posix()\n",
    "    return \"/clip_real_npy/\" in s\n",
    "\n",
    "# å»º ELA/PRNU æª”åç´¢å¼•ï¼ˆç”¨ basename æˆ– stem å°æ‡‰ï¼‰\n",
    "def index_dir(d):\n",
    "    idx={}\n",
    "    for q in Path(d).glob(\"*.npy\"):\n",
    "        idx.setdefault(q.name.lower(), str(q))\n",
    "        idx.setdefault(q.stem.lower(), str(q))\n",
    "    for q in Path(d).glob(\"*.npz\"):\n",
    "        idx.setdefault(q.name.lower(), str(q))\n",
    "        idx.setdefault(q.stem.lower(), str(q))\n",
    "    return idx\n",
    "\n",
    "IDX_ELA_REAL = index_dir(ELA_REAL_DIR)\n",
    "IDX_ELA_FAKE = index_dir(ELA_FAKE_DIR)\n",
    "IDX_PR_REAL  = index_dir(PRNU_REAL_I8)\n",
    "IDX_PR_FAKE  = index_dir(PRNU_FAKE_I8)\n",
    "\n",
    "def map_to(dir_idx_real, dir_idx_fake, p: str):\n",
    "    \"\"\"å¾ CLIP split çš„è·¯å¾‘ map åˆ°æŸç¨®ç‰¹å¾µï¼ˆELA/PRNUï¼‰çš„ç›®éŒ„\"\"\"\n",
    "    y = 0 if is_real_clip(p) else 1\n",
    "    key_bn = Path(p).name.lower(); key_st = Path(p).stem.lower()\n",
    "    idx = dir_idx_real if y==0 else dir_idx_fake\n",
    "    q = idx.get(key_bn) or idx.get(key_st)\n",
    "    return q, y\n",
    "\n",
    "def get_split_paths(name: str):\n",
    "    clp = SPLITS.get(name, [])\n",
    "    clip_paths = []; clip_y = []\n",
    "    ela_paths  = []; ela_y  = []; miss_ela=0\n",
    "    pr_paths   = []; pr_y   = []; miss_pr =0\n",
    "    for p in clp:\n",
    "        clip_paths.append(p); clip_y.append(0 if is_real_clip(p) else 1)\n",
    "        q1,y1 = map_to(IDX_ELA_REAL, IDX_ELA_FAKE, p)\n",
    "        if q1 is None: miss_ela += 1\n",
    "        else: ela_paths.append(q1); ela_y.append(y1)\n",
    "        q2,y2 = map_to(IDX_PR_REAL, IDX_PR_FAKE, p)\n",
    "        if q2 is None: miss_pr += 1\n",
    "        else: pr_paths.append(q2); pr_y.append(y2)\n",
    "    print(f\"[{name}] CLIP={len(clip_paths)} | ELA={len(ela_paths)}(miss {miss_ela}) | PRNU={len(pr_paths)}(miss {miss_pr})\")\n",
    "    return (clip_paths, np.array(clip_y,int),\n",
    "            ela_paths, np.array(ela_y,int),\n",
    "            pr_paths,  np.array(pr_y,int))\n",
    "\n",
    "(val_clip, yv_clip, val_ela, yv_ela, val_pr, yv_pr) = get_split_paths(\"val\")\n",
    "(ti_clip, yti_clip, ti_ela, yti_ela, ti_pr, yti_pr) = get_split_paths(\"test_iid\")\n",
    "(to_clip, yto_clip, to_ela, yto_ela, to_pr, yto_pr) = get_split_paths(\"test_ood\")\n",
    "\n",
    "assert len(val_clip)>0 and len(val_ela)>0 and len(val_pr)>0, \"Val split å°ä¸åˆ°ï¼ˆè«‹æª¢æŸ¥å‘½å/ç›®éŒ„ï¼‰\"\n",
    "assert (len(yv_clip)==len(yv_ela)==len(yv_pr)), \"Val æ¨™ç±¤é•·åº¦ä¸ä¸€è‡´ï¼Œè«‹æª¢æŸ¥ç´¢å¼•\"\n",
    "\n",
    "# ---------- CLIPï¼šè¼‰å…¥æœ€æ–° LinearSVCï¼ŒVal ä¸Šåš sigmoid æ ¡æº– ----------\n",
    "def latest_file(patterns):\n",
    "    cand=[]\n",
    "    for pat in (patterns if isinstance(patterns,(list,tuple)) else [patterns]):\n",
    "        cand += glob.glob(os.path.join(OUTPUT_DIR, pat))\n",
    "    assert cand, f\"æ‰¾ä¸åˆ°æ¨¡å‹ï¼š{patterns}\"\n",
    "    cand = sorted(cand, key=os.path.getmtime)\n",
    "    return cand[-1]\n",
    "\n",
    "CLIP_SVM_PATH = latest_file(\"clip_linear_svm_feature_*.joblib\")\n",
    "print(\"CLIP SVM:\", CLIP_SVM_PATH)\n",
    "svc = joblib.load(CLIP_SVM_PATH)\n",
    "\n",
    "def load_clip_vec(p):\n",
    "    v = np.asarray(np.load(p, allow_pickle=True)).astype(np.float32).reshape(-1)\n",
    "    n = np.linalg.norm(v) + 1e-12\n",
    "    return v / n\n",
    "\n",
    "def load_clip_matrix(paths):\n",
    "    X = np.stack([load_clip_vec(p) for p in tqdm(paths, desc=\"CLIP load\")], axis=0)\n",
    "    return X\n",
    "\n",
    "# æ ¡æº–ï¼ˆç”¨ Valï¼‰\n",
    "Xv_clip = load_clip_matrix(val_clip)\n",
    "cal_clip = CalibratedClassifierCV(svc, method=\"sigmoid\", cv=\"prefit\")\n",
    "cal_clip.fit(Xv_clip, yv_clip)  # åªå­¸æ ¡æº–åƒæ•¸\n",
    "\n",
    "# ---------- ELAï¼šæ¨¡å‹èˆ‡è®€æª” ----------\n",
    "def load_ela_array(path):\n",
    "    z = np.load(path, mmap_mode='r')\n",
    "    if isinstance(z, np.lib.npyio.NpzFile):\n",
    "        a = z.get('ela', z.get('arr', z.get('arr_0')))\n",
    "    else:\n",
    "        a = z\n",
    "    a = np.asarray(a)\n",
    "    if a.ndim == 2:\n",
    "        a = np.repeat(a[...,None], 3, axis=2)\n",
    "    elif a.ndim == 3 and a.shape[0] in (1,3) and a.shape[-1] not in (1,3):\n",
    "        a = np.transpose(a, (1,2,0))\n",
    "    elif a.ndim == 3 and a.shape[-1] == 1:\n",
    "        a = np.repeat(a, 3, axis=2)\n",
    "    a = a.astype(np.float32)\n",
    "    if a.max() > 1.5: a *= (1/255.0)\n",
    "    return a\n",
    "\n",
    "def zscore3(x):\n",
    "    m = x.mean(axis=(0,1), keepdims=True)\n",
    "    s = x.std(axis=(0,1), keepdims=True); s[s<1e-6]=1.0\n",
    "    return (x - m) / s\n",
    "\n",
    "def crop_hw3(img, size=256, center=True):\n",
    "    h,w,_ = img.shape\n",
    "    if h < size or w < size:\n",
    "        ph, pw = max(0,size-h), max(0,size-w)\n",
    "        img = np.pad(img, ((ph//2,ph-ph//2),(pw//2,pw-pw//2),(0,0)), mode='edge')\n",
    "        h,w,_ = img.shape\n",
    "    if center:\n",
    "        top=(h-size)//2; left=(w-size)//2\n",
    "    else:\n",
    "        top=0; left=0\n",
    "    return img[top:top+size, left:left+size, :].copy()\n",
    "\n",
    "class ELAForensicCNN(nn.Module):\n",
    "    def __init__(self,in_ch=3):\n",
    "        super().__init__()\n",
    "        def bnblk(ci,co): \n",
    "            return nn.Sequential(nn.Conv2d(ci,co,3,padding=1,bias=False), nn.BatchNorm2d(co), nn.ReLU(True))\n",
    "        def gnblk(ci,co,g=8):\n",
    "            return nn.Sequential(nn.Conv2d(ci,co,3,padding=1,bias=False), nn.GroupNorm(num_groups=min(g,co), num_channels=co), nn.ReLU(True))\n",
    "        self.net = nn.Sequential(\n",
    "            bnblk(in_ch,32), bnblk(32,32), nn.AvgPool2d(2),\n",
    "            bnblk(32,64),    bnblk(64,64), nn.AvgPool2d(2),\n",
    "            gnblk(64,128),   gnblk(128,128), nn.AvgPool2d(2),\n",
    "            gnblk(128,256),  gnblk(256,256), nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "        self.fc = nn.Linear(256,1)\n",
    "    def forward(self,x): return self.fc(self.net(x).flatten(1)).squeeze(1)\n",
    "\n",
    "ELA_MODEL_PATH = latest_file(\"ela_fromnpy_cnn_best_*.pt\")\n",
    "print(\"ELA model:\", ELA_MODEL_PATH)\n",
    "ela_model = ELAForensicCNN().to(device).eval()\n",
    "ela_model.load_state_dict(torch.load(ELA_MODEL_PATH, map_location=device), strict=True)\n",
    "\n",
    "@torch.no_grad()\n",
    "def ela_probs(paths, batch=128, size=256):\n",
    "    ps=[]\n",
    "    for i in tqdm(range(0, len(paths), batch), desc=\"ELA infer\"):\n",
    "        xs=[]\n",
    "        for p in paths[i:i+batch]:\n",
    "            a = load_ela_array(p)\n",
    "            a = crop_hw3(a, size=size, center=True)\n",
    "            a = zscore3(a)\n",
    "            xs.append(np.transpose(a,(2,0,1)))\n",
    "        t = torch.from_numpy(np.stack(xs,0)).to(device)\n",
    "        logit = ela_model(t.contiguous(memory_format=torch.channels_last))\n",
    "        ps.extend(torch.sigmoid(logit).float().cpu().numpy().tolist())\n",
    "    return np.array(ps)\n",
    "\n",
    "# ---------- PRNUï¼šæ¨¡å‹èˆ‡è®€æª”ï¼ˆint8ï¼‰ ----------\n",
    "def load_i8_2d(path):\n",
    "    a = np.load(path, mmap_mode='r')\n",
    "    a = np.asarray(a)\n",
    "    if a.ndim == 3 and (a.shape[0]==1 or a.shape[-1]==1):\n",
    "        a = a.squeeze()\n",
    "    assert a.ndim==2, f\"{path} got {a.shape}\"\n",
    "    return a.astype(np.float32)\n",
    "\n",
    "def per_image_norm(x):\n",
    "    m, s = x.mean(), x.std()\n",
    "    if not np.isfinite(s) or s<1e-6: s=20.0; m=0.0\n",
    "    return (x - m) / s\n",
    "\n",
    "def avg_pool_2x(x):\n",
    "    H,W = x.shape; H2,W2 = H//2*2, W//2*2\n",
    "    x = x[:H2,:W2].reshape(H2//2,2,W2//2,2).mean(axis=(1,3))\n",
    "    return x\n",
    "\n",
    "def crop_2d(img, size=256, center=True):\n",
    "    h,w = img.shape\n",
    "    if h < size or w < size:\n",
    "        ph,pw = max(0,size-h), max(0,size-w)\n",
    "        img = np.pad(img, ((ph//2,ph-ph//2),(pw//2,pw-pw//2)), mode='edge')\n",
    "        h,w = img.shape\n",
    "    if center:\n",
    "        y0=(h-size)//2; x0=(w-size)//2\n",
    "    else:\n",
    "        y0=0; x0=0\n",
    "    return img[y0:y0+size, x0:x0+size].copy()\n",
    "\n",
    "class SmallForensicCNN(nn.Module):\n",
    "    def __init__(self,in_ch=1):\n",
    "        super().__init__()\n",
    "        def blk(ci,co,g=8):\n",
    "            return nn.Sequential(nn.Conv2d(ci,co,3,padding=1,bias=False),\n",
    "                                 nn.GroupNorm(num_groups=min(g,co), num_channels=co),\n",
    "                                 nn.ReLU(True))\n",
    "        self.net = nn.Sequential(\n",
    "            blk(in_ch,32), blk(32,32), nn.AvgPool2d(2),\n",
    "            blk(32,64),    blk(64,64), nn.AvgPool2d(2),\n",
    "            blk(64,128),   blk(128,128), nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "        self.fc = nn.Linear(128,1)\n",
    "    def forward(self,x): return self.fc(self.net(x).flatten(1)).squeeze(1)\n",
    "\n",
    "PRNU_MODEL_PATH = latest_file([\"prnu_cnn_i8_best_*.pt\",\"prnu_fromnpy_cnn_best_*.pt\"])\n",
    "print(\"PRNU model:\", PRNU_MODEL_PATH)\n",
    "pr_model = SmallForensicCNN(1).to(device).eval()\n",
    "pr_model.load_state_dict(torch.load(PRNU_MODEL_PATH, map_location=device), strict=True)\n",
    "\n",
    "@torch.no_grad()\n",
    "def prnu_probs(paths, batch=128, size=256, downsample=True):\n",
    "    ps=[]\n",
    "    for i in tqdm(range(0, len(paths), batch), desc=\"PRNU infer\"):\n",
    "        xs=[]\n",
    "        for p in paths[i:i+batch]:\n",
    "            w = load_i8_2d(p)                 # int8â†’float32\n",
    "            if downsample and (w.shape[0]>=512 and w.shape[1]>=512):\n",
    "                w = avg_pool_2x(w)\n",
    "            w = crop_2d(w, size=size, center=True)\n",
    "            w = per_image_norm(w)\n",
    "            xs.append(w[None,...])\n",
    "        t = torch.from_numpy(np.stack(xs,0)).to(device)\n",
    "        logit = pr_model(t.contiguous(memory_format=torch.channels_last))\n",
    "        ps.extend(torch.sigmoid(logit).float().cpu().numpy().tolist())\n",
    "    return np.array(ps)\n",
    "\n",
    "# ---------- å–å¾—ä¸‰è·¯æ©Ÿç‡ ----------\n",
    "# Val\n",
    "pv_clip = cal_clip.predict_proba(Xv_clip)[:,1]\n",
    "pv_ela  = ela_probs(val_ela)\n",
    "pv_pr   = prnu_probs(val_pr)\n",
    "assert len(pv_clip)==len(pv_ela)==len(pv_pr)==len(yv_clip)\n",
    "\n",
    "# Test-IID\n",
    "Xi_clip = load_clip_matrix(ti_clip) if len(ti_clip) else np.zeros((0, Xv_clip.shape[1]), np.float32)\n",
    "pi_clip = cal_clip.predict_proba(Xi_clip)[:,1] if len(ti_clip) else np.array([])\n",
    "pi_ela  = ela_probs(ti_ela) if len(ti_ela) else np.array([])\n",
    "pi_pr   = prnu_probs(ti_pr) if len(ti_pr) else np.array([])\n",
    "\n",
    "# Test-OOD\n",
    "Xo_clip = load_clip_matrix(to_clip) if len(to_clip) else np.zeros((0, Xv_clip.shape[1]), np.float32)\n",
    "po_clip = cal_clip.predict_proba(Xo_clip)[:,1] if len(to_clip) else np.array([])\n",
    "po_ela  = ela_probs(to_ela) if len(to_ela) else np.array([])\n",
    "po_pr   = prnu_probs(to_pr) if len(to_pr) else np.array([])\n",
    "\n",
    "# ---------- èåˆå™¨ï¼ˆåœ¨ Val ä¸Šå­¸ï¼‰ ----------\n",
    "def stack_feats(p1,p2,p3): \n",
    "    return np.stack([p1,p2,p3], axis=1).astype(np.float32)\n",
    "Xv = stack_feats(pv_clip, pv_ela, pv_pr); yv = yv_clip\n",
    "Xi = stack_feats(pi_clip, pi_ela, pi_pr) if len(pi_clip) else None\n",
    "Xo = stack_feats(po_clip, po_ela, po_pr) if len(po_clip) else None\n",
    "\n",
    "fuser = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
    "fuser.fit(Xv, yv)\n",
    "print(\"Fusion weights:\", fuser.coef_, \"bias:\", fuser.intercept_)\n",
    "\n",
    "def eval_block(name, X, y):\n",
    "    if X is None or len(X)==0:\n",
    "        print(f\"[{name}] (empty)\"); return None\n",
    "    proba = fuser.predict_proba(X)[:,1]\n",
    "    auc = roc_auc_score(y, proba)\n",
    "    # Youden é–€æª»ï¼ˆç”¨ Val çš„ï¼‰\n",
    "    return proba, auc\n",
    "\n",
    "# ä»¥ Val æ‰¾å…©å€‹é–€æª»\n",
    "p_val_fused, auc_val = eval_block(\"Val\", Xv, yv)\n",
    "fpr, tpr, thr = roc_curve(yv, p_val_fused)\n",
    "thr_youden = float(thr[(tpr - fpr).argmax()])\n",
    "idx = np.where(fpr <= 0.05)[0]\n",
    "thr_fpr05 = float(thr[idx[-1]]) if len(idx) else float(thr[0])\n",
    "print(f\"[Val Fused] AUC={auc_val:.4f} | thr_youden={thr_youden:.3f} | thr_fpr@5%={thr_fpr05:.3f}\")\n",
    "\n",
    "def report(name, X, y, thr):\n",
    "    if X is None or len(X)==0:\n",
    "        print(f\"[{name}] (empty)\"); return\n",
    "    p = fuser.predict_proba(X)[:,1]\n",
    "    pred = (p >= thr).astype(int)\n",
    "    acc = accuracy_score(y, pred)\n",
    "    try: auc = roc_auc_score(y, p)\n",
    "    except: auc = float(\"nan\")\n",
    "    print(f\"\\n[{name}] acc@thr={acc:.4f} | auc={auc:.4f} | thr={thr:.3f}\")\n",
    "    print(confusion_matrix(y, pred))\n",
    "    print(classification_report(y, pred, digits=4))\n",
    "\n",
    "# å ±å‘Šï¼ˆYouden èˆ‡ FPR@5%ï¼‰\n",
    "report(\"Val (Youden)\", Xv, yv, thr_youden)\n",
    "if Xi is not None: report(\"Test-IID (Youden)\", Xi, yti_clip, thr_youden)\n",
    "if Xo is not None: report(\"Test-OOD (Youden)\", Xo, yto_clip, thr_youden)\n",
    "\n",
    "report(\"Val (FPR@5%)\", Xv, yv, thr_fpr05)\n",
    "if Xi is not None: report(\"Test-IID (FPR@5%)\", Xi, yti_clip, thr_fpr05)\n",
    "if Xo is not None: report(\"Test-OOD (FPR@5%)\", Xo, yto_clip, thr_fpr05)\n",
    "\n",
    "# ---------- OOD åˆ†ä¾†æºï¼ˆç”¨ FPR@5% é–€æª»ï¼‰ ----------\n",
    "def tag_from_path(p: str, y: int):\n",
    "    s = Path(p).as_posix().lower()\n",
    "    if y==0:\n",
    "        return \"unsplash\" if \"unsplash\" in s else (\"imagenet\" if \"imagenet\" in s else \"real\")\n",
    "    for k in [\"dalle3\",\"midjourney\",\"sd3\",\"flux\",\"stable\",\"sdxl\",\"playground\",\"kolors\"]:\n",
    "        if k in s: return k\n",
    "    # å¾æª”åé¦–æ®µçŒœ\n",
    "    stem = Path(p).stem.lower().split(\"_\")[0].split(\"-\")[0]\n",
    "    return stem or \"fake\"\n",
    "\n",
    "def ood_breakdown(thr):\n",
    "    if Xo is None: \n",
    "        print(\"\\n[OOD breakdown] (empty)\"); return\n",
    "    p = fuser.predict_proba(Xo)[:,1]; y = yto_clip\n",
    "    # ç”¨ CLIP split çš„åŸå§‹è·¯å¾‘ä¾†æŠ“æ¨™ç±¤ï¼ˆtagï¼‰\n",
    "    tags = [tag_from_path(pp, yy) for pp,yy in zip(to_clip,y)]\n",
    "    buckets = {}\n",
    "    for yy,pp,tag in zip(y,p,tags):\n",
    "        buckets.setdefault(tag, []).append((yy,pp))\n",
    "    print(\"\\n== OOD per-dataset ==\")\n",
    "    for tag, lst in sorted(buckets.items(), key=lambda kv: -len(kv[1])):\n",
    "        arr_y = np.array([a for a,_ in lst]); arr_p = np.array([b for _,b in lst])\n",
    "        try: auc = roc_auc_score(arr_y, arr_p)\n",
    "        except: auc = float(\"nan\")\n",
    "        pred = (arr_p >= thr).astype(int)\n",
    "        acc = (pred==arr_y).mean()\n",
    "        cm  = confusion_matrix(arr_y, pred)\n",
    "        print(f\"- {tag:10s} n={len(arr_y):5d} | acc={acc:.4f} | auc={auc:.4f}\\n{cm}\\n\")\n",
    "\n",
    "print(\"\\n[OOD breakdown @ FPR@5%]\")\n",
    "ood_breakdown(thr_fpr05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27265c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Val (Youden, ELA+PRNU)] acc=0.9353 | auc=0.9729 | thr=0.467\n",
      "[[ 5708   292]\n",
      " [  873 11127]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8673    0.9513    0.9074      6000\n",
      "           1     0.9744    0.9273    0.9503     12000\n",
      "\n",
      "    accuracy                         0.9353     18000\n",
      "   macro avg     0.9209    0.9393    0.9288     18000\n",
      "weighted avg     0.9387    0.9353    0.9360     18000\n",
      "\n",
      "\n",
      "[Test-IID (Youden, ELA+PRNU)] acc=0.9382 | auc=0.9753 | thr=0.467\n",
      "[[ 5714   286]\n",
      " [  827 11173]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8736    0.9523    0.9113      6000\n",
      "           1     0.9750    0.9311    0.9526     12000\n",
      "\n",
      "    accuracy                         0.9382     18000\n",
      "   macro avg     0.9243    0.9417    0.9319     18000\n",
      "weighted avg     0.9412    0.9382    0.9388     18000\n",
      "\n",
      "\n",
      "[Test-OOD (Youden, ELA+PRNU)] acc=0.7845 | auc=0.8802 | thr=0.467\n",
      "[[19791  5198]\n",
      " [ 4283 14717]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8221    0.7920    0.8068     24989\n",
      "           1     0.7390    0.7746    0.7564     19000\n",
      "\n",
      "    accuracy                         0.7845     43989\n",
      "   macro avg     0.7805    0.7833    0.7816     43989\n",
      "weighted avg     0.7862    0.7845    0.7850     43989\n",
      "\n",
      "\n",
      "[Val (FPR@5%, ELA+PRNU)] acc=0.9355 | auc=0.9729 | thr=0.457\n",
      "[[ 5703   297]\n",
      " [  864 11136]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8684    0.9505    0.9076      6000\n",
      "           1     0.9740    0.9280    0.9505     12000\n",
      "\n",
      "    accuracy                         0.9355     18000\n",
      "   macro avg     0.9212    0.9393    0.9290     18000\n",
      "weighted avg     0.9388    0.9355    0.9362     18000\n",
      "\n",
      "\n",
      "[Test-IID (FPR@5%, ELA+PRNU)] acc=0.9384 | auc=0.9753 | thr=0.457\n",
      "[[ 5710   290]\n",
      " [  818 11182]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8747    0.9517    0.9116      6000\n",
      "           1     0.9747    0.9318    0.9528     12000\n",
      "\n",
      "    accuracy                         0.9384     18000\n",
      "   macro avg     0.9247    0.9417    0.9322     18000\n",
      "weighted avg     0.9414    0.9384    0.9390     18000\n",
      "\n",
      "\n",
      "[Test-OOD (FPR@5%, ELA+PRNU)] acc=0.7841 | auc=0.8802 | thr=0.457\n",
      "[[19730  5259]\n",
      " [ 4237 14763]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8232    0.7895    0.8060     24989\n",
      "           1     0.7373    0.7770    0.7567     19000\n",
      "\n",
      "    accuracy                         0.7841     43989\n",
      "   macro avg     0.7803    0.7833    0.7813     43989\n",
      "weighted avg     0.7861    0.7841    0.7847     43989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# åªç”¨ ELA+PRNU åœ¨ Val è¨“ç·´èåˆå™¨ï¼Œç„¶å¾Œè©•ä¼°\n",
    "Xv_2 = np.stack([pv_ela, pv_pr], axis=1).astype(np.float32); yv_2 = yv\n",
    "Xi_2 = np.stack([pi_ela, pi_pr], axis=1).astype(np.float32) if len(pi_ela) else None\n",
    "Xo_2 = np.stack([po_ela, po_pr], axis=1).astype(np.float32) if len(po_ela) else None\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "fuser_2 = LogisticRegression(max_iter=1000, class_weight=\"balanced\", C=0.5)\n",
    "fuser_2.fit(Xv_2, yv_2)\n",
    "\n",
    "p_val_2 = fuser_2.predict_proba(Xv_2)[:,1]\n",
    "fpr,tpr,thr = roc_curve(yv_2, p_val_2)\n",
    "thr_y_2 = float(thr[(tpr-fpr).argmax()])\n",
    "idx = np.where(fpr<=0.05)[0]; thr_f05_2 = float(thr[idx[-1]]) if len(idx) else float(thr[0])\n",
    "\n",
    "def report(name, X, y, thr):\n",
    "    if X is None: print(f\"[{name}] empty\"); return\n",
    "    p = fuser_2.predict_proba(X)[:,1]\n",
    "    pred = (p>=thr).astype(int)\n",
    "    print(f\"\\n[{name}] acc={ (pred==y).mean():.4f} | auc={roc_auc_score(y,p):.4f} | thr={thr:.3f}\")\n",
    "    print(confusion_matrix(y, pred))\n",
    "    print(classification_report(y, pred, digits=4))\n",
    "\n",
    "report(\"Val (Youden, ELA+PRNU)\", Xv_2, yv_2, thr_y_2)\n",
    "if Xi_2 is not None: report(\"Test-IID (Youden, ELA+PRNU)\", Xi_2, yti_clip, thr_y_2)\n",
    "if Xo_2 is not None: report(\"Test-OOD (Youden, ELA+PRNU)\", Xo_2, yto_clip, thr_y_2)\n",
    "\n",
    "report(\"Val (FPR@5%, ELA+PRNU)\", Xv_2, yv_2, thr_f05_2)\n",
    "if Xi_2 is not None: report(\"Test-IID (FPR@5%, ELA+PRNU)\", Xi_2, yti_clip, thr_f05_2)\n",
    "if Xo_2 is not None: report(\"Test-OOD (FPR@5%, ELA+PRNU)\", Xo_2, yto_clip, thr_f05_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b1e0641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Test-OOD (Youden, cost-sensitive)] acc=0.4814 | auc=0.8844 | thr=0.639\n",
      "[[ 2198 22791]\n",
      " [   21 18979]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9905    0.0880    0.1616     24989\n",
      "           1     0.4544    0.9989    0.6246     19000\n",
      "\n",
      "    accuracy                         0.4814     43989\n",
      "   macro avg     0.7225    0.5434    0.3931     43989\n",
      "weighted avg     0.7590    0.4814    0.3616     43989\n",
      "\n",
      "\n",
      "[Test-OOD (FPR@5%, cost-sensitive)] acc=0.4517 | auc=0.8844 | thr=0.072\n",
      "[[  871 24118]\n",
      " [    0 19000]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0349    0.0674     24989\n",
      "           1     0.4407    1.0000    0.6117     19000\n",
      "\n",
      "    accuracy                         0.4517     43989\n",
      "   macro avg     0.7203    0.5174    0.3396     43989\n",
      "weighted avg     0.7584    0.4517    0.3025     43989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ä»¥ Val çš„çœŸå¯¦é¡åŠ æ¬Šï¼ˆæ¬Šé‡å¯å¾ 2~5 è©¦ï¼‰\n",
    "w = np.where(yv==0, 3.0, 1.0).astype(np.float32)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "fuser_cs = LogisticRegression(max_iter=1000, C=0.5)  # å¯å†å°ä¸€é»æ›´ä¿å®ˆ\n",
    "fuser_cs.fit(np.stack([pv_clip,pv_ela,pv_pr],1), yv, sample_weight=w)\n",
    "\n",
    "# é–€æª»æ²¿ç”¨ Val ROC\n",
    "from sklearn.metrics import roc_curve\n",
    "p_val_cs = fuser_cs.predict_proba(np.stack([pv_clip,pv_ela,pv_pr],1))[:,1]\n",
    "fpr,tpr,thr = roc_curve(yv, p_val_cs)\n",
    "thr_y_cs = float(thr[(tpr-fpr).argmax()])\n",
    "idx = np.where(fpr<=0.05)[0]; thr_f05_cs = float(thr[idx[-1]]) if len(idx) else float(thr[0])\n",
    "\n",
    "def report_cs(name, X, y, thr):\n",
    "    if X is None: print(f\"[{name}] empty\"); return\n",
    "    p = fuser_cs.predict_proba(X)[:,1]; pred=(p>=thr).astype(int)\n",
    "    from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, classification_report\n",
    "    print(f\"\\n[{name}] acc={ (pred==y).mean():.4f} | auc={roc_auc_score(y,p):.4f} | thr={thr:.3f}\")\n",
    "    print(confusion_matrix(y, pred)); print(classification_report(y, pred, digits=4))\n",
    "\n",
    "Xi = np.stack([pi_clip,pi_ela,pi_pr],1) if len(pi_clip) else None\n",
    "Xo = np.stack([po_clip,po_ela,po_pr],1) if len(po_clip) else None\n",
    "report_cs(\"Test-OOD (Youden, cost-sensitive)\", Xo, yto_clip, thr_y_cs)\n",
    "report_cs(\"Test-OOD (FPR@5%, cost-sensitive)\", Xo, yto_clip, thr_f05_cs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "835a3754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å°‡æ”¹å 2700 å€‹æª”æ¡ˆï¼›å”¯ä¸€å½±åƒæ•¸ 900ï¼›é›¶å¡«ä½æ•¸ 4ã€‚\n",
      "ğŸ“ å°ç…§è¡¨å·²è¼¸å‡ºï¼š /home/yaya/ai-detect-proj/Script/features_npy/DIV2K_rename_map_4d.csv\n",
      "âœ… å·²å®Œæˆæ”¹åã€‚\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# Rename DIV2K npy â†’ \"DIV2K__000001.npy\" (consistent across features)\n",
    "# ======================================================\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "# ---- è¨­å®š ----\n",
    "OUT_ROOT = Path(\"/home/yaya/ai-detect-proj/Script/features_npy\")  # ä½ çš„ç‰¹å¾µè¼¸å‡ºæ ¹ç›®éŒ„\n",
    "NEW_PREFIX = \"DIV2K\"                      # æ–°æª”åå‰ç¶´\n",
    "MATCH_PREFIXES = (\"DIV2K\", \"DIV2K_HR\")    # è¦–ç‚º DIV2K çš„èˆŠå‰ç¶´\n",
    "DRY_RUN = False                           # True=åªé è¦½ä¸æ”¹å\n",
    "START_INDEX = 1                           # ç·¨è™Ÿèµ·å§‹ï¼ˆé€šå¸¸ 1ï¼‰\n",
    "PAD_WIDTH = None                          # None=è‡ªå‹•ï¼›æˆ–æ‰‹å‹•çµ¦ 6 â†’ 000001\n",
    "\n",
    "# ---- æ”¶é›†ç›®æ¨™æª”æ¡ˆï¼ˆåƒ…é™ *_npy è³‡æ–™å¤¾ï¼‰----\n",
    "assert OUT_ROOT.exists(), f\"æ‰¾ä¸åˆ°ç›®éŒ„ï¼š{OUT_ROOT}\"\n",
    "all_npy = [p for p in OUT_ROOT.rglob(\"*.npy\") if p.parent.name.endswith(\"_npy\")]\n",
    "\n",
    "def is_div2k_stem(stem: str) -> bool:\n",
    "    up = stem.upper()\n",
    "    return any(up.startswith(pref.upper()) for pref in MATCH_PREFIXES)\n",
    "\n",
    "target_files = [p for p in all_npy if is_div2k_stem(p.stem)]\n",
    "if not target_files:\n",
    "    raise SystemExit(\"åœ¨ features_npy ä¸­æ‰¾ä¸åˆ° DIV2K ç›¸é—œçš„ .npy æª”ï¼›è«‹ç¢ºèª MATCH_PREFIXES æˆ–è·¯å¾‘ã€‚\")\n",
    "\n",
    "# ---- å»ºç«‹ã€ŒèˆŠstem â†’ æ–°stemã€çš„ç·¨è™Ÿæ˜ å°„ï¼ˆè·¨ç‰¹å¾µä¸€è‡´ï¼‰----\n",
    "unique_stems = sorted({p.stem for p in target_files})\n",
    "total = len(unique_stems)\n",
    "pad = PAD_WIDTH or max(4, len(str(total)))\n",
    "mapping = {\n",
    "    stem: f\"{NEW_PREFIX}__{idx:0{pad}d}\"\n",
    "    for idx, stem in enumerate(unique_stems, start=START_INDEX)\n",
    "}\n",
    "\n",
    "# ---- è¦åŠƒæ”¹å & æª¢æŸ¥è¡çª ----\n",
    "plan = []\n",
    "conflicts = []\n",
    "for src in target_files:\n",
    "    new_stem = mapping[src.stem]\n",
    "    dst = src.with_name(new_stem + src.suffix)\n",
    "    plan.append((src, dst))\n",
    "    if dst.exists() and dst != src:\n",
    "        conflicts.append((src, dst))\n",
    "\n",
    "print(f\"å°‡æ”¹å {len(plan)} å€‹æª”æ¡ˆï¼›å”¯ä¸€å½±åƒæ•¸ {len(unique_stems)}ï¼›é›¶å¡«ä½æ•¸ {pad}ã€‚\")\n",
    "if conflicts:\n",
    "    print(\"âš ï¸ åµæ¸¬åˆ°æœƒè¦†è“‹æ—¢æœ‰æª”æ¡ˆï¼Œç‚ºå®‰å…¨èµ·è¦‹å…ˆä¸­æ­¢ã€‚è¡çªç¯„ä¾‹ï¼š\")\n",
    "    for s, d in conflicts[:10]:\n",
    "        print(\" -\", d)\n",
    "    raise SystemExit(\"è«‹å…ˆè™•ç†è¡çªæˆ–èª¿æ•´ MATCH_PREFIXESã€‚\")\n",
    "\n",
    "# ---- è¼¸å‡ºå°ç…§è¡¨ CSVï¼ˆå¯ç”¨ä¾†å›å¾©èˆŠåï¼‰----\n",
    "map_csv = OUT_ROOT / f\"DIV2K_rename_map_{pad}d.csv\"\n",
    "with open(map_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"old_path\",\"new_path\",\"old_stem\",\"new_stem\"])\n",
    "    for s, d in plan:\n",
    "        w.writerow([str(s), str(d), s.stem, d.stem])\n",
    "print(\"ğŸ“ å°ç…§è¡¨å·²è¼¸å‡ºï¼š\", map_csv)\n",
    "\n",
    "# ---- åŸ·è¡Œæ”¹å ----\n",
    "if not DRY_RUN:\n",
    "    for s, d in plan:\n",
    "        s.rename(d)\n",
    "    print(\"âœ… å·²å®Œæˆæ”¹åã€‚\")\n",
    "else:\n",
    "    print(\"ï¼ˆDRY_RUN=True åƒ…é è¦½ï¼Œæœªå¯¦éš›æ”¹åï¼‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3929b5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å°‡æ”¹å 26355 å€‹æª”æ¡ˆï¼›å”¯ä¸€å½±åƒæ•¸ 8785ï¼›é›¶å¡«ä½æ•¸ 4ã€‚\n",
      "ğŸ“ å°ç…§è¡¨å·²è¼¸å‡ºï¼š /home/yaya/ai-detect-proj/Script/features_npy/COCO2017_rename_map_4d.csv\n",
      "âœ… å·²å®Œæˆæ”¹åã€‚\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# Rename COCO2017 npy â†’ \"COCO2017__000001.npy\"ï¼ˆè·¨ç‰¹å¾µå…±äº«ç·¨è™Ÿï¼‰\n",
    "# ======================================================\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "# ---- è¨­å®š ----\n",
    "OUT_ROOT = Path(\"/home/yaya/ai-detect-proj/Script/features_npy\")   # ä½ çš„ç‰¹å¾µè¼¸å‡ºæ ¹ç›®éŒ„\n",
    "NEW_PREFIX = \"COCO2017\"                    # æ–°æª”åå‰ç¶´\n",
    "# ä½ çš„ç”¢ç”Ÿå™¨ä»¥å‰å¤§å¤šæœƒç”¨åˆ°é€™äº›å‰ç¶´ï¼ˆå¯è¦–éœ€è¦å¢æ¸›ï¼‰\n",
    "MATCH_PREFIXES = (\"coco2017_ge512\", \"coco_ge512\", \"coco2017\", \"COCO2017\")\n",
    "DRY_RUN = False                            # True=åªé è¦½ä¸æ”¹å\n",
    "START_INDEX = 1                            # ç·¨è™Ÿèµ·å§‹\n",
    "PAD_WIDTH = None                           # None=è‡ªå‹•ä½æ•¸ï¼›æˆ–æ‰‹å‹•çµ¦ 6 â†’ 000001\n",
    "\n",
    "# ---- æ”¶é›†ç›®æ¨™æª”æ¡ˆï¼ˆåƒ…é™ *_npy è³‡æ–™å¤¾ï¼‰----\n",
    "assert OUT_ROOT.exists(), f\"æ‰¾ä¸åˆ°ç›®éŒ„ï¼š{OUT_ROOT}\"\n",
    "all_npy = [p for p in OUT_ROOT.rglob(\"*.npy\") if p.parent.name.endswith(\"_npy\")]\n",
    "\n",
    "def is_coco_stem(stem: str) -> bool:\n",
    "    up = stem.upper()\n",
    "    return any(up.startswith(pref.upper()) for pref in MATCH_PREFIXES)\n",
    "\n",
    "target_files = [p for p in all_npy if is_coco_stem(p.stem)]\n",
    "if not target_files:\n",
    "    raise SystemExit(\"åœ¨ features_npy ä¸­æ‰¾ä¸åˆ° COCO2017 ç›¸é—œçš„ .npyï¼›è«‹ç¢ºèª MATCH_PREFIXES æˆ–è·¯å¾‘ã€‚\")\n",
    "\n",
    "# ---- å»ºç«‹ã€ŒèˆŠ stem â†’ æ–° stemã€çš„æ˜ å°„ï¼ˆè·¨ç‰¹å¾µä¸€è‡´ï¼‰----\n",
    "unique_stems = sorted({p.stem for p in target_files})\n",
    "total = len(unique_stems)\n",
    "pad = PAD_WIDTH or max(4, len(str(total)))\n",
    "mapping = {\n",
    "    stem: f\"{NEW_PREFIX}__{idx:0{pad}d}\"\n",
    "    for idx, stem in enumerate(unique_stems, start=START_INDEX)\n",
    "}\n",
    "\n",
    "# ---- è¦åŠƒæ”¹å & æª¢æŸ¥è¡çª ----\n",
    "plan, conflicts = [], []\n",
    "for src in target_files:\n",
    "    new_stem = mapping[src.stem]\n",
    "    dst = src.with_name(new_stem + src.suffix)\n",
    "    plan.append((src, dst))\n",
    "    if dst.exists() and dst != src:\n",
    "        conflicts.append((src, dst))\n",
    "\n",
    "print(f\"å°‡æ”¹å {len(plan)} å€‹æª”æ¡ˆï¼›å”¯ä¸€å½±åƒæ•¸ {len(unique_stems)}ï¼›é›¶å¡«ä½æ•¸ {pad}ã€‚\")\n",
    "if conflicts:\n",
    "    print(\"âš ï¸ åµæ¸¬åˆ°å°‡è¦†è“‹æ—¢æœ‰æª”æ¡ˆï¼Œç‚ºå®‰å…¨èµ·è¦‹å…ˆä¸­æ­¢ã€‚è¡çªç¯„ä¾‹ï¼š\")\n",
    "    for s, d in conflicts[:10]:\n",
    "        print(\" -\", d)\n",
    "    raise SystemExit(\"è«‹å…ˆè™•ç†è¡çªæˆ–èª¿æ•´ MATCH_PREFIXESã€‚\")\n",
    "\n",
    "# ---- è¼¸å‡ºå°ç…§è¡¨ CSVï¼ˆå¯æ‹¿ä¾†å›å¾©èˆŠåï¼‰----\n",
    "map_csv = OUT_ROOT / f\"COCO2017_rename_map_{pad}d.csv\"\n",
    "with open(map_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"old_path\",\"new_path\",\"old_stem\",\"new_stem\"])\n",
    "    for s, d in plan:\n",
    "        w.writerow([str(s), str(d), s.stem, d.stem])\n",
    "print(\"ğŸ“ å°ç…§è¡¨å·²è¼¸å‡ºï¼š\", map_csv)\n",
    "\n",
    "# ---- åŸ·è¡Œæ”¹å ----\n",
    "if not DRY_RUN:\n",
    "    for s, d in plan:\n",
    "        s.rename(d)\n",
    "    print(\"âœ… å·²å®Œæˆæ”¹åã€‚\")\n",
    "else:\n",
    "    print(\"ï¼ˆDRY_RUN=True åƒ…é è¦½ï¼Œæœªå¯¦éš›æ”¹åï¼‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18297f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å°‡æ”¹å 45000 å€‹æª”æ¡ˆï¼›å”¯ä¸€å½±åƒæ•¸ 15000ï¼›é›¶å¡«ä½æ•¸ 5ã€‚\n",
      "ğŸ“ å°ç…§è¡¨å·²è¼¸å‡ºï¼š /home/yaya/ai-detect-proj/Script/features_npy/PLACES365_rename_map_5d.csv\n",
      "âœ… å·²å®Œæˆæ”¹åã€‚\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# Rename Places365 npy â†’ \"PLACES365__000001.npy\"ï¼ˆè·¨ç‰¹å¾µå…±äº«ç·¨è™Ÿï¼‰\n",
    "# ======================================================\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "# ---- è¨­å®š ----\n",
    "OUT_ROOT = Path(\"/home/yaya/ai-detect-proj/Script/features_npy\")   # ä½ çš„ç‰¹å¾µè¼¸å‡ºæ ¹ç›®éŒ„\n",
    "NEW_PREFIX = \"PLACES365\"                   # æ–°æª”åå‰ç¶´\n",
    "# ä¾ä½ å‰é¢å…©ç¨® Places ç”¢ç”Ÿå™¨çš„å‰ç¶´åšåŒ¹é…ï¼ˆå¯è‡ªè¡Œå¢æ¸›ï¼‰\n",
    "MATCH_PREFIXES = (\n",
    "    \"Places365_valHR_15k_gt512\",\n",
    "    \"Places365_val256_15k\",\n",
    "    \"Places365\",\n",
    "    \"PLACES365\",\n",
    ")\n",
    "DRY_RUN = False                            # True=åªé è¦½ä¸æ”¹å\n",
    "START_INDEX = 1                            # ç·¨è™Ÿèµ·å§‹\n",
    "PAD_WIDTH = None                           # None=è‡ªå‹•ä½æ•¸ï¼›æˆ–æ‰‹å‹•çµ¦ 6 â†’ 000001\n",
    "\n",
    "# ---- æ”¶é›†ç›®æ¨™æª”æ¡ˆï¼ˆåƒ…é™ *_npy è³‡æ–™å¤¾ï¼‰----\n",
    "assert OUT_ROOT.exists(), f\"æ‰¾ä¸åˆ°ç›®éŒ„ï¼š{OUT_ROOT}\"\n",
    "all_npy = [p for p in OUT_ROOT.rglob(\"*.npy\") if p.parent.name.endswith(\"_npy\")]\n",
    "\n",
    "def is_places_stem(stem: str) -> bool:\n",
    "    up = stem.upper()\n",
    "    return any(up.startswith(pref.upper()) for pref in MATCH_PREFIXES)\n",
    "\n",
    "target_files = [p for p in all_npy if is_places_stem(p.stem)]\n",
    "if not target_files:\n",
    "    raise SystemExit(\"åœ¨ features_npy ä¸­æ‰¾ä¸åˆ° Places365 ç›¸é—œçš„ .npyï¼›è«‹ç¢ºèª MATCH_PREFIXES æˆ–è·¯å¾‘ã€‚\")\n",
    "\n",
    "# ---- å»ºç«‹ã€ŒèˆŠ stem â†’ æ–° stemã€çš„æ˜ å°„ï¼ˆè·¨ç‰¹å¾µä¸€è‡´ï¼‰----\n",
    "unique_stems = sorted({p.stem for p in target_files})\n",
    "total = len(unique_stems)\n",
    "pad = PAD_WIDTH or max(4, len(str(total)))\n",
    "mapping = {\n",
    "    stem: f\"{NEW_PREFIX}__{idx:0{pad}d}\"\n",
    "    for idx, stem in enumerate(unique_stems, start=START_INDEX)\n",
    "}\n",
    "\n",
    "# ---- è¦åŠƒæ”¹å & æª¢æŸ¥è¡çª ----\n",
    "plan, conflicts = [], []\n",
    "for src in target_files:\n",
    "    new_stem = mapping[src.stem]\n",
    "    dst = src.with_name(new_stem + src.suffix)\n",
    "    plan.append((src, dst))\n",
    "    if dst.exists() and dst != src:\n",
    "        conflicts.append((src, dst))\n",
    "\n",
    "print(f\"å°‡æ”¹å {len(plan)} å€‹æª”æ¡ˆï¼›å”¯ä¸€å½±åƒæ•¸ {len(unique_stems)}ï¼›é›¶å¡«ä½æ•¸ {pad}ã€‚\")\n",
    "if conflicts:\n",
    "    print(\"âš ï¸ åµæ¸¬åˆ°å°‡è¦†è“‹æ—¢æœ‰æª”æ¡ˆï¼Œç‚ºå®‰å…¨èµ·è¦‹å…ˆä¸­æ­¢ã€‚è¡çªç¯„ä¾‹ï¼š\")\n",
    "    for s, d in conflicts[:10]:\n",
    "        print(\" -\", d)\n",
    "    raise SystemExit(\"è«‹å…ˆè™•ç†è¡çªæˆ–èª¿æ•´ MATCH_PREFIXESã€‚\")\n",
    "\n",
    "# ---- è¼¸å‡ºå°ç…§è¡¨ CSVï¼ˆå¯æ‹¿ä¾†å›å¾©èˆŠåï¼‰----\n",
    "map_csv = OUT_ROOT / f\"PLACES365_rename_map_{pad}d.csv\"\n",
    "with open(map_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"old_path\",\"new_path\",\"old_stem\",\"new_stem\"])\n",
    "    for s, d in plan:\n",
    "        w.writerow([str(s), str(d), s.stem, d.stem])\n",
    "print(\"ğŸ“ å°ç…§è¡¨å·²è¼¸å‡ºï¼š\", map_csv)\n",
    "\n",
    "# ---- åŸ·è¡Œæ”¹å ----\n",
    "if not DRY_RUN:\n",
    "    for s, d in plan:\n",
    "        s.rename(d)\n",
    "    print(\"âœ… å·²å®Œæˆæ”¹åã€‚\")\n",
    "else:\n",
    "    print(\"ï¼ˆDRY_RUN=True åƒ…é è¦½ï¼Œæœªå¯¦éš›æ”¹åï¼‰\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgfeat (PyTorch)",
   "language": "python",
   "name": "imgfeat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
