{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1a347b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yaya/miniforge3/envs/imgfeat/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CLIP (ViT-L/14) → Linear SVM\n",
    "# 支援兩種來源：\n",
    "#  1) 每個 .npy = 一張圖片 (HxW或HxWx3)\n",
    "#  2) 每個 .npy = 一個 CLIP 向量 (例如 768/1024 維)\n",
    "# 會自動偵測；也可手動指定 FORCE_MODE = 'image' 或 'feature'\n",
    "# 目錄：\n",
    "#  Script/\n",
    "#    features/\n",
    "#      clip_real/*.npy\n",
    "#      clip_fake/*.npy\n",
    "#    saved_models/   (輸出)\n",
    "# ============================================\n",
    "\n",
    "# !pip -q install open_clip_torch scikit-learn pillow tqdm joblib\n",
    "\n",
    "import os, glob, json, math, time, random, gc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import open_clip\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "\n",
    "# ---------- Config ----------\n",
    "SCRIPT_ROOT = \"/home/yaya/ai-detect-proj/Script\"          # <<< 改成你的 Script 目錄\n",
    "CLIP_REAL_DIR = os.path.join(SCRIPT_ROOT, \"features_npy\", \"clip_real_npy\")\n",
    "CLIP_FAKE_DIR = os.path.join(SCRIPT_ROOT, \"features_npy\", \"clip_fake_npy\")\n",
    "OUTPUT_DIR   = os.path.join(SCRIPT_ROOT, \"saved_models\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"ViT-L-14\"\n",
    "PRETRAINED = \"openai\"\n",
    "BATCH_SIZE = 64\n",
    "VAL_SIZE = 0.2\n",
    "RANDOM_SEED = 1337\n",
    "\n",
    "# 自動/手動模式：'auto' | 'image' | 'feature'\n",
    "FORCE_MODE = 'feature'  # <<< 改成 'image' 或 'feature' 以強制指定模式\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06b81b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- Utils ----------\n",
    "def list_npy(folder):\n",
    "    files = sorted(glob.glob(os.path.join(folder, \"*.npy\")))\n",
    "    assert len(files) > 0, f\"No .npy in {folder}\"\n",
    "    return files\n",
    "\n",
    "def npy_to_rgb(arr: np.ndarray) -> np.ndarray:\n",
    "    arr = np.asarray(arr)\n",
    "    # channel-first 轉 HWC\n",
    "    if arr.ndim == 3 and arr.shape[0] in (1,3) and arr.shape[-1] not in (1,3):\n",
    "        arr = np.transpose(arr, (1,2,0))\n",
    "    if arr.ndim == 2:\n",
    "        arr = np.stack([arr]*3, axis=-1)\n",
    "    if arr.dtype != np.uint8:\n",
    "        arr = np.clip(arr, 0, 1)\n",
    "        arr = (arr * 255.0).round().astype(np.uint8)\n",
    "    if arr.shape[-1] == 1:\n",
    "        arr = np.repeat(arr, 3, axis=-1)\n",
    "    return arr\n",
    "\n",
    "def detect_mode(sample_path):\n",
    "    a = np.load(sample_path, allow_pickle=True)\n",
    "    # 影像常見：2D或3D且 min(H,W) >= 64；向量常見：1D，或2D但其中一維很小\n",
    "    is_image = (\n",
    "        (a.ndim == 2 and min(a.shape) >= 64) or\n",
    "        (a.ndim == 3 and (a.shape[-1] in (1,3) or a.shape[0] in (1,3)) and max(a.shape[:2]) >= 64)\n",
    "    )\n",
    "    return 'image' if is_image else 'feature'\n",
    "\n",
    "def save_json(obj, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "544ff04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train=4  Val=4  Test-IID=4  Test-OOD=4\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_paths)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  Val=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(val_paths)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  Test-IID=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_iid)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m  Test-OOD=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_ood)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# 依 splits 決定偵測模式（取第一個可用檔）\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m _first = \u001b[43m(\u001b[49m\u001b[43mtrain_paths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_paths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_iid\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_ood\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     27\u001b[39m mode = FORCE_MODE \u001b[38;5;28;01mif\u001b[39;00m FORCE_MODE != \u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m detect_mode(_first)\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDetected mode:\u001b[39m\u001b[33m\"\u001b[39m, mode)\n",
      "\u001b[31mKeyError\u001b[39m: 0"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- Load splits from JSON ----------\n",
    "SPLITS_JSON = os.path.join(OUTPUT_DIR, \"splits_clip_feature_iid_ood.json\")  # 如有不同檔名請改這行\n",
    "assert os.path.isfile(SPLITS_JSON), f\"找不到 splits json：{SPLITS_JSON}\"\n",
    "\n",
    "with open(SPLITS_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    SPLITS = json.load(f)[\"splits\"]\n",
    "\n",
    "train_paths = SPLITS.get(\"train\", [])\n",
    "val_paths   = SPLITS.get(\"val\", [])\n",
    "test_iid    = SPLITS.get(\"test_iid\", [])\n",
    "test_ood    = SPLITS.get(\"test_ood\", [])\n",
    "\n",
    "def label_from_path(p: str) -> int:\n",
    "    # 以資料夾判斷：在 clip_real_npy → 0，否則 1\n",
    "    pnorm = Path(p).as_posix()\n",
    "    return 0 if (\"/clip_real_npy/\" in pnorm or pnorm.startswith(Path(CLIP_REAL_DIR).as_posix())) else 1\n",
    "\n",
    "y_tr = [label_from_path(p) for p in train_paths]\n",
    "y_va = [label_from_path(p) for p in val_paths]\n",
    "y_ti = [label_from_path(p) for p in test_iid] if test_iid else []\n",
    "y_to = [label_from_path(p) for p in test_ood] if test_ood else []\n",
    "\n",
    "print(f\"Train={len(train_paths)}  Val={len(val_paths)}  Test-IID={len(test_iid)}  Test-OOD={len(test_ood)}\")\n",
    "\n",
    "# 依 splits 決定偵測模式（取第一個可用檔）\n",
    "_first = (train_paths or val_paths or test_iid or test_ood)[0]\n",
    "mode = FORCE_MODE if FORCE_MODE != 'auto' else detect_mode(_first)\n",
    "print(\"Detected mode:\", mode)\n",
    "\n",
    "# ---------- If image mode: load CLIP and extractor ----------\n",
    "if mode == 'image':\n",
    "    print(\"Loading CLIP:\", MODEL_NAME, PRETRAINED)\n",
    "    clip_model, _, clip_preprocess = open_clip.create_model_and_transforms(\n",
    "        MODEL_NAME, pretrained=PRETRAINED\n",
    "    )\n",
    "    clip_model = clip_model.to(device).eval()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def clip_embed_batch(np_imgs):\n",
    "        pil_list = [Image.fromarray(x, mode=\"RGB\") for x in np_imgs]\n",
    "        tensors = [clip_preprocess(img).unsqueeze(0) for img in pil_list]\n",
    "        imgs = torch.cat(tensors, dim=0).to(device, non_blocking=True)\n",
    "        feats = clip_model.encode_image(imgs)\n",
    "        feats = feats / feats.norm(dim=-1, keepdim=True)\n",
    "        return feats.float().cpu().numpy()\n",
    "\n",
    "    def load_feature_vec(p):  # 影像模式下此函式不會用到，但為了 predict_one 一致保留\n",
    "        v = np.asarray(np.load(p, allow_pickle=True)).astype(np.float32).reshape(-1)\n",
    "        n = np.linalg.norm(v) + 1e-12\n",
    "        return v / n\n",
    "\n",
    "    def extract_features(paths, batch=BATCH_SIZE):\n",
    "        X=[]\n",
    "        for i in tqdm(range(0, len(paths), batch), desc=\"CLIP feats\"):\n",
    "            chunk = [npy_to_rgb(np.load(p, allow_pickle=True)) for p in paths[i:i+batch]]\n",
    "            X.append(clip_embed_batch(chunk))\n",
    "            del chunk\n",
    "            if device == 'cuda': torch.cuda.empty_cache()\n",
    "        return np.vstack(X)\n",
    "\n",
    "else:\n",
    "    # feature mode：每個 .npy 就是一個向量；做 L2 normalize 以對齊 CLIP 特徵慣例\n",
    "    def load_feature_vec(p):\n",
    "        v = np.asarray(np.load(p, allow_pickle=True)).astype(np.float32)\n",
    "        v = v.reshape(-1)  # 支援 (d,) 或 (1,d) 等\n",
    "        n = np.linalg.norm(v) + 1e-12\n",
    "        return v / n\n",
    "\n",
    "    def extract_features(paths, batch=None):\n",
    "        return np.vstack([load_feature_vec(p) for p in tqdm(paths, desc=\"Load feats\")])\n",
    "\n",
    "# ---------- Optional: per-class cap（用在 train/val；測試不動） ----------\n",
    "CAP_TRAIN_PER_CLASS = None   # 例如 70000；None 表示不限制\n",
    "CAP_VAL_PER_CLASS   = None\n",
    "AUTO_BALANCE        = True   # True 且 CAP_TRAIN_PER_CLASS=None 時，用少數類樣本數當 cap\n",
    "\n",
    "def cap_per_class(paths, labels, cap, seed=RANDOM_SEED):\n",
    "    if cap is None: \n",
    "        return paths, labels\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(len(paths))\n",
    "    idx0 = idx[np.array(labels) == 0]\n",
    "    idx1 = idx[np.array(labels) == 1]\n",
    "\n",
    "    def pick(idxs):\n",
    "        if len(idxs) <= cap: \n",
    "            return idxs\n",
    "        return rng.choice(idxs, size=cap, replace=False)\n",
    "\n",
    "    keep = np.concatenate([pick(idx0), pick(idx1)])\n",
    "    rng.shuffle(keep)\n",
    "    return [paths[i] for i in keep], [labels[i] for i in keep]\n",
    "\n",
    "if AUTO_BALANCE and CAP_TRAIN_PER_CLASS is None:\n",
    "    n0 = sum(np.array(y_tr) == 0)\n",
    "    n1 = sum(np.array(y_tr) == 1)\n",
    "    CAP_TRAIN_PER_CLASS = min(n0, n1)\n",
    "\n",
    "train_paths, y_tr = cap_per_class(train_paths, y_tr, CAP_TRAIN_PER_CLASS)\n",
    "val_paths,   y_va = cap_per_class(val_paths,   y_va, CAP_VAL_PER_CLASS)\n",
    "\n",
    "print(f\"Train (after cap): total={len(train_paths)} | real={sum(np.array(y_tr)==0)} fake={sum(np.array(y_tr)==1)} \"\n",
    "      f\"| cap_per_class={CAP_TRAIN_PER_CLASS}\")\n",
    "print(f\"Val   (after cap): total={len(val_paths)} | real={sum(np.array(y_va)==0)} fake={sum(np.array(y_va)==1)} \"\n",
    "      f\"| cap_per_class={CAP_VAL_PER_CLASS}\")\n",
    "\n",
    "# ---------- Feature Extraction ----------\n",
    "X_tr = extract_features(train_paths)\n",
    "X_va = extract_features(val_paths)\n",
    "assert X_tr.shape[1] == X_va.shape[1], \"Feature dim mismatch between train/val\"\n",
    "\n",
    "# ---------- Train SVM ----------\n",
    "svc = LinearSVC(C=1.0, class_weight=\"balanced\", max_iter=20000, tol=1e-4, dual=False)\n",
    "print(\"Fitting LinearSVC...\")\n",
    "svc.fit(X_tr, y_tr)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "def evaluate(svc, X, y, name=\"Split\"):\n",
    "    if X is None or len(y) == 0:\n",
    "        print(f\"[{name}] (empty)\")\n",
    "        return float(\"nan\"), float(\"nan\")\n",
    "    scores = svc.decision_function(X)   # >0 => fake\n",
    "    preds  = (scores > 0).astype(int)\n",
    "    acc = accuracy_score(y, preds)\n",
    "    try:\n",
    "        auc = roc_auc_score(y, scores)\n",
    "    except ValueError:\n",
    "        auc = float(\"nan\")\n",
    "    print(f\"[{name}] Acc={acc:.4f} | AUC={auc:.4f}\")\n",
    "    print(confusion_matrix(y, preds))\n",
    "    print(classification_report(y, preds, target_names=[\"real(0)\",\"fake(1)\"]))\n",
    "    return acc, auc\n",
    "\n",
    "print(\"=== Train ===\"); evaluate(svc, X_tr, y_tr, \"Train\")\n",
    "print(\"=== Val ===\");   evaluate(svc, X_va, y_va, \"Val\")\n",
    "\n",
    "# 測試（若 JSON 有提供）\n",
    "X_ti = extract_features(test_iid) if test_iid else None\n",
    "X_to = extract_features(test_ood) if test_ood else None\n",
    "if X_ti is not None: evaluate(svc, X_ti, y_ti, \"Test-IID\")\n",
    "if X_to is not None: evaluate(svc, X_to, y_to, \"Test-OOD\")\n",
    "\n",
    "# ---------- Save ----------\n",
    "stamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_path = os.path.join(OUTPUT_DIR, f\"clip_linear_svm_{mode}_{stamp}.joblib\")\n",
    "joblib.dump(svc, model_path)\n",
    "meta = {\n",
    "    \"pipeline\": \"CLIP→LinearSVC\",\n",
    "    \"mode\": mode,\n",
    "    \"clip_backbone\": MODEL_NAME if mode=='image' else \"precomputed\",\n",
    "    \"pretrained\": PRETRAINED if mode=='image' else None,\n",
    "    \"feature_dim\": int(X_tr.shape[1]),\n",
    "    \"val_count\": len(y_va),\n",
    "    \"train_count\": len(y_tr),\n",
    "    \"test_iid_count\": len(y_ti) if y_ti else 0,\n",
    "    \"test_ood_count\": len(y_to) if y_to else 0,\n",
    "    \"folders\": {\"real\": CLIP_REAL_DIR, \"fake\": CLIP_FAKE_DIR},\n",
    "    \"splits_json\": SPLITS_JSON,\n",
    "    \"random_seed\": RANDOM_SEED,\n",
    "    \"created_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "}\n",
    "save_json(meta, os.path.join(OUTPUT_DIR, f\"clip_linear_svm_meta_{stamp}.json\"))\n",
    "print(\"Saved:\", model_path)\n",
    "\n",
    "# ---------- Inference helpers（維持相容；會使用上方的 mode 與函式） ----------\n",
    "@torch.no_grad()\n",
    "def predict_one(npy_path, svc, mode='auto'):\n",
    "    mode_local = detect_mode(npy_path) if mode == 'auto' else mode\n",
    "    if mode_local == 'image':\n",
    "        global clip_model, clip_preprocess\n",
    "        if 'clip_model' not in globals():\n",
    "            clip_model, _, clip_preprocess = open_clip.create_model_and_transforms(\n",
    "                MODEL_NAME, pretrained=PRETRAINED\n",
    "            )\n",
    "            clip_model = clip_model.to(device).eval()\n",
    "        img = npy_to_rgb(np.load(npy_path, allow_pickle=True))\n",
    "        pil = Image.fromarray(img, mode=\"RGB\")\n",
    "        x = clip_preprocess(pil).unsqueeze(0).to(device)\n",
    "        f = clip_model.encode_image(x); f = f / f.norm(dim=-1, keepdim=True)\n",
    "        v = f.cpu().numpy()\n",
    "    else:\n",
    "        v = load_feature_vec(npy_path)[None, :]\n",
    "    score = svc.decision_function(v)[0]     # >0 => fake\n",
    "    prob_like_fake = 1 / (1 + math.exp(-score))\n",
    "    return score, prob_like_fake, int(score > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "723c2e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load feats: 100%|██████████| 18000/18000 [00:00<00:00, 18629.67it/s]\n",
      "Load feats: 100%|██████████| 18000/18000 [00:00<00:00, 19820.37it/s]\n",
      "Load feats: 100%|██████████| 43989/43989 [00:02<00:00, 18474.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_best(J) = -0.02346035780521083  | t_f1 = -0.09413094176667464\n",
      "\n",
      "== 用驗證集 Youden J 門檻 ==\n",
      "[Val] thr=-0.0235 | acc=0.9766\n",
      "[[ 5953    47]\n",
      " [  374 11626]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9409    0.9922    0.9658      6000\n",
      "           1     0.9960    0.9688    0.9822     12000\n",
      "\n",
      "    accuracy                         0.9766     18000\n",
      "   macro avg     0.9684    0.9805    0.9740     18000\n",
      "weighted avg     0.9776    0.9766    0.9768     18000\n",
      "\n",
      "[Test-IID] thr=-0.0235 | acc=0.9784\n",
      "[[ 5956    44]\n",
      " [  344 11656]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9454    0.9927    0.9685      6000\n",
      "           1     0.9962    0.9713    0.9836     12000\n",
      "\n",
      "    accuracy                         0.9784     18000\n",
      "   macro avg     0.9708    0.9820    0.9760     18000\n",
      "weighted avg     0.9793    0.9784    0.9786     18000\n",
      "\n",
      "[Test-OOD] thr=-0.0235 | acc=0.4761\n",
      "[[ 1968 23021]\n",
      " [   27 18973]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9865    0.0788    0.1459     24989\n",
      "           1     0.4518    0.9986    0.6221     19000\n",
      "\n",
      "    accuracy                         0.4761     43989\n",
      "   macro avg     0.7191    0.5387    0.3840     43989\n",
      "weighted avg     0.7555    0.4761    0.3516     43989\n",
      "\n",
      "\n",
      "== 用驗證集 F1 門檻 ==\n",
      "[Val] thr=-0.0941 | acc=0.9768\n",
      "[[ 5941    59]\n",
      " [  359 11641]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9430    0.9902    0.9660      6000\n",
      "           1     0.9950    0.9701    0.9824     12000\n",
      "\n",
      "    accuracy                         0.9768     18000\n",
      "   macro avg     0.9690    0.9801    0.9742     18000\n",
      "weighted avg     0.9776    0.9768    0.9769     18000\n",
      "\n",
      "[Test-IID] thr=-0.0941 | acc=0.9790\n",
      "[[ 5945    55]\n",
      " [  323 11677]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9485    0.9908    0.9692      6000\n",
      "           1     0.9953    0.9731    0.9841     12000\n",
      "\n",
      "    accuracy                         0.9790     18000\n",
      "   macro avg     0.9719    0.9820    0.9766     18000\n",
      "weighted avg     0.9797    0.9790    0.9791     18000\n",
      "\n",
      "[Test-OOD] thr=-0.0941 | acc=0.4718\n",
      "[[ 1774 23215]\n",
      " [   20 18980]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9889    0.0710    0.1325     24989\n",
      "           1     0.4498    0.9989    0.6203     19000\n",
      "\n",
      "    accuracy                         0.4718     43989\n",
      "   macro avg     0.7193    0.5350    0.3764     43989\n",
      "weighted avg     0.7560    0.4718    0.3432     43989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 重新取各 split 的分數（若你還在記憶體就跳過重取） ---\n",
    "def get_scores(paths):\n",
    "    X = extract_features(paths)\n",
    "    return svc.decision_function(X)\n",
    "\n",
    "scores_va = get_scores(val_paths)\n",
    "scores_ti = get_scores(test_iid) if test_iid else None\n",
    "scores_to = get_scores(test_ood) if test_ood else None\n",
    "y_va = np.array([0 if \"/clip_real_npy/\" in Path(p).as_posix() else 1 for p in val_paths])\n",
    "y_ti = np.array([0 if \"/clip_real_npy/\" in Path(p).as_posix() else 1 for p in test_iid]) if test_iid else None\n",
    "y_to = np.array([0 if \"/clip_real_npy/\" in Path(p).as_posix() else 1 for p in test_ood]) if test_ood else None\n",
    "\n",
    "from sklearn.metrics import roc_curve, f1_score, accuracy_score\n",
    "\n",
    "# 1) Youden's J：最大化 (TPR - FPR)\n",
    "fpr, tpr, thr = roc_curve(y_va, scores_va)\n",
    "j = tpr - fpr\n",
    "t_best = thr[j.argmax()]\n",
    "\n",
    "# 2) 或者用驗證集最大 F1 的門檻\n",
    "def best_f1_threshold(y, s):\n",
    "    qs = np.quantile(s, np.linspace(0.01, 0.99, 99))  # 掃一圈\n",
    "    f1s = [f1_score(y, (s>q).astype(int)) for q in qs]\n",
    "    return qs[int(np.argmax(f1s))]\n",
    "\n",
    "t_f1 = best_f1_threshold(y_va, scores_va)\n",
    "print(\"t_best(J) =\", float(t_best), \" | t_f1 =\", float(t_f1))\n",
    "\n",
    "def eval_with_threshold(name, y, s, t):\n",
    "    pred = (s > t).astype(int)\n",
    "    acc = accuracy_score(y, pred)\n",
    "    print(f\"[{name}] thr={t:.4f} | acc={acc:.4f}\")\n",
    "    print(confusion_matrix(y, pred))\n",
    "    print(classification_report(y, pred, digits=4))\n",
    "\n",
    "print(\"\\n== 用驗證集 Youden J 門檻 ==\")\n",
    "eval_with_threshold(\"Val\", y_va, scores_va, t_best)\n",
    "if scores_ti is not None: eval_with_threshold(\"Test-IID\", y_ti, scores_ti, t_best)\n",
    "if scores_to is not None: eval_with_threshold(\"Test-OOD\", y_to, scores_to, t_best)\n",
    "\n",
    "print(\"\\n== 用驗證集 F1 門檻 ==\")\n",
    "eval_with_threshold(\"Val\", y_va, scores_va, t_f1)\n",
    "if scores_ti is not None: eval_with_threshold(\"Test-IID\", y_ti, scores_ti, t_f1)\n",
    "if scores_to is not None: eval_with_threshold(\"Test-OOD\", y_to, scores_to, t_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d7ab73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== 校準後（sigmoid） ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load feats: 100%|██████████| 18000/18000 [00:00<00:00, 22629.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] acc=0.9765 auc=0.9891\n",
      "[[ 5950    50]\n",
      " [  373 11627]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9410    0.9917    0.9657      6000\n",
      "           1     0.9957    0.9689    0.9821     12000\n",
      "\n",
      "    accuracy                         0.9765     18000\n",
      "   macro avg     0.9684    0.9803    0.9739     18000\n",
      "weighted avg     0.9775    0.9765    0.9766     18000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load feats: 100%|██████████| 18000/18000 [00:00<00:00, 21446.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test-IID] acc=0.9786 auc=0.9901\n",
      "[[ 5954    46]\n",
      " [  339 11661]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9461    0.9923    0.9687      6000\n",
      "           1     0.9961    0.9718    0.9838     12000\n",
      "\n",
      "    accuracy                         0.9786     18000\n",
      "   macro avg     0.9711    0.9820    0.9762     18000\n",
      "weighted avg     0.9794    0.9786    0.9787     18000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load feats: 100%|██████████| 43989/43989 [00:01<00:00, 22527.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test-OOD] acc=0.4748 auc=0.8461\n",
      "[[ 1911 23078]\n",
      " [   25 18975]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9871    0.0765    0.1419     24989\n",
      "           1     0.4512    0.9987    0.6216     19000\n",
      "\n",
      "    accuracy                         0.4748     43989\n",
      "   macro avg     0.7192    0.5376    0.3818     43989\n",
      "weighted avg     0.7556    0.4748    0.3491     43989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "# 用現成的 svc 做 sigmoid 校準（預設將內部分成 CV=5，也可改 cv=\"prefit\" + 另外保留的 val）\n",
    "cal = CalibratedClassifierCV(svc, method=\"sigmoid\", cv=5)\n",
    "cal.fit(X_tr, y_tr)\n",
    "\n",
    "def eval_cal(name, paths, y):\n",
    "    if not paths: \n",
    "        print(f\"[{name}] (empty)\"); return\n",
    "    X = extract_features(paths)\n",
    "    proba = cal.predict_proba(X)[:,1]  # P(fake)\n",
    "    pred  = (proba >= 0.5).astype(int) # 可改 0.5→驗證集找最佳\n",
    "    acc = accuracy_score(y, pred)\n",
    "    try:\n",
    "        auc = roc_auc_score(y, proba)\n",
    "    except ValueError:\n",
    "        auc = float(\"nan\")\n",
    "    print(f\"[{name}] acc={acc:.4f} auc={auc:.4f}\")\n",
    "    print(confusion_matrix(y, pred))\n",
    "    print(classification_report(y, pred, digits=4))\n",
    "\n",
    "print(\"\\n== 校準後（sigmoid） ==\")\n",
    "eval_cal(\"Val\",      val_paths,   y_va)\n",
    "if test_iid: eval_cal(\"Test-IID\", test_iid, y_ti)\n",
    "if test_ood: eval_cal(\"Test-OOD\", test_ood, y_to)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d208ae55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- (取代原本 \"Gather paths\" 區塊；其餘程式碼保留) ----------\n",
    "\n",
    "# 讓每個資料集前綴（dataset tag）在各自類別內（real / fake）數量均衡\n",
    "BALANCE_BY_DATASET   = True                 # 是否啟用依資料集均衡\n",
    "BALANCE_STRATEGY     = 'undersample'        # 'undersample' | 'oversample' | 'none'\n",
    "PER_DATASET_CAP_REAL = None                 # 每個資料集在 real 的上限；None 表示用各群組的最小值\n",
    "PER_DATASET_CAP_FAKE = None                 # 每個資料集在 fake 的上限；None 表示用各群組的最小值\n",
    "MIN_KEEP_PER_GROUP   = 1                    # 群組太小可丟棄（小於此值就不保留）\n",
    "\n",
    "# 可選：把常見別名合併（自己再加）\n",
    "DATASET_ALIASES = {\n",
    "    'imagenet1k': 'imagenet', 'imgnet': 'imagenet',\n",
    "    'sd': 'stablediffusion', 'stable-diffusion': 'stablediffusion', 'sdxl': 'sdxl',\n",
    "    'mj': 'midjourney', 'midj': 'midjourney',\n",
    "    'dalle3': 'dalle-3', 'dalle2': 'dalle-2','FLUX': 'flux'\n",
    "}\n",
    "\n",
    "def canonical_tag(tag: str) -> str:\n",
    "    tag = tag.lower().strip()\n",
    "    return DATASET_ALIASES.get(tag, tag)\n",
    "\n",
    "def infer_dataset_tag(path: str, is_real: bool) -> str:\n",
    "    \"\"\"\n",
    "    從檔名最前段推測資料集前綴；支援分隔符：'__','---','--','_','-',' '\n",
    "    例：'sdxl__xxxx.npy' → 'sdxl'；'midjourney-000123.npy' → 'midjourney'\n",
    "    若真實圖片檔名沒有前綴或就是序號，預設標成 'imagenet'\n",
    "    \"\"\"\n",
    "    stem = Path(path).stem\n",
    "    seps = ['__','---','--','_','-',' ']\n",
    "    cut = None\n",
    "    for s in seps:\n",
    "        i = stem.find(s)\n",
    "        if i != -1:\n",
    "            cut = i if cut is None else min(cut, i)\n",
    "    tag = stem[:cut] if cut is not None else stem\n",
    "    tag = tag.strip()\n",
    "    # 若沒有合理前綴或是純數字 → 真實圖片視為 imagenet；否則標 unknown\n",
    "    if (not tag) or tag.isdigit():\n",
    "        tag = 'imagenet' if is_real else 'unknown'\n",
    "    return canonical_tag(tag)\n",
    "\n",
    "def summarize_counts(paths, is_real: bool):\n",
    "    counts = {}\n",
    "    for p in paths:\n",
    "        t = infer_dataset_tag(p, is_real=is_real)\n",
    "        counts[t] = counts.get(t, 0) + 1\n",
    "    return dict(sorted(counts.items(), key=lambda kv: (-kv[1], kv[0])))\n",
    "\n",
    "def balance_paths(paths, is_real: bool, strategy='undersample', per_dataset_cap=None, min_keep=1):\n",
    "    \"\"\"\n",
    "    依資料集前綴做均衡抽樣；回傳抽樣後的路徑清單\n",
    "    - undersample: 各群組下砍到 cap\n",
    "    - oversample: 各群組抽樣（可重複）到 cap\n",
    "    - none: 不動\n",
    "    \"\"\"\n",
    "    if strategy == 'none':\n",
    "        return paths\n",
    "\n",
    "    groups = {}\n",
    "    for idx, p in enumerate(paths):\n",
    "        t = infer_dataset_tag(p, is_real=is_real)\n",
    "        groups.setdefault(t, []).append(idx)\n",
    "\n",
    "    # 可選：丟棄過小群組\n",
    "    groups = {t: idxs for t, idxs in groups.items() if len(idxs) >= min_keep}\n",
    "    if not groups:\n",
    "        return []\n",
    "\n",
    "    if per_dataset_cap is None:\n",
    "        cap = min(len(idxs) for idxs in groups.values())  # 用最小群作標準\n",
    "    else:\n",
    "        cap = int(per_dataset_cap)\n",
    "        if cap <= 0:\n",
    "            raise ValueError(\"per_dataset_cap must be positive.\")\n",
    "\n",
    "    rng = np.random.default_rng(RANDOM_SEED)\n",
    "    selected_indices = []\n",
    "\n",
    "    if strategy == 'undersample':\n",
    "        for t, idxs in groups.items():\n",
    "            k = min(cap, len(idxs))\n",
    "            choose = rng.choice(idxs, size=k, replace=False)\n",
    "            selected_indices.extend(choose.tolist())\n",
    "    elif strategy == 'oversample':\n",
    "        for t, idxs in groups.items():\n",
    "            k = max(cap, len(idxs))\n",
    "            choose = rng.choice(idxs, size=k, replace=True)\n",
    "            selected_indices.extend(choose.tolist())\n",
    "    else:\n",
    "        raise ValueError(\"BALANCE_STRATEGY must be 'undersample' | 'oversample' | 'none'.\")\n",
    "\n",
    "    # 保持原本順序輕度穩定（也可打亂）\n",
    "    selected_indices = sorted(set(selected_indices))\n",
    "    return [paths[i] for i in selected_indices]\n",
    "\n",
    "# 讀取原始路徑\n",
    "real_paths_all = list_npy(CLIP_REAL_DIR)\n",
    "fake_paths_all = list_npy(CLIP_FAKE_DIR)\n",
    "\n",
    "print(\"【原始分佈（real）】\", summarize_counts(real_paths_all, is_real=True))\n",
    "print(\"【原始分佈（fake）】\", summarize_counts(fake_paths_all, is_real=False))\n",
    "\n",
    "# 依資料集均衡\n",
    "if BALANCE_BY_DATASET:\n",
    "    real_paths = balance_paths(real_paths_all, is_real=True,\n",
    "                               strategy=BALANCE_STRATEGY,\n",
    "                               per_dataset_cap=PER_DATASET_CAP_REAL,\n",
    "                               min_keep=MIN_KEEP_PER_GROUP)\n",
    "    fake_paths = balance_paths(fake_paths_all, is_real=False,\n",
    "                               strategy=BALANCE_STRATEGY,\n",
    "                               per_dataset_cap=PER_DATASET_CAP_FAKE,\n",
    "                               min_keep=MIN_KEEP_PER_GROUP)\n",
    "else:\n",
    "    real_paths, fake_paths = real_paths_all, fake_paths_all\n",
    "\n",
    "print(\"【均衡後分佈（real）】\", summarize_counts(real_paths, is_real=True))\n",
    "print(\"【均衡後分佈（fake）】\", summarize_counts(fake_paths, is_real=False))\n",
    "\n",
    "# 合併與標籤\n",
    "all_paths  = real_paths + fake_paths\n",
    "all_labels = [0]*len(real_paths) + [1]*len(fake_paths)\n",
    "print(f\"Total: {len(all_paths)} | real={len(real_paths)} fake={len(fake_paths)}\")\n",
    "\n",
    "# 自動/手動模式偵測\n",
    "mode = FORCE_MODE if FORCE_MODE != 'auto' else detect_mode(all_paths[0])\n",
    "print(\"Detected mode:\", mode)\n",
    "\n",
    "# 可選：把分佈存檔，方便追蹤實驗\n",
    "save_json({\n",
    "    \"before\": {\n",
    "        \"real\": summarize_counts(real_paths_all, True),\n",
    "        \"fake\": summarize_counts(fake_paths_all, False)\n",
    "    },\n",
    "    \"after\": {\n",
    "        \"real\": summarize_counts(real_paths, True),\n",
    "        \"fake\": summarize_counts(fake_paths, False)\n",
    "    },\n",
    "    \"strategy\": BALANCE_STRATEGY,\n",
    "    \"cap_real\": PER_DATASET_CAP_REAL,\n",
    "    \"cap_fake\": PER_DATASET_CAP_FAKE\n",
    "}, os.path.join(OUTPUT_DIR, \"dataset_balance_clip.json\"))\n",
    "# ---------- (區塊結束) ----------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "016689c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train=112000 (real=56000, fake=56000)\n",
      "Val  =14000 (real=7000, fake=7000)\n",
      "Test-IID=14000 | Test-OOD=17570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load features: 100%|██████████| 112000/112000 [00:43<00:00, 2553.97it/s]\n",
      "Load features: 100%|██████████| 14000/14000 [00:04<00:00, 2859.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LinearSVC...\n",
      "\n",
      "=== Eval: Train ===\n",
      "[Train] Acc=0.9385 | AUC=0.9757\n",
      "[[53488  2512]\n",
      " [ 4379 51621]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     real(0)     0.9243    0.9551    0.9395     56000\n",
      "     fake(1)     0.9536    0.9218    0.9374     56000\n",
      "\n",
      "    accuracy                         0.9385    112000\n",
      "   macro avg     0.9390    0.9385    0.9385    112000\n",
      "weighted avg     0.9390    0.9385    0.9385    112000\n",
      "\n",
      "\n",
      "=== Eval: Val ===\n",
      "[Val] Acc=0.9360 | AUC=0.9738\n",
      "[[6659  341]\n",
      " [ 555 6445]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     real(0)     0.9231    0.9513    0.9370      7000\n",
      "     fake(1)     0.9497    0.9207    0.9350      7000\n",
      "\n",
      "    accuracy                         0.9360     14000\n",
      "   macro avg     0.9364    0.9360    0.9360     14000\n",
      "weighted avg     0.9364    0.9360    0.9360     14000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load features: 100%|██████████| 14000/14000 [00:04<00:00, 2866.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Eval: Test-IID ===\n",
      "[Test-IID] Acc=0.9381 | AUC=0.9767\n",
      "[[6677  323]\n",
      " [ 544 6456]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     real(0)     0.9247    0.9539    0.9390      7000\n",
      "     fake(1)     0.9524    0.9223    0.9371      7000\n",
      "\n",
      "    accuracy                         0.9381     14000\n",
      "   macro avg     0.9385    0.9381    0.9381     14000\n",
      "weighted avg     0.9385    0.9381    0.9381     14000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load features: 100%|██████████| 17570/17570 [00:06<00:00, 2757.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Eval: Test-OOD ===\n",
      "[Test-OOD] Acc=0.8618 | AUC=0.9418\n",
      "[[7558 1227]\n",
      " [1202 7583]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     real(0)     0.8628    0.8603    0.8616      8785\n",
      "     fake(1)     0.8607    0.8632    0.8619      8785\n",
      "\n",
      "    accuracy                         0.8618     17570\n",
      "   macro avg     0.8618    0.8618    0.8618     17570\n",
      "weighted avg     0.8618    0.8618    0.8618     17570\n",
      "\n",
      "\n",
      "Val thresholds → YoudenJ:0.057070  |  F1:0.039132\n",
      "\n",
      "-- Eval with Val-YoudenJ threshold --\n",
      "[Val] thr=0.057070 | acc=0.9370\n",
      "[[6712  288]\n",
      " [ 594 6406]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     real(0)     0.9187    0.9589    0.9383      7000\n",
      "     fake(1)     0.9570    0.9151    0.9356      7000\n",
      "\n",
      "    accuracy                         0.9370     14000\n",
      "   macro avg     0.9378    0.9370    0.9370     14000\n",
      "weighted avg     0.9378    0.9370    0.9370     14000\n",
      "\n",
      "[Test-IID] thr=0.057070 | acc=0.9384\n",
      "[[6723  277]\n",
      " [ 586 6414]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     real(0)     0.9198    0.9604    0.9397      7000\n",
      "     fake(1)     0.9586    0.9163    0.9370      7000\n",
      "\n",
      "    accuracy                         0.9384     14000\n",
      "   macro avg     0.9392    0.9384    0.9383     14000\n",
      "weighted avg     0.9392    0.9384    0.9383     14000\n",
      "\n",
      "[Test-OOD] thr=0.057070 | acc=0.8613\n",
      "[[7721 1064]\n",
      " [1373 7412]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     real(0)     0.8490    0.8789    0.8637      8785\n",
      "     fake(1)     0.8745    0.8437    0.8588      8785\n",
      "\n",
      "    accuracy                         0.8613     17570\n",
      "   macro avg     0.8617    0.8613    0.8613     17570\n",
      "weighted avg     0.8617    0.8613    0.8613     17570\n",
      "\n",
      "\n",
      "-- Eval with Val-F1 threshold --\n",
      "[Val] thr=0.039132 | acc=0.9369\n",
      "[[6698  302]\n",
      " [ 582 6418]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     real(0)     0.9201    0.9569    0.9381      7000\n",
      "     fake(1)     0.9551    0.9169    0.9356      7000\n",
      "\n",
      "    accuracy                         0.9369     14000\n",
      "   macro avg     0.9376    0.9369    0.9368     14000\n",
      "weighted avg     0.9376    0.9369    0.9368     14000\n",
      "\n",
      "[Test-IID] thr=0.039132 | acc=0.9381\n",
      "[[6710  290]\n",
      " [ 576 6424]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     real(0)     0.9209    0.9586    0.9394      7000\n",
      "     fake(1)     0.9568    0.9177    0.9369      7000\n",
      "\n",
      "    accuracy                         0.9381     14000\n",
      "   macro avg     0.9389    0.9381    0.9381     14000\n",
      "weighted avg     0.9389    0.9381    0.9381     14000\n",
      "\n",
      "[Test-OOD] thr=0.039132 | acc=0.8626\n",
      "[[7680 1105]\n",
      " [1309 7476]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     real(0)     0.8544    0.8742    0.8642      8785\n",
      "     fake(1)     0.8712    0.8510    0.8610      8785\n",
      "\n",
      "    accuracy                         0.8626     17570\n",
      "   macro avg     0.8628    0.8626    0.8626     17570\n",
      "weighted avg     0.8628    0.8626    0.8626     17570\n",
      "\n",
      "\n",
      "✅ Saved model: /home/yaya/ai-detect-proj/Script/saved_models/clip_linear_svm_feature_20250820_194147.joblib\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Train CLIP (precomputed features) → Linear SVM using your new splits JSON\n",
    "# - expects JSON structure:\n",
    "#   splits[split_name][\"clip\"][\"real\" or \"fake\"] = list of .npy paths\n",
    "# ============================================\n",
    "\n",
    "# !pip -q install scikit-learn tqdm joblib\n",
    "\n",
    "import os, json, math, time, numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix, roc_curve, f1_score\n",
    "import joblib\n",
    "\n",
    "# ---------- Config ----------\n",
    "SCRIPT_ROOT = \"/home/yaya/ai-detect-proj/Script\"\n",
    "SPLITS_JSON = os.path.join(SCRIPT_ROOT, \"saved_models\", \"splits_clip_feature_iid_ood.json\")\n",
    "OUTPUT_DIR  = os.path.join(SCRIPT_ROOT, \"saved_models\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "RANDOM_SEED = 1337\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# 可選：限制每類最大樣本（train/val）；None 表示不限制\n",
    "CAP_TRAIN_PER_CLASS = None\n",
    "CAP_VAL_PER_CLASS   = None\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def load_splits(json_path):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data[\"splits\"], data\n",
    "\n",
    "def paths_labels_from_split(splits, split_name, key=\"clip\"):\n",
    "    real = splits[split_name][key][\"real\"]\n",
    "    fake = splits[split_name][key][\"fake\"]\n",
    "    paths = real + fake\n",
    "    labels = [0]*len(real) + [1]*len(fake)\n",
    "    # 固定打亂\n",
    "    idx = np.random.permutation(len(paths))\n",
    "    return [paths[i] for i in idx], [labels[i] for i in idx]\n",
    "\n",
    "def cap_per_class(paths, labels, cap, seed=RANDOM_SEED):\n",
    "    if cap is None: return paths, labels\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = np.arange(len(paths))\n",
    "    idx0 = idx[np.array(labels)==0]\n",
    "    idx1 = idx[np.array(labels)==1]\n",
    "    def pick(idxs):\n",
    "        if len(idxs) <= cap: return idxs\n",
    "        return rng.choice(idxs, size=cap, replace=False)\n",
    "    keep = np.concatenate([pick(idx0), pick(idx1)])\n",
    "    rng.shuffle(keep)\n",
    "    return [paths[i] for i in keep], [labels[i] for i in keep]\n",
    "\n",
    "def load_feature_vec(p):\n",
    "    v = np.asarray(np.load(p, allow_pickle=True), dtype=np.float32).reshape(-1)\n",
    "    n = np.linalg.norm(v) + 1e-12\n",
    "    return v / n\n",
    "\n",
    "def extract_features(paths):\n",
    "    return np.vstack([load_feature_vec(p) for p in tqdm(paths, desc=\"Load features\")])\n",
    "\n",
    "def evaluate(clf, X, y, name=\"Split\"):\n",
    "    if X is None or len(y)==0:\n",
    "        print(f\"[{name}] (empty)\"); return float(\"nan\"), float(\"nan\")\n",
    "    scores = clf.decision_function(X)\n",
    "    preds  = (scores > 0).astype(int)\n",
    "    acc = accuracy_score(y, preds)\n",
    "    try:\n",
    "        auc = roc_auc_score(y, scores)\n",
    "    except ValueError:\n",
    "        auc = float(\"nan\")\n",
    "    print(f\"[{name}] Acc={acc:.4f} | AUC={auc:.4f}\")\n",
    "    print(confusion_matrix(y, preds))\n",
    "    print(classification_report(y, preds, target_names=[\"real(0)\",\"fake(1)\"], digits=4))\n",
    "    return acc, auc, scores\n",
    "\n",
    "# ---------- Load splits ----------\n",
    "SPLITS, RAW = load_splits(SPLITS_JSON)\n",
    "\n",
    "train_paths, y_tr = paths_labels_from_split(SPLITS, \"train\", key=\"clip\")\n",
    "val_paths,   y_va = paths_labels_from_split(SPLITS, \"val\",   key=\"clip\")\n",
    "ti_paths,    y_ti = paths_labels_from_split(SPLITS, \"test_iid\", key=\"clip\") if \"test_iid\" in SPLITS else ([], [])\n",
    "to_paths,    y_to = paths_labels_from_split(SPLITS, \"test_ood\", key=\"clip\") if \"test_ood\" in SPLITS else ([], [])\n",
    "\n",
    "# 可選 cap\n",
    "train_paths, y_tr = cap_per_class(train_paths, y_tr, CAP_TRAIN_PER_CLASS)\n",
    "val_paths,   y_va = cap_per_class(val_paths,   y_va, CAP_VAL_PER_CLASS)\n",
    "\n",
    "print(f\"Train={len(train_paths)} (real={sum(np.array(y_tr)==0)}, fake={sum(np.array(y_tr)==1)})\")\n",
    "print(f\"Val  ={len(val_paths)} (real={sum(np.array(y_va)==0)}, fake={sum(np.array(y_va)==1)})\")\n",
    "print(f\"Test-IID={len(ti_paths)} | Test-OOD={len(to_paths)}\")\n",
    "\n",
    "# ---------- Feature extraction ----------\n",
    "X_tr = extract_features(train_paths)\n",
    "X_va = extract_features(val_paths)\n",
    "feat_dim = X_tr.shape[1]\n",
    "assert X_va.shape[1] == feat_dim\n",
    "\n",
    "# ---------- Train Linear SVM ----------\n",
    "clf = LinearSVC(C=1.0, class_weight=\"balanced\", max_iter=20000, tol=1e-4, dual=False)\n",
    "print(\"Fitting LinearSVC...\")\n",
    "clf.fit(X_tr, y_tr)\n",
    "\n",
    "print(\"\\n=== Eval: Train ===\")\n",
    "acc_tr, auc_tr, scores_tr = evaluate(clf, X_tr, y_tr, \"Train\")\n",
    "print(\"\\n=== Eval: Val ===\")\n",
    "acc_va, auc_va, scores_va = evaluate(clf, X_va, y_va, \"Val\")\n",
    "\n",
    "# Optional tests\n",
    "scores_ti = scores_to = None\n",
    "if ti_paths:\n",
    "    X_ti = extract_features(ti_paths)\n",
    "    print(\"\\n=== Eval: Test-IID ===\")\n",
    "    acc_ti, auc_ti, scores_ti = evaluate(clf, X_ti, y_ti, \"Test-IID\")\n",
    "if to_paths:\n",
    "    X_to = extract_features(to_paths)\n",
    "    print(\"\\n=== Eval: Test-OOD ===\")\n",
    "    acc_to, auc_to, scores_to = evaluate(clf, X_to, y_to, \"Test-OOD\")\n",
    "\n",
    "# ---------- Thresholds (from Val) ----------\n",
    "fpr, tpr, thr = roc_curve(y_va, scores_va)\n",
    "t_bestJ = thr[(tpr - fpr).argmax()]\n",
    "\n",
    "def best_f1_threshold(y, s):\n",
    "    qs = np.quantile(s, np.linspace(0.01, 0.99, 99))\n",
    "    f1s = [f1_score(y, (s>q).astype(int)) for q in qs]\n",
    "    return float(qs[int(np.argmax(f1s))])\n",
    "\n",
    "t_f1 = best_f1_threshold(y_va, scores_va)\n",
    "print(f\"\\nVal thresholds → YoudenJ:{t_bestJ:.6f}  |  F1:{t_f1:.6f}\")\n",
    "\n",
    "def eval_with_threshold(name, y, s, t):\n",
    "    if s is None: return\n",
    "    pred = (s > t).astype(int)\n",
    "    acc = accuracy_score(y, pred)\n",
    "    print(f\"[{name}] thr={t:.6f} | acc={acc:.4f}\")\n",
    "    print(confusion_matrix(y, pred))\n",
    "    print(classification_report(y, pred, target_names=[\"real(0)\",\"fake(1)\"], digits=4))\n",
    "\n",
    "print(\"\\n-- Eval with Val-YoudenJ threshold --\")\n",
    "eval_with_threshold(\"Val\", y_va, scores_va, t_bestJ)\n",
    "if scores_ti is not None: eval_with_threshold(\"Test-IID\", y_ti, scores_ti, t_bestJ)\n",
    "if scores_to is not None: eval_with_threshold(\"Test-OOD\", y_to, scores_to, t_bestJ)\n",
    "\n",
    "print(\"\\n-- Eval with Val-F1 threshold --\")\n",
    "eval_with_threshold(\"Val\", y_va, scores_va, t_f1)\n",
    "if scores_ti is not None: eval_with_threshold(\"Test-IID\", y_ti, scores_ti, t_f1)\n",
    "if scores_to is not None: eval_with_threshold(\"Test-OOD\", y_to, scores_to, t_f1)\n",
    "\n",
    "# ---------- Save model & meta ----------\n",
    "stamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_path = os.path.join(OUTPUT_DIR, f\"clip_linear_svm_feature_{stamp}.joblib\")\n",
    "joblib.dump(clf, model_path)\n",
    "\n",
    "meta = {\n",
    "    \"pipeline\": \"CLIP(precomputed)→LinearSVC\",\n",
    "    \"feature_dim\": int(feat_dim),\n",
    "    \"counts\": {\n",
    "        \"train\": len(y_tr), \"val\": len(y_va),\n",
    "        \"test_iid\": len(y_ti), \"test_ood\": len(y_to)\n",
    "    },\n",
    "    \"thresholds\": {\"val_youdenJ\": float(t_bestJ), \"val_f1\": float(t_f1)},\n",
    "    \"splits_json\": SPLITS_JSON,\n",
    "    \"created_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"random_seed\": RANDOM_SEED\n",
    "}\n",
    "with open(os.path.join(OUTPUT_DIR, f\"clip_linear_svm_meta_{stamp}.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\n✅ Saved model:\", model_path)\n",
    "\n",
    "# ---------- Quick inference helper ----------\n",
    "def predict_one_feature_npy(npy_path, clf):\n",
    "    v = load_feature_vec(npy_path)[None, :]\n",
    "    score = clf.decision_function(v)[0]    # >0 => fake\n",
    "    prob  = 1 / (1 + math.exp(-score))\n",
    "    pred  = int(score > 0)\n",
    "    return score, prob, pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94ab1023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coco2017     | n= 8785 | acc=0.860 | real_recall=0.860 | fake_recall=0.000\n",
      "midjourney   | n= 6376 | acc=0.824 | real_recall=0.000 | fake_recall=0.824\n",
      "dalle3       | n= 2409 | acc=0.968 | real_recall=0.000 | fake_recall=0.968\n"
     ]
    }
   ],
   "source": [
    "# === OOD 分來源診斷（哪個來源最常被誤判） ===\n",
    "import json, numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "SCRIPT_ROOT = \"/home/yaya/ai-detect-proj/Script\"\n",
    "SPLITS_JSON = f\"{SCRIPT_ROOT}/saved_models/splits_clip_feature_iid_ood.json\"\n",
    "MODEL_PATH  = sorted(Path(f\"{SCRIPT_ROOT}/saved_models\").glob(\"clip_linear_svm_feature_*.joblib\"))[-1]\n",
    "\n",
    "import joblib\n",
    "clf = joblib.load(MODEL_PATH)\n",
    "\n",
    "with open(SPLITS_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    J = json.load(f)[\"splits\"]\n",
    "\n",
    "ood_real = J[\"test_ood\"][\"clip\"][\"real\"]\n",
    "ood_fake = J[\"test_ood\"][\"clip\"][\"fake\"]\n",
    "paths = ood_real + ood_fake\n",
    "y = np.array([0]*len(ood_real) + [1]*len(ood_fake))\n",
    "\n",
    "def src_of(stem: str):\n",
    "    s = stem.lower()\n",
    "    for k in [\"places365\",\"coco2017\",\"midjourney\",\"dalle3\",\"unsplash\",\"flickr30k\",\"imagenet\",\"div2k\",\"flux\",\"sd3\"]:\n",
    "        if s.startswith(k) or (k in s):\n",
    "            return k\n",
    "    return \"other\"\n",
    "\n",
    "def load_vec(p):\n",
    "    v = np.asarray(np.load(p, allow_pickle=True), dtype=np.float32).reshape(-1)\n",
    "    n = np.linalg.norm(v) + 1e-12\n",
    "    return v/n\n",
    "\n",
    "X = np.vstack([load_vec(p) for p in paths])\n",
    "scores = clf.decision_function(X)\n",
    "pred = (scores>0).astype(int)\n",
    "\n",
    "by_src = defaultdict(list)\n",
    "for p, yt, yp in zip(paths, y, pred):\n",
    "    by_src[src_of(Path(p).stem)].append((yt, yp))\n",
    "\n",
    "for k, L in sorted(by_src.items(), key=lambda kv:-len(kv[1])):\n",
    "    yt = np.array([t for t,_ in L]); yp = np.array([p for _,p in L])\n",
    "    acc = accuracy_score(yt, yp)\n",
    "    print(f\"{k:12s} | n={len(L):5d} | acc={acc:.3f} | real_recall={((yp==0)&(yt==0)).sum()/max((yt==0).sum(),1):.3f} | fake_recall={((yp==1)&(yt==1)).sum()/max((yt==1).sum(),1):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0ee4123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load: 100%|██████████| 112000/112000 [00:34<00:00, 3257.37it/s]\n",
      "load: 100%|██████████| 14000/14000 [00:00<00:00, 19363.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Train ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load: 100%|██████████| 112000/112000 [00:05<00:00, 21195.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Acc=0.9271 | AUC=0.9701\n",
      "[[52726  3274]\n",
      " [ 4887 51113]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     real(0)     0.9152    0.9415    0.9282     56000\n",
      "     fake(1)     0.9398    0.9127    0.9261     56000\n",
      "\n",
      "    accuracy                         0.9271    112000\n",
      "   macro avg     0.9275    0.9271    0.9271    112000\n",
      "weighted avg     0.9275    0.9271    0.9271    112000\n",
      "\n",
      "=== Val ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load: 100%|██████████| 14000/14000 [00:00<00:00, 24968.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Val] Acc=0.9264 | AUC=0.9691\n",
      "[[6574  426]\n",
      " [ 604 6396]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     real(0)     0.9159    0.9391    0.9274      7000\n",
      "     fake(1)     0.9376    0.9137    0.9255      7000\n",
      "\n",
      "    accuracy                         0.9264     14000\n",
      "   macro avg     0.9267    0.9264    0.9264     14000\n",
      "weighted avg     0.9267    0.9264    0.9264     14000\n",
      "\n",
      "=== Test-IID ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load: 100%|██████████| 14000/14000 [00:00<00:00, 20616.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test-IID] Acc=0.9289 | AUC=0.9706\n",
      "[[6607  393]\n",
      " [ 602 6398]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     real(0)     0.9165    0.9439    0.9300      7000\n",
      "     fake(1)     0.9421    0.9140    0.9279      7000\n",
      "\n",
      "    accuracy                         0.9289     14000\n",
      "   macro avg     0.9293    0.9289    0.9289     14000\n",
      "weighted avg     0.9293    0.9289    0.9289     14000\n",
      "\n",
      "=== Test-OOD ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load: 100%|██████████| 17570/17570 [00:00<00:00, 20814.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test-OOD] Acc=0.8542 | AUC=0.9401\n",
      "[[7207 1578]\n",
      " [ 984 7801]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     real(0)     0.8799    0.8204    0.8491      8785\n",
      "     fake(1)     0.8318    0.8880    0.8590      8785\n",
      "\n",
      "    accuracy                         0.8542     17570\n",
      "   macro avg     0.8558    0.8542    0.8540     17570\n",
      "weighted avg     0.8558    0.8542    0.8540     17570\n",
      "\n",
      "✅ saved: /home/yaya/ai-detect-proj/Script/saved_models/clip_pca256_svm_20250820_194313.joblib\n"
     ]
    }
   ],
   "source": [
    "# === StandardScaler + PCA(256) + LinearSVC（用你現有 splits） ===\n",
    "from pathlib import Path\n",
    "import json, numpy as np, time\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "SCRIPT_ROOT = \"/home/yaya/ai-detect-proj/Script\"\n",
    "SPLITS_JSON = f\"{SCRIPT_ROOT}/saved_models/splits_clip_feature_iid_ood.json\"\n",
    "OUTPUT_DIR  = f\"{SCRIPT_ROOT}/saved_models\"\n",
    "\n",
    "with open(SPLITS_JSON,\"r\",encoding=\"utf-8\") as f:\n",
    "    S = json.load(f)[\"splits\"]\n",
    "\n",
    "def load_vec(p):\n",
    "    v = np.asarray(np.load(p, allow_pickle=True), dtype=np.float32).reshape(-1)\n",
    "    n = np.linalg.norm(v) + 1e-12\n",
    "    return v/n\n",
    "\n",
    "def paths_labels(split):\n",
    "    r = S[split][\"clip\"][\"real\"]; f = S[split][\"clip\"][\"fake\"]\n",
    "    Xp = r+f; y = np.array([0]*len(r)+[1]*len(f))\n",
    "    idx = np.random.permutation(len(Xp))\n",
    "    return [Xp[i] for i in idx], y[idx]\n",
    "\n",
    "def feats(paths): return np.vstack([load_vec(p) for p in tqdm(paths, desc=\"load\")])\n",
    "\n",
    "tr_p,y_tr = paths_labels(\"train\"); va_p,y_va = paths_labels(\"val\")\n",
    "ti_p,y_ti = paths_labels(\"test_iid\"); to_p,y_to = paths_labels(\"test_ood\")\n",
    "\n",
    "X_tr = feats(tr_p); X_va = feats(va_p)\n",
    "\n",
    "scaler = StandardScaler(with_mean=True, with_std=True).fit(X_tr)\n",
    "X_tr_s = scaler.transform(X_tr); X_va_s = scaler.transform(X_va)\n",
    "\n",
    "pca_dim = 256\n",
    "pca = PCA(n_components=pca_dim, random_state=1337).fit(X_tr_s)\n",
    "X_tr_p = pca.transform(X_tr_s); X_va_p = pca.transform(X_va_s)\n",
    "\n",
    "clf = LinearSVC(C=1.0, class_weight=\"balanced\", max_iter=20000, dual=False).fit(X_tr_p, y_tr)\n",
    "\n",
    "def eval_block(name, paths, y):\n",
    "    if not paths: return\n",
    "    X = feats(paths); Xs = scaler.transform(X); Xp = pca.transform(Xs)\n",
    "    sc = clf.decision_function(Xp); pr = (sc>0).astype(int)\n",
    "    acc = accuracy_score(y, pr)\n",
    "    auc = roc_auc_score(y, sc)\n",
    "    print(f\"[{name}] Acc={acc:.4f} | AUC={auc:.4f}\")\n",
    "    print(confusion_matrix(y, pr))\n",
    "    print(classification_report(y, pr, target_names=[\"real(0)\",\"fake(1)\"], digits=4))\n",
    "\n",
    "print(\"=== Train ===\");   eval_block(\"Train\", tr_p, y_tr)\n",
    "print(\"=== Val ===\");     eval_block(\"Val\",   va_p, y_va)\n",
    "print(\"=== Test-IID ===\");eval_block(\"Test-IID\", ti_p, y_ti)\n",
    "print(\"=== Test-OOD ===\");eval_block(\"Test-OOD\", to_p, y_to)\n",
    "\n",
    "# 存模型（含 scaler/pca）\n",
    "import joblib, time\n",
    "stamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "joblib.dump({\"scaler\":scaler,\"pca\":pca,\"svc\":clf},\n",
    "            f\"{OUTPUT_DIR}/clip_pca256_svm_{stamp}.joblib\")\n",
    "print(\"✅ saved:\", f\"{OUTPUT_DIR}/clip_pca256_svm_{stamp}.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8960dc5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m base_svc = LinearSVC(C=\u001b[32m1.0\u001b[39m, class_weight=\u001b[33m\"\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m\"\u001b[39m, max_iter=\u001b[32m20000\u001b[39m, dual=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      7\u001b[39m cal = CalibratedClassifierCV(base_svc, method=\u001b[33m\"\u001b[39m\u001b[33msigmoid\u001b[39m\u001b[33m\"\u001b[39m, cv=\u001b[32m3\u001b[39m)  \u001b[38;5;66;03m# 或 method=\"isotonic\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mcal\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34meval_cal\u001b[39m(name, paths, y):\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m paths: \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/imgfeat/lib/python3.11/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/imgfeat/lib/python3.11/site-packages/sklearn/calibration.py:424\u001b[39m, in \u001b[36mCalibratedClassifierCV.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, **fit_params)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _ensemble:\n\u001b[32m    423\u001b[39m     parallel = Parallel(n_jobs=\u001b[38;5;28mself\u001b[39m.n_jobs)\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[38;5;28mself\u001b[39m.calibrated_classifiers_ = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_classifier_calibrator_pair\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m            \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m            \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m            \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    439\u001b[39m     this_estimator = clone(estimator)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/imgfeat/lib/python3.11/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/imgfeat/lib/python3.11/site-packages/joblib/parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/imgfeat/lib/python3.11/site-packages/joblib/parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/imgfeat/lib/python3.11/site-packages/sklearn/utils/parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/imgfeat/lib/python3.11/site-packages/sklearn/calibration.py:626\u001b[39m, in \u001b[36m_fit_classifier_calibrator_pair\u001b[39m\u001b[34m(estimator, X, y, train, test, method, classes, sample_weight, fit_params)\u001b[39m\n\u001b[32m    623\u001b[39m X_train, y_train = _safe_indexing(X, train), _safe_indexing(y, train)\n\u001b[32m    624\u001b[39m X_test, y_test = _safe_indexing(X, test), _safe_indexing(y, test)\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    628\u001b[39m predictions, _ = _get_response_values(\n\u001b[32m    629\u001b[39m     estimator,\n\u001b[32m    630\u001b[39m     X_test,\n\u001b[32m    631\u001b[39m     response_method=[\u001b[33m\"\u001b[39m\u001b[33mdecision_function\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpredict_proba\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    632\u001b[39m )\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m predictions.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m    634\u001b[39m     \u001b[38;5;66;03m# Reshape binary output from `(n_samples,)` to `(n_samples, 1)`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/imgfeat/lib/python3.11/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/imgfeat/lib/python3.11/site-packages/sklearn/svm/_classes.py:321\u001b[39m, in \u001b[36mLinearSVC.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    315\u001b[39m \u001b[38;5;28mself\u001b[39m.classes_ = np.unique(y)\n\u001b[32m    317\u001b[39m _dual = _validate_dual_parameter(\n\u001b[32m    318\u001b[39m     \u001b[38;5;28mself\u001b[39m.dual, \u001b[38;5;28mself\u001b[39m.loss, \u001b[38;5;28mself\u001b[39m.penalty, \u001b[38;5;28mself\u001b[39m.multi_class, X\n\u001b[32m    319\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m321\u001b[39m \u001b[38;5;28mself\u001b[39m.coef_, \u001b[38;5;28mself\u001b[39m.intercept_, n_iter_ = \u001b[43m_fit_liblinear\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mintercept_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_dual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[38;5;66;03m# Backward compatibility: _fit_liblinear is used both by LinearSVC/R\u001b[39;00m\n\u001b[32m    339\u001b[39m \u001b[38;5;66;03m# and LogisticRegression but LogisticRegression sets a structured\u001b[39;00m\n\u001b[32m    340\u001b[39m \u001b[38;5;66;03m# `n_iter_` attribute with information about the underlying OvR fits\u001b[39;00m\n\u001b[32m    341\u001b[39m \u001b[38;5;66;03m# while LinearSVC/R only reports the maximum value.\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[38;5;28mself\u001b[39m.n_iter_ = n_iter_.max().item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/imgfeat/lib/python3.11/site-packages/sklearn/svm/_base.py:1230\u001b[39m, in \u001b[36m_fit_liblinear\u001b[39m\u001b[34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[39m\n\u001b[32m   1227\u001b[39m sample_weight = _check_sample_weight(sample_weight, X, dtype=np.float64)\n\u001b[32m   1229\u001b[39m solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n\u001b[32m-> \u001b[39m\u001b[32m1230\u001b[39m raw_coef_, n_iter_ = \u001b[43mliblinear\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_wrap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_ind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m    \u001b[49m\u001b[43msp\u001b[49m\u001b[43m.\u001b[49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m    \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_weight_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrnd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43miinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mi\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[38;5;66;03m# Regarding rnd.randint(..) in the above signature:\u001b[39;00m\n\u001b[32m   1245\u001b[39m \u001b[38;5;66;03m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[39;00m\n\u001b[32m   1246\u001b[39m \u001b[38;5;66;03m# on 32-bit platforms, we can't get to the UINT_MAX limit that\u001b[39;00m\n\u001b[32m   1247\u001b[39m \u001b[38;5;66;03m# srand supports\u001b[39;00m\n\u001b[32m   1248\u001b[39m n_iter_max = \u001b[38;5;28mmax\u001b[39m(n_iter_)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# === 用 CalibratedClassifierCV 做校準 ===\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# 仍承接上一步的 StandardScaler/PCA（或你第一版的 X_tr/X_va 也可）\n",
    "base_svc = LinearSVC(C=1.0, class_weight=\"balanced\", max_iter=20000, dual=False)\n",
    "cal = CalibratedClassifierCV(base_svc, method=\"sigmoid\", cv=3)  # 或 method=\"isotonic\"\n",
    "cal.fit(X_tr_p, y_tr)\n",
    "\n",
    "def eval_cal(name, paths, y):\n",
    "    if not paths: return\n",
    "    X = feats(paths); Xs = scaler.transform(X); Xp = pca.transform(Xs)\n",
    "    proba = cal.predict_proba(Xp)[:,1]   # 機率：越大越像 fake\n",
    "    pred  = (proba > 0.5).astype(int)\n",
    "    acc = accuracy_score(y, pred)\n",
    "    try:\n",
    "        auc = roc_auc_score(y, proba)\n",
    "    except:\n",
    "        auc = float(\"nan\")\n",
    "    print(f\"[{name}] (calibrated) Acc={acc:.4f} | AUC={auc:.4f}\")\n",
    "    print(confusion_matrix(y, pred))\n",
    "    print(classification_report(y, pred, target_names=[\"real(0)\",\"fake(1)\"], digits=4))\n",
    "\n",
    "print(\"=== Calibrated on PCA256 ===\")\n",
    "eval_cal(\"Val\", va_p, y_va)\n",
    "eval_cal(\"Test-IID\", ti_p, y_ti)\n",
    "eval_cal(\"Test-OOD\", to_p, y_to)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgfeat (PyTorch)",
   "language": "python",
   "name": "imgfeat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
