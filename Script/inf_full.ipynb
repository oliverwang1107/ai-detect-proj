{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d4e29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CLIP: cuML LogisticRegressionï¼ˆlogitï¼‰\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Slide-256 Full-Image Inference (PRNU-CNN / ELA-CNN / CLIP-LogReg + LR Fusion)\n",
    "-----------------------------------------------------------------------------\n",
    "ç›®æ¨™ï¼šç”¨ 256Ã—256 è¦†è“‹æ•´å¼µåœ–ï¼ˆå¯é‡ç–Šï¼‰ï¼Œå°æ¯ä¸€å¡Šåšæ¨è«–ï¼Œè¼¸å‡ºï¼š\n",
    "  1) æ¯å¡Šçš„ logit èˆ‡æ©Ÿç‡ã€åº§æ¨™ã€é æ¸¬\n",
    "  2) ç–ŠåŠ å¯è¦–åŒ–ï¼ˆæ ¼å­ä¸Šè‰² + åŠé€æ˜ç†±åº¦è¦†è“‹ï¼‰\n",
    "  3) æ•´å¼µåœ–çš„å½™ç¸½çµæœï¼ˆå¤šç¨®åŒ¯ç¸½ç­–ç•¥ï¼‰\n",
    "\n",
    "ç‰¹é»ï¼š\n",
    "- é .jpg ä¾†æºæœƒå…ˆåšè‡¨æ™‚ .jpgï¼ˆEXIF æ–¹å‘ä¿®æ­£ã€RGBã€4:4:4, Q=95ï¼‰ï¼Œä»¥åˆ© ELA/CLIPï¼›\n",
    "  PRNU ç›´æ¥ç”¨ numpy tile è¨ˆç®—ï¼Œä¸å— jpg è½‰æª”å½±éŸ¿ã€‚\n",
    "- CLIP é‡å°æ¯å€‹ tile ç›´æ¥ç”¨ 256Ã—256 JPGï¼ˆ4:4:4, Q=95ï¼‰ï¼Œèˆ‡ Center-256 è¦æ ¼ä¸€è‡´ã€‚\n",
    "- èåˆé †åºå›ºå®š [PRNU, ELA, CLIP]ï¼Œå„ªå…ˆç”¨ sklearn LRï¼ˆfusion_lr.pklï¼‰ï¼Œå¦å‰‡ fallback æ¬Šé‡ã€‚\n",
    "\n",
    "å¯ç›´æ¥æ”¾åˆ° Jupyterï¼›ä¸‹æ–¹ __main__ çµ¦å‡ºç”¨æ³•ç¯„ä¾‹ã€‚\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import uuid\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Tuple\n",
    "\n",
    "# CUDA/encoding å»ºè­°\n",
    "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True,max_split_size_mb:128\")\n",
    "os.environ.setdefault(\"PYTHONUTF8\",\"1\")\n",
    "os.environ.setdefault(\"PYTHONIOENCODING\",\"utf-8\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image, ImageChops, ImageOps, ImageDraw, ImageFont\n",
    "from skimage import io as skio\n",
    "from skimage.util import img_as_float32\n",
    "from skimage.restoration import denoise_wavelet\n",
    "\n",
    "# è·¯å¾‘ï¼ˆç…§ä½ çš„å°ˆæ¡ˆï¼‰\n",
    "SCRIPT_ROOT     = Path(\"/home/yaya/ai-detect-proj/Script\")\n",
    "SAVED_MODELS    = SCRIPT_ROOT / \"saved_models\"\n",
    "\n",
    "PRNU_MODEL_PATH = SAVED_MODELS / \"prnu_fastcnn_best.pt\"\n",
    "ELA_MODEL_PATH  = SAVED_MODELS / \"ela_fastcnn_best.pt\"\n",
    "\n",
    "CLIP_LOGREG_PKL = SAVED_MODELS / \"clip_logreg_gpu.pkl\"    # cuML LogisticRegressionï¼ˆå»ºè­°ï¼‰\n",
    "CLIP_SVM_CUML   = SAVED_MODELS / \"clip_svm_gpu.pkl\"       # cuML SVMï¼ˆå›é€€ï¼‰\n",
    "CLIP_SVM_TORCH  = SAVED_MODELS / \"clip_svm_gpu_torch.pt\"  # Torch ç·šæ€§ SVMï¼ˆå›é€€ï¼‰\n",
    "CLIP_PLATT_PKL  = SAVED_MODELS / \"clip_platt.pkl\"         #ï¼ˆå¯é¸ï¼‰Platt æ¨™å®š\n",
    "\n",
    "FUSER_PKL       = SAVED_MODELS / \"fusion_lr.pkl\"\n",
    "FUSER_META      = SAVED_MODELS / \"fusion_lr_meta.json\"\n",
    "\n",
    "# åƒæ•¸\n",
    "SEED            = 42\n",
    "TILE            = 256      # tile å°ºå¯¸\n",
    "STRIDE          = 128      # æ­¥é•·ï¼ˆ128 = 50% é‡ç–Šï¼‰\n",
    "ELA_QUALITY     = 90\n",
    "ELA_SCALE       = 15\n",
    "ELA_FEASZ       = 128\n",
    "PRNU_MODE       = \"soft\"\n",
    "PRNU_WAVELET    = \"db8\"\n",
    "PRNU_Q_MODE     = \"per_file\"\n",
    "PRNU_Q_PERC     = 0.999\n",
    "PRNU_Q_SAMPLES  = 4096\n",
    "\n",
    "FORCE_JPG_NONJPG = True\n",
    "FORCE_JPG_FOR    = {\"ela\": True, \"clip\": True, \"prnu\": False}  # prnu ä¸ä¾è³´ jpg\n",
    "\n",
    "JPEG_FORCE_QUALITY     = 95\n",
    "JPEG_FORCE_SUBSAMPLING = 0     # 4:4:4\n",
    "\n",
    "CLIP_BACKBONE   = \"ViT-L-14\"\n",
    "CLIP_PRETRAINED = {\"ViT-L-14\":\"laion2b_s32b_b82k\",\"ViT-B-32\":\"laion400m_e32\",\"ViT-L-14-336\":\"laion2b_s32b_b82k\"}.get(CLIP_BACKBONE, \"laion2b_s32b_b82k\")\n",
    "\n",
    "# è£ç½®\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ========= å°å·¥å…· =========\n",
    "def _safe_logit(p: float, eps: float = 1e-6, clamp: float = 20.0) -> float:\n",
    "    p = float(np.clip(p, eps, 1.0 - eps))\n",
    "    z = math.log(p) - math.log(1.0 - p)\n",
    "    return float(np.clip(z, -clamp, clamp))\n",
    "\n",
    "def as_jpg_if_needed(p: Path,\n",
    "                     quality: int = JPEG_FORCE_QUALITY,\n",
    "                     subsampling: int | str = JPEG_FORCE_SUBSAMPLING) -> Tuple[Path, str | None]:\n",
    "    p = Path(p)\n",
    "    if p.suffix.lower() == \".jpg\":\n",
    "        return p, None\n",
    "    img = Image.open(p)\n",
    "    try:\n",
    "        img = ImageOps.exif_transpose(img)\n",
    "    except Exception:\n",
    "        pass\n",
    "    if img.mode != \"RGB\":\n",
    "        img = img.convert(\"RGB\")\n",
    "    tmp = p.with_suffix(f\".tmp_infer_{uuid.uuid4().hex[:8]}.jpg\")\n",
    "    buf = BytesIO(); img.save(buf, format=\"JPEG\", quality=int(quality), subsampling=subsampling)\n",
    "    with open(tmp, \"wb\") as f:\n",
    "        f.write(buf.getvalue())\n",
    "    return tmp, str(tmp)\n",
    "\n",
    "# ========= PRNU/ELA CNN =========\n",
    "class DSBlock(nn.Module):\n",
    "    def __init__(self, c_in, c_out, stride=1):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv2d(c_in, c_in, 3, stride=stride, padding=1, groups=c_in, bias=False)\n",
    "        self.bn1= nn.BatchNorm2d(c_in)\n",
    "        self.pw = nn.Conv2d(c_in, c_out, 1, bias=False)\n",
    "        self.bn2= nn.BatchNorm2d(c_out)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.bn1(self.dw(x)))\n",
    "        x = self.act(self.bn2(self.pw(x)))\n",
    "        return x\n",
    "\n",
    "class FastCNN_1ch(nn.Module):\n",
    "    def __init__(self, base=32, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.stem = nn.Sequential(nn.Conv2d(1, base, 3, padding=1, bias=False),\n",
    "                                  nn.BatchNorm2d(base), nn.ReLU(inplace=True))\n",
    "        self.stage= nn.Sequential(DSBlock(base,base*2,1), DSBlock(base*2,base*4,2),\n",
    "                                  DSBlock(base*4,base*4,1), DSBlock(base*4,base*8,2),\n",
    "                                  DSBlock(base*8,base*8,1))\n",
    "        self.head = nn.Sequential(nn.Conv2d(base*8, base*8, 1, bias=False),\n",
    "                                  nn.BatchNorm2d(base*8), nn.ReLU(inplace=True))\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1); self.fc = nn.Linear(base*8,2)\n",
    "    def forward(self, x):\n",
    "        x=self.stem(x); x=self.stage(x); x=self.head(x); x=self.pool(x).flatten(1); return self.fc(x)\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "def _safe_load(path, map_location=\"cpu\"):\n",
    "    try:\n",
    "        return torch.load(path, map_location=map_location, weights_only=True)\n",
    "    except TypeError:\n",
    "        return torch.load(path, map_location=map_location)\n",
    "\n",
    "def _extract_state_dict(blob):\n",
    "    if isinstance(blob, dict):\n",
    "        for k in (\"state_dict\",\"model\",\"weights\"):\n",
    "            if k in blob and isinstance(blob[k], dict):\n",
    "                sd = blob[k]; break\n",
    "        else:\n",
    "            sd = {k:v for k,v in blob.items() if torch.is_tensor(v)}\n",
    "            if not sd: raise RuntimeError(\"æœªçŸ¥ checkpoint æ ¼å¼\")\n",
    "    elif isinstance(blob, torch.nn.Module):\n",
    "        sd = blob.state_dict()\n",
    "    else:\n",
    "        sd = blob\n",
    "    if len(sd)>0 and next(iter(sd)).startswith(\"module.\"):\n",
    "        sd = OrderedDict((k[len(\"module.\"):], v) for k,v in sd.items())\n",
    "    return sd\n",
    "\n",
    "prnu_model = FastCNN_1ch().to(device).eval()\n",
    "ela_model  = FastCNN_1ch().to(device).eval()\n",
    "prnu_model.load_state_dict(_extract_state_dict(_safe_load(PRNU_MODEL_PATH, device)))\n",
    "ela_model .load_state_dict(_extract_state_dict(_safe_load(ELA_MODEL_PATH,  device)))\n",
    "\n",
    "@torch.no_grad()\n",
    "def prnu_logit_from_i8(arr_i8: np.ndarray) -> float:\n",
    "    a = arr_i8\n",
    "    if a.dtype == np.int8:\n",
    "        x = a.astype(np.float32) / 127.0\n",
    "    elif a.dtype == np.uint8:\n",
    "        x = a.astype(np.float32) / 255.0\n",
    "    else:\n",
    "        x = a.astype(np.float32); x = x/255.0 if x.max()>1.5 else x\n",
    "    x = x - x.mean()\n",
    "    t = torch.from_numpy(x[None,None,...]).to(device)\n",
    "    p1 = torch.softmax(prnu_model(t), dim=1)[0,1].item()\n",
    "    return _safe_logit(p1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def ela_logit_from_i8(arr_i8: np.ndarray) -> float:\n",
    "    a = arr_i8\n",
    "    if a.dtype == np.int8:\n",
    "        x = (a.astype(np.float32) + 128.0) / 255.0  # offset128\n",
    "    elif a.dtype == np.uint8:\n",
    "        x = a.astype(np.float32) / 255.0\n",
    "    else:\n",
    "        x = a.astype(np.float32); x = x/255.0 if x.max()>1.5 else x\n",
    "    x = x - x.mean()\n",
    "    t = torch.from_numpy(x[None,None,...]).to(device)\n",
    "    p1 = torch.softmax(ela_model(t), dim=1)[0,1].item()\n",
    "    return _safe_logit(p1)\n",
    "\n",
    "# ========= open_clip + CLIP åˆ†æ”¯ =========\n",
    "_openclip = {\"model\":None,\"pre\":None,\"dev\":\"cpu\"}\n",
    "\n",
    "def _cuml_ok():\n",
    "    try:\n",
    "        import cuml, cupy  # noqa: F401\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "@torch.no_grad()\n",
    "def load_openclip():\n",
    "    if _openclip[\"model\"] is None:\n",
    "        import open_clip\n",
    "        dev = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        model, _, pre = open_clip.create_model_and_transforms(CLIP_BACKBONE, pretrained=CLIP_PRETRAINED)\n",
    "        model = model.to(dev).eval()\n",
    "        _openclip.update(model=model, pre=pre, dev=dev)\n",
    "    return _openclip[\"model\"], _openclip[\"pre\"], _openclip[\"dev\"]\n",
    "\n",
    "class CLIPSingle:\n",
    "    def __init__(self):\n",
    "        self.mode=None; self.backend=None; self.model=None; self.D=None; self.platt=None\n",
    "        self._load()\n",
    "    def _load(self):\n",
    "        # cuML LRï¼ˆå„ªå…ˆï¼‰\n",
    "        if CLIP_LOGREG_PKL.exists():\n",
    "            import joblib\n",
    "            obj = joblib.load(CLIP_LOGREG_PKL)\n",
    "            self.model = obj[\"model\"] if isinstance(obj, dict) and \"model\" in obj else obj\n",
    "            self.mode, self.backend, self.D = \"logreg\", \"cuml\", 1024\n",
    "            print(\"âœ… CLIP: cuML LogisticRegressionï¼ˆlogitï¼‰\"); return\n",
    "        # cuML SVMï¼ˆå›é€€ï¼‰\n",
    "        if CLIP_SVM_CUML.exists() and _cuml_ok():\n",
    "            import joblib\n",
    "            clf = joblib.load(CLIP_SVM_CUML)\n",
    "            self.model = clf[\"model\"] if isinstance(clf, dict) and \"model\" in clf else clf\n",
    "            self.mode, self.backend, self.D = \"svm\", \"cuml\", 1024\n",
    "            print(\"âš ï¸ CLIP: cuML SVMï¼ˆmarginï¼‰\")\n",
    "        # Torch ç·šæ€§ SVMï¼ˆå›é€€ï¼‰\n",
    "        elif CLIP_SVM_TORCH.exists():\n",
    "            sd = _safe_load(CLIP_SVM_TORCH, \"cpu\")\n",
    "            state = sd[\"state_dict\"] if isinstance(sd, dict) and \"state_dict\" in sd else sd\n",
    "            self.D = int(sd[\"D\"]) if isinstance(sd, dict) and \"D\" in sd else state[\"weight\"].shape[1]\n",
    "            lin = nn.Linear(self.D, 1, bias=True).eval(); lin.load_state_dict(state)\n",
    "            self.model = lin; self.mode, self.backend = \"svm\", \"torch\"\n",
    "            print(f\"âš ï¸ CLIP: Torch SVMï¼ˆmargin, D={self.D}ï¼‰\")\n",
    "        else:\n",
    "            print(\"â„¹ï¸ æœªæ‰¾åˆ° CLIP åˆ†é¡å™¨ï¼ˆè·³é CLIPï¼‰\")\n",
    "            return\n",
    "        # å¯é¸ï¼šPlatt\n",
    "        if self.mode == \"svm\" and CLIP_PLATT_PKL.exists():\n",
    "            import joblib\n",
    "            try:\n",
    "                self.platt = joblib.load(CLIP_PLATT_PKL)\n",
    "                print(\"âœ… è¼‰å…¥ Platt æ¨™å®šå™¨ï¼ˆSVM â†’ probï¼‰\")\n",
    "            except Exception as e:\n",
    "                print(\"âš ï¸ Platt è¼‰å…¥å¤±æ•—ï¼š\", e)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict_logit(self, pil_tile_256: Image.Image) -> float | None:\n",
    "        if self.model is None: return None\n",
    "        # ç›´æ¥æŠŠ 256Ã—256 tile å¦å­˜ç‚ºè‡¨æ™‚ JPGï¼Œä¿æŒèˆ‡ Center-256 ä¸€è‡´\n",
    "        tmp = Path(f\"/tmp/clip_tile_{uuid.uuid4().hex[:8]}.jpg\")\n",
    "        buf = BytesIO(); pil_tile_256.save(buf, format=\"JPEG\", quality=95, subsampling=0)\n",
    "        with open(tmp, \"wb\") as f: f.write(buf.getvalue())\n",
    "        try:\n",
    "            model, pre, dev = load_openclip()\n",
    "            img = Image.open(tmp).convert(\"RGB\")\n",
    "            im  = pre(img).unsqueeze(0).to(dev)\n",
    "            visual = model.visual\n",
    "            tokens=None\n",
    "            def _apply_norm(x):\n",
    "                if x.ndim==2: x=x.unsqueeze(0)\n",
    "                if hasattr(visual, \"ln_post\") and visual.ln_post is not None:\n",
    "                    x = visual.ln_post(x)\n",
    "                elif hasattr(visual, \"trunk\") and hasattr(visual.trunk, \"norm\") and visual.trunk.norm is not None:\n",
    "                    x = visual.trunk.norm(x)\n",
    "                return x.squeeze(0)\n",
    "            # å˜—è©¦æŠ“ token map\n",
    "            ok=False\n",
    "            for try_path in (\"trunk.forward_features\",\"visual.forward_features\",\"hook\"):\n",
    "                try:\n",
    "                    if try_path==\"trunk.forward_features\" and hasattr(visual,\"trunk\") and hasattr(visual.trunk,\"forward_features\"):\n",
    "                        out = visual.trunk.forward_features(im)\n",
    "                        if isinstance(out,(tuple,list)): out=out[0]\n",
    "                        if isinstance(out,dict): out=out.get(\"x\", out.get(\"tokens\", out))\n",
    "                        if torch.is_tensor(out) and out.ndim==3:\n",
    "                            tokens=_apply_norm(out.detach()); ok=True; break\n",
    "                    if try_path==\"visual.forward_features\" and hasattr(visual,\"forward_features\"):\n",
    "                        out = visual.forward_features(im)\n",
    "                        if isinstance(out,(tuple,list)): out=out[0]\n",
    "                        if isinstance(out,dict): out=out.get(\"x\", out.get(\"tokens\", out))\n",
    "                        if torch.is_tensor(out) and out.ndim==3:\n",
    "                            tokens=_apply_norm(out.detach()); ok=True; break\n",
    "                    if try_path==\"hook\":\n",
    "                        feats={}; h=None\n",
    "                        try:\n",
    "                            if hasattr(visual,\"trunk\") and hasattr(visual.trunk,\"blocks\") and len(visual.trunk.blocks)>0:\n",
    "                                target=visual.trunk.blocks[-1]\n",
    "                                def _hook(_m,_i,o): feats[\"x\"]=o\n",
    "                                h=target.register_forward_hook(_hook)\n",
    "                                _ = getattr(visual.trunk, \"forward_features\", visual.trunk.forward)(im)\n",
    "                            elif hasattr(visual,\"transformer\") and hasattr(visual.transformer,\"resblocks\") and len(visual.transformer.resblocks)>0:\n",
    "                                target=visual.transformer.resblocks[-1]\n",
    "                                def _hook(_m,_i,o): feats[\"x\"]=o\n",
    "                                h=target.register_forward_hook(_hook); _=model.encode_image(im)\n",
    "                        finally:\n",
    "                            if h is not None:\n",
    "                                try: h.remove()\n",
    "                                except Exception: pass\n",
    "                        x=feats.get(\"x\",None)\n",
    "                        if torch.is_tensor(x) and x.ndim==3:\n",
    "                            tokens=_apply_norm(x.detach()); ok=True; break\n",
    "                except Exception:\n",
    "                    pass\n",
    "            if not ok:\n",
    "                # ä¿åº•ï¼šå– ln_post CLSï¼ˆé€™è£¡æ²’æœ‰åˆ†é¡å™¨æ™‚ä¸è¿”å›ï¼‰\n",
    "                return None\n",
    "            tokens = tokens.float().cpu().numpy().astype(np.float32)\n",
    "            if tokens.shape[0] <= 1: return None\n",
    "            pooled = tokens[1:].mean(axis=0)\n",
    "            pooled /= (np.linalg.norm(pooled)+1e-12)\n",
    "            # æ±ºç­–\n",
    "            if self.backend == \"cuml\":\n",
    "                import cupy as cp\n",
    "                s = self.model.decision_function(cp.asarray(pooled[None,:])).get().astype(np.float32)[0]\n",
    "                return float(np.clip(s, -20.0, 20.0))\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    s = self.model(torch.from_numpy(pooled[None,:]).float()).squeeze(1).numpy().astype(np.float32)[0]\n",
    "                if self.mode == \"svm\" and self.platt is not None:\n",
    "                    from sklearn.linear_model import LogisticRegression  # noqa\n",
    "                    import numpy as _np\n",
    "                    p = float(self.platt.predict_proba(_np.array(s, _np.float32).reshape(1,1))[:,1][0])\n",
    "                    return _safe_logit(p)\n",
    "                return float(np.clip(s, -20.0, 20.0))\n",
    "        finally:\n",
    "            try: os.unlink(tmp)\n",
    "            except Exception: pass\n",
    "\n",
    "clip_single = CLIPSingle()\n",
    "\n",
    "# ========= èåˆå™¨ =========\n",
    "def read_json_utf8(p: Path):\n",
    "    with p.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_fuser_and_meta():\n",
    "    meta=None; kind=\"dummy\"; fuser=None\n",
    "    try:\n",
    "        if FUSER_PKL.exists():\n",
    "            import joblib\n",
    "            fuser = joblib.load(FUSER_PKL); kind=\"lr\"\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ fusion_lr.pkl è¼‰å…¥å¤±æ•—ï¼š\", e)\n",
    "    if FUSER_META.exists():\n",
    "        try: meta = read_json_utf8(FUSER_META)\n",
    "        except Exception as e: print(\"âš ï¸ fusion_lr_meta.json è®€å–å¤±æ•—ï¼š\", e)\n",
    "    return kind, fuser, meta\n",
    "\n",
    "fuser_kind, fuser, fmeta = load_fuser_and_meta()\n",
    "\n",
    "def fuse_logits(logits_dict: Dict[str, float | None]) -> float:\n",
    "    keys = [\"prnu\",\"ela\",\"clip\"]\n",
    "    z = [float(np.nan_to_num(logits_dict.get(k,0.0), nan=0.0, posinf=20.0, neginf=-20.0)) for k in keys]\n",
    "    X = np.array([z], np.float32)\n",
    "    if fuser_kind == \"lr\":\n",
    "        try:\n",
    "            proba = fuser.predict_proba(X)[:,1][0]\n",
    "            return float(np.clip(proba, 1e-6, 1-1e-6))\n",
    "        except Exception as e:\n",
    "            print(\"âš ï¸ èåˆå™¨å¤±æ•—ï¼Œfallbackï¼š\", e)\n",
    "    if fmeta and \"weights_if_no_sklearn\" in fmeta:\n",
    "        w = np.array(fmeta[\"weights_if_no_sklearn\"], np.float32); w = w/(w.sum()+1e-12)\n",
    "    else:\n",
    "        w = np.array([1/3,1/3,1/3], np.float32)\n",
    "    zz = float(np.clip(np.dot(X[0], w), -20.0, 20.0))\n",
    "    return float(1.0 / (1.0 + np.exp(-zz)))\n",
    "\n",
    "# ========= ç‰¹å¾µæŠ½å–ï¼ˆtile ç´šï¼‰ =========\n",
    "def _to_int8_offset128_from_01(x01: np.ndarray) -> np.ndarray:\n",
    "    u8 = np.rint(np.clip(x01, 0.0, 1.0) * 255.0).astype(np.uint8)\n",
    "    return (u8.astype(np.int16) - 128).astype(np.int8)\n",
    "\n",
    "def ela_i8_from_tile(pil_tile_256: Image.Image) -> np.ndarray:\n",
    "    buf = BytesIO(); pil_tile_256.save(buf, format=\"JPEG\", quality=int(ELA_QUALITY), subsampling=0, optimize=False)\n",
    "    buf.seek(0)\n",
    "    diff = ImageChops.difference(pil_tile_256, Image.open(buf)).point(lambda x: x * ELA_SCALE)\n",
    "    diff = diff.convert(\"L\").resize((ELA_FEASZ, ELA_FEASZ))\n",
    "    arr01 = np.asarray(diff, dtype=np.float32) / 255.0\n",
    "    return _to_int8_offset128_from_01(arr01)\n",
    "\n",
    "def prnu_i8_from_tile(np_tile_rgb: np.ndarray) -> np.ndarray:\n",
    "    if np_tile_rgb.ndim == 2:\n",
    "        np_tile_rgb = np.repeat(np_tile_rgb[...,None], 3, axis=-1)\n",
    "    gray = np_tile_rgb.mean(axis=2, dtype=np.float32)\n",
    "    try:\n",
    "        den = denoise_wavelet(gray, channel_axis=None, mode=PRNU_MODE, wavelet=PRNU_WAVELET, convert2ycbcr=False)\n",
    "    except TypeError:\n",
    "        den = denoise_wavelet(gray, multichannel=False, mode=PRNU_MODE, wavelet=PRNU_WAVELET, convert2ycbcr=False)\n",
    "    residual = gray - den\n",
    "    residual -= residual.mean()\n",
    "    if PRNU_Q_MODE == \"per_file\":\n",
    "        v = residual.reshape(-1).astype(np.float32, copy=False)\n",
    "        if v.size > PRNU_Q_SAMPLES:\n",
    "            rng = np.random.default_rng(SEED)\n",
    "            idx = rng.integers(0, v.size, size=PRNU_Q_SAMPLES, endpoint=False)\n",
    "            v = np.abs(v[idx])\n",
    "        else:\n",
    "            v = np.abs(v)\n",
    "        k = int(PRNU_Q_PERC * max(1, v.size-1))\n",
    "        S = float(max(1e-8, np.partition(v, k)[k]))\n",
    "    else:\n",
    "        S = max(1e-6, float(np.std(residual)) * 6.0)\n",
    "    x = np.clip(residual, -S, S) / S * 127.0\n",
    "    q = np.rint(x).astype(np.int16)\n",
    "    q = np.clip(q, -127, 127).astype(np.int8)\n",
    "    return q\n",
    "\n",
    "# ========= è¦†è“‹åº§æ¨™ =========\n",
    "def make_grid(w: int, h: int, tile: int = TILE, stride: int = STRIDE) -> List[Tuple[int,int,int,int]]:\n",
    "    xs = list(range(0, max(1, w - tile + 1), stride))\n",
    "    ys = list(range(0, max(1, h - tile + 1), stride))\n",
    "    if xs[-1] != w - tile: xs.append(max(0, w - tile))\n",
    "    if ys[-1] != h - tile: ys.append(max(0, h - tile))\n",
    "    coords = [(x, y, tile, tile) for y in ys for x in xs]\n",
    "    return coords\n",
    "\n",
    "# ========= å¯è¦–åŒ– =========\n",
    "# --- é‡æ–‡å­—å¤§å°ï¼šå…¼å®¹ Pillow èˆŠæ–°ç‰ˆæœ¬ ---\n",
    "def _text_size(draw, text, font):\n",
    "    # Pillow â‰¥10\n",
    "    if hasattr(draw, \"textbbox\"):\n",
    "        l, t, r, b = draw.textbbox((0, 0), text, font=font)\n",
    "        return (r - l), (b - t)\n",
    "    # å¾Œå‚™ï¼šæœ‰äº›ç‰ˆæœ¬åœ¨ font ç‰©ä»¶ä¸Š\n",
    "    if hasattr(font, \"getbbox\"):\n",
    "        l, t, r, b = font.getbbox(text)\n",
    "        return (r - l), (b - t)\n",
    "    # èˆŠç‰ˆ\n",
    "    if hasattr(font, \"getsize\"):\n",
    "        return font.getsize(text)\n",
    "    # æœ€å¾Œçš„ä¿åº•ä¼°è¨ˆ\n",
    "    return (8 * len(text), 12)\n",
    "\n",
    "def overlay_tiles(base_img: Image.Image,\n",
    "                  tiles: list[dict],\n",
    "                  alpha: float = 0.35,\n",
    "                  draw_frame: bool = True,\n",
    "                  show_score: bool = True) -> Image.Image:\n",
    "    W, H = base_img.size\n",
    "\n",
    "    # ä»¥æ¯åƒç´ å¹³å‡æ©Ÿç‡åšç†±åº¦åœ–\n",
    "    heat = np.zeros((H, W), dtype=np.float32)\n",
    "    cnt  = np.zeros((H, W), dtype=np.float32)\n",
    "    for t in tiles:\n",
    "        x, y, w, h = t['x'], t['y'], t['w'], t['h']\n",
    "        p = float(t['prob_fake'])\n",
    "        heat[y:y+h, x:x+w] += p\n",
    "        cnt [y:y+h, x:x+w] += 1.0\n",
    "    cnt[cnt == 0] = 1.0\n",
    "    heat = heat / cnt\n",
    "    heat_u8 = np.rint(np.clip(heat, 0.0, 1.0) * 255.0).astype(np.uint8)\n",
    "\n",
    "    # è½‰ç‚ºç´…è‰²ç†±åœ–ï¼ˆR=heat, G=0, B=0ï¼‰\n",
    "    heat_rgb = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "    heat_rgb[..., 0] = heat_u8\n",
    "    base_rgb = base_img.convert('RGB')\n",
    "    heat_img = Image.fromarray(heat_rgb, mode='RGB')\n",
    "\n",
    "    # æ··åˆå¾Œè½‰ RGBAï¼Œæ–¹ä¾¿ç•«åŠé€æ˜æ¨™ç±¤\n",
    "    overlay = Image.blend(base_rgb, heat_img, alpha).convert('RGBA')\n",
    "    draw = ImageDraw.Draw(overlay, 'RGBA')\n",
    "\n",
    "    # å­—å‹\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\", 16)\n",
    "    except Exception:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    if draw_frame or show_score:\n",
    "        for t in tiles:\n",
    "            x, y, w, h = t['x'], t['y'], t['w'], t['h']\n",
    "            p  = float(t['prob_fake'])\n",
    "            lab = int(t['pred_label'])\n",
    "            color = (255, 0, 0, 255) if lab == 1 else (0, 255, 0, 255)\n",
    "\n",
    "            if draw_frame:\n",
    "                draw.rectangle([x, y, x + w, y + h], outline=color, width=2)\n",
    "\n",
    "            if show_score:\n",
    "                txt = f\"{p:.2f}\"\n",
    "                tw, th = _text_size(draw, txt, font)\n",
    "                # é»‘åº•åŠé€æ˜æ–‡å­—æ¡†\n",
    "                draw.rectangle([x, y, x + tw + 6, y + th + 4], fill=(0, 0, 0, 127))\n",
    "                draw.text((x + 3, y + 2), txt, fill=(255, 255, 255, 255), font=font)\n",
    "\n",
    "    return overlay\n",
    "\n",
    "\n",
    "# ========= ä¸»æµç¨‹ï¼šæ•´å¼µåœ–ï¼ˆtileï¼‰æ¨è«– =========\n",
    "def infer_image_by_tiles(img_path: str | Path,\n",
    "                         tile: int = TILE,\n",
    "                         stride: int = STRIDE,\n",
    "                         aggregate: str = 'mean_prob',  # 'mean_prob'|'max_prob'|'topk_mean:0.2'|'mean_logit'\n",
    "                         use_clip: bool = True,\n",
    "                         save_overlay: bool = True,\n",
    "                         overlay_alpha: float = 0.35) -> Dict[str, Any]:\n",
    "    p = Path(img_path)\n",
    "    tmp_files = []\n",
    "    # åŸåœ–ï¼ˆåƒ…ä¾› ELA/CLIP çš„ jpg æµç¨‹éœ€è¦ï¼›PRNU èµ° numpy tileï¼‰\n",
    "    if FORCE_JPG_NONJPG:\n",
    "        p_jpg, t1 = as_jpg_if_needed(p); \n",
    "        if t1: tmp_files.append(t1)\n",
    "    else:\n",
    "        p_jpg = p\n",
    "\n",
    "    # è®€åœ–ï¼ˆçµ¦ tile è£åˆ‡ï¼‰\n",
    "    img_pil = Image.open(p_jpg).convert('RGB')\n",
    "    W,H = img_pil.size\n",
    "    coords = make_grid(W, H, tile=tile, stride=stride)\n",
    "\n",
    "    tiles_out: List[Dict[str, Any]] = []\n",
    "\n",
    "    # ä¹Ÿæº–å‚™ä¸€ä»½ numpyï¼ˆPRNU ç”¨ï¼‰ï¼Œä»¥åŸå§‹æª”è·¯å¾‘è®€ï¼Œé¿å…é‡å£“ç¸®å½±éŸ¿\n",
    "    np_img = np.asarray(Image.open(p).convert('RGB'), dtype=np.uint8)\n",
    "\n",
    "    for (x,y,w,h) in coords:\n",
    "        pil_tile = img_pil.crop((x,y,x+w,y+h))\n",
    "        np_tile  = np.asarray(np_img[y:y+h, x:x+w, :], dtype=np.uint8)\n",
    "\n",
    "        # ç‰¹å¾µ\n",
    "        prnu_i8 = prnu_i8_from_tile(np_tile)\n",
    "        ela_i8  = ela_i8_from_tile(pil_tile)\n",
    "\n",
    "        # ä¸‰è·¯ logit\n",
    "        z_prnu = prnu_logit_from_i8(prnu_i8)\n",
    "        z_ela  = ela_logit_from_i8(ela_i8)\n",
    "        z_clip = clip_single.predict_logit(pil_tile) if (use_clip and clip_single.model is not None) else None\n",
    "\n",
    "        prob_fake = fuse_logits({\"prnu\": z_prnu, \"ela\": z_ela, \"clip\": z_clip})\n",
    "        pred = int(prob_fake >= 0.5)\n",
    "\n",
    "        tiles_out.append({\n",
    "            \"x\":x, \"y\":y, \"w\":w, \"h\":h,\n",
    "            \"prnu_logit\": float(z_prnu),\n",
    "            \"ela_logit\":  float(z_ela),\n",
    "            \"clip_logit\": (None if z_clip is None else float(z_clip)),\n",
    "            \"prob_fake\": float(prob_fake),\n",
    "            \"pred_label\": pred,\n",
    "        })\n",
    "\n",
    "    # åŒ¯ç¸½ç­–ç•¥\n",
    "    probs = np.array([t['prob_fake'] for t in tiles_out], np.float32)\n",
    "    if aggregate == 'mean_prob':\n",
    "        whole_prob = float(np.clip(probs.mean() if len(probs)>0 else 0.0, 1e-6, 1-1e-6))\n",
    "    elif aggregate == 'max_prob':\n",
    "        whole_prob = float(np.clip(probs.max() if len(probs)>0 else 0.0, 1e-6, 1-1e-6))\n",
    "    elif aggregate.startswith('topk_mean'):\n",
    "        try:\n",
    "            frac = float(aggregate.split(':',1)[1]) if ':' in aggregate else 0.2\n",
    "        except Exception:\n",
    "            frac = 0.2\n",
    "        k = max(1, int(len(probs) * frac))\n",
    "        idx = np.argsort(-probs)[:k]\n",
    "        whole_prob = float(np.clip(probs[idx].mean(), 1e-6, 1-1e-6))\n",
    "    elif aggregate == 'mean_logit':\n",
    "        lgs = np.array([_safe_logit(float(p)) for p in probs], np.float32)\n",
    "        lg  = float(np.clip(lgs.mean() if len(lgs)>0 else 0.0, -20.0, 20.0))\n",
    "        whole_prob = float(1.0/(1.0+np.exp(-lg)))\n",
    "    else:\n",
    "        whole_prob = float(np.clip(probs.mean() if len(probs)>0 else 0.0, 1e-6, 1-1e-6))\n",
    "\n",
    "    whole_pred = int(whole_prob >= 0.5)\n",
    "\n",
    "    overlay_path = None\n",
    "    if save_overlay:\n",
    "        overlay_img = overlay_tiles(Image.open(p).convert('RGB'), tiles_out, alpha=overlay_alpha,\n",
    "                                    draw_frame=True, show_score=True)\n",
    "        overlay_path = str(p.with_suffix(\".tiles_overlay.png\"))\n",
    "        overlay_img.save(overlay_path)\n",
    "\n",
    "    out = {\n",
    "        \"path\": str(p),\n",
    "        \"image_size\": [H, W],\n",
    "        \"tile\": tile,\n",
    "        \"stride\": stride,\n",
    "        \"aggregate\": aggregate,\n",
    "        \"overall\": {\"prob_fake\": float(whole_prob), \"pred_label\": int(whole_pred)},\n",
    "        \"tiles\": tiles_out,\n",
    "        \"overlay_path\": overlay_path,\n",
    "    }\n",
    "\n",
    "    # æ¸…ç†è‡¨æ™‚æª”\n",
    "    for t in tmp_files:\n",
    "        try: os.unlink(t)\n",
    "        except Exception: pass\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd67d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08198eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… pillow-heif registered\n",
      "âœ… pillow-avif registered\n",
      "HEIC/AVIF support is ready. ğŸ‰\n"
     ]
    }
   ],
   "source": [
    "# ==== HEIC/HEIF/AVIF æ”¯æ´ï¼ˆè¨»å†Šå¤–æ› + å¼·åŒ–é–‹åœ–èˆ‡è½‰JPGï¼‰====\n",
    "\n",
    "# 1) è¨»å†Šè§£ç¢¼å™¨ï¼ˆå¯å¤šæ¬¡å‘¼å«ï¼Œç„¡å‰¯ä½œç”¨ï¼‰\n",
    "def _register_heif_avif():\n",
    "    ok = False\n",
    "    try:\n",
    "        import pillow_heif\n",
    "        pillow_heif.register_heif_opener()\n",
    "        ok = True\n",
    "        print(\"âœ… pillow-heif registered\")\n",
    "    except Exception as e:\n",
    "        print(\"â„¹ï¸ pillow-heif not available:\", e)\n",
    "    try:\n",
    "        # åŒ¯å…¥å³å®Œæˆ AVIF è¨»å†Š\n",
    "        import pillow_avif  # noqa: F401\n",
    "        from pillow_avif import AvifImagePlugin  # noqa: F401\n",
    "        ok = True or ok\n",
    "        print(\"âœ… pillow-avif registered\")\n",
    "    except Exception as e:\n",
    "        print(\"â„¹ï¸ pillow-avif not available:\", e)\n",
    "    return ok\n",
    "\n",
    "_register_heif_avif()\n",
    "\n",
    "# 2) æ›´ç©©çš„é–‹åœ–ï¼ˆå¿…è¦æ™‚ç›´æ¥ç”¨ pillow_heif è®€ï¼‰\n",
    "from PIL import Image\n",
    "\n",
    "def _open_image_any(p: Path) -> Image.Image:\n",
    "    p = Path(p)\n",
    "    try:\n",
    "        img = Image.open(p)\n",
    "        img.load()  # ç«‹åˆ»è®€å…¥ï¼Œé¿å…å»¶å¾Œæ‰å ±éŒ¯\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        # é‡å° heif/avif å†è©¦ä¸€æ¬¡ï¼ˆä¸é  PIL openerï¼‰\n",
    "        suf = p.suffix.lower()\n",
    "        if suf in {\".heic\", \".heif\", \".heifs\", \".hif\", \".avif\"}:\n",
    "            try:\n",
    "                import pillow_heif\n",
    "                h = pillow_heif.read_heif(str(p))\n",
    "                img = Image.frombytes(h.mode, h.size, h.data, \"raw\")\n",
    "                return img\n",
    "            except Exception as e2:\n",
    "                raise RuntimeError(f\"HEIF/AVIF decode failed: {e2}\") from e2\n",
    "        raise\n",
    "\n",
    "def _to_rgb_no_alpha(img: Image.Image) -> Image.Image:\n",
    "    # å…ˆå¥—ç”¨ EXIF æ–¹å‘\n",
    "    try:\n",
    "        from PIL import ImageOps\n",
    "        img = ImageOps.exif_transpose(img)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # å»é™¤ alphaï¼ˆç™½åº•è²¼ä¸Šï¼‰\n",
    "    if img.mode in (\"RGBA\", \"LA\") or (img.mode == \"P\" and \"transparency\" in img.info):\n",
    "        bg = Image.new(\"RGB\", img.size, (255, 255, 255))\n",
    "        bg.paste(img.convert(\"RGBA\"), mask=img.convert(\"RGBA\").split()[-1])\n",
    "        return bg\n",
    "    # å…¶ä»–è‰²å½©ç©ºé–“çµ±ä¸€åˆ° RGB\n",
    "    if img.mode != \"RGB\":\n",
    "        return img.convert(\"RGB\")\n",
    "    return img\n",
    "\n",
    "# 3) å–ä»£ä½ åŸæœ¬çš„ as_jpg_if_neededï¼ˆæ“´å…… .jpeg èˆ‡ heic/avifï¼‰\n",
    "def as_jpg_if_needed(p: Path,\n",
    "                     quality: int = 95,\n",
    "                     subsampling: int | str = 0) -> Tuple[Path, str | None]:\n",
    "    \"\"\"\n",
    "    - è‹¥åŸæª”å·²æ˜¯ .jpg/.jpegï¼šç›´æ¥å›å‚³åŸè·¯å¾‘\n",
    "    - å¦å‰‡é–‹åœ–ï¼ˆå« HEIC/AVIFï¼‰ï¼Œåš EXIF æ–¹å‘ã€å» alphaã€è½‰ RGBï¼Œå­˜è‡¨æ™‚ JPGï¼ˆ4:4:4, Q=qualityï¼‰\n",
    "    \"\"\"\n",
    "    p = Path(p)\n",
    "    if p.suffix.lower() in {\".jpg\", \".jpeg\"}:\n",
    "        return p, None\n",
    "\n",
    "    # ç”¨å¼·åŒ–ç‰ˆé–‹åœ– + è¦ç¯„æˆ RGB ç„¡ alpha\n",
    "    img = _open_image_any(p)\n",
    "    img = _to_rgb_no_alpha(img)\n",
    "\n",
    "    # è¼¸å‡ºè‡¨æ™‚ JPGï¼ˆèˆ‡ä½ åŸé‚è¼¯ä¸€è‡´ï¼š4:4:4, Q=95ï¼‰\n",
    "    tmp = p.with_suffix(f\".tmp_infer_{uuid.uuid4().hex[:8]}.jpg\")\n",
    "    buf = BytesIO()\n",
    "    img.save(buf, format=\"JPEG\", quality=int(quality), subsampling=subsampling, optimize=False)\n",
    "    with open(tmp, \"wb\") as f:\n",
    "        f.write(buf.getvalue())\n",
    "    return tmp, str(tmp)\n",
    "\n",
    "# === ä¹Ÿå»ºè­°æŠŠ PRNU ç«¯çš„è®€å–æ”¹ç”¨ _open_image_anyï¼Œç¢ºä¿ HEIC å¯è®€ ===\n",
    "# åœ¨ infer_image_by_tiles è£¡é€™è¡Œï¼š\n",
    "#   np_img = np.asarray(Image.open(p).convert('RGB'), dtype=np.uint8)\n",
    "# æ›æˆï¼š\n",
    "#   np_img = np.asarray(_to_rgb_no_alpha(_open_image_any(p)), dtype=np.uint8)\n",
    "\n",
    "print(\"HEIC/AVIF support is ready. ğŸ‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7d0e8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Gradio UI with progress (drop-in) ===\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import tempfile, json, math\n",
    "\n",
    "def _aggregate_probs(probs: np.ndarray, method: str) -> float:\n",
    "    probs = np.asarray(probs, np.float32)\n",
    "    if probs.size == 0: \n",
    "        return 1e-6\n",
    "    if method == \"mean_prob\":\n",
    "        p = probs.mean()\n",
    "    elif method == \"max_prob\":\n",
    "        p = probs.max()\n",
    "    elif method.startswith(\"topk_mean\"):\n",
    "        try:\n",
    "            frac = float(method.split(\":\",1)[1]) if \":\" in method else 0.2\n",
    "        except Exception:\n",
    "            frac = 0.2\n",
    "        k = max(1, int(len(probs) * frac))\n",
    "        idx = np.argsort(-probs)[:k]\n",
    "        p = probs[idx].mean()\n",
    "    elif method == \"mean_logit\":\n",
    "        # same asä½ çš„ç¨‹å¼ï¼šå¹³å‡ logit å† sigmoid\n",
    "        def _safe_logit(p, eps=1e-6, clamp=20.0):\n",
    "            p = float(np.clip(p, eps, 1.0 - eps))\n",
    "            z = math.log(p) - math.log(1.0 - p)\n",
    "            return float(np.clip(z, -clamp, clamp))\n",
    "        lgs = np.array([_safe_logit(float(x)) for x in probs], np.float32)\n",
    "        lg = float(np.clip(lgs.mean(), -20.0, 20.0))\n",
    "        p = float(1.0/(1.0+np.exp(-lg)))\n",
    "    else:\n",
    "        p = probs.mean()\n",
    "    return float(np.clip(p, 1e-6, 1-1e-6))\n",
    "\n",
    "def infer_stream(pil_img,\n",
    "                 tile=256, stride=128, aggregate=\"topk_mean:0.25\",\n",
    "                 use_clip=True, draw_boxes=True, show_score=True, alpha=0.35,\n",
    "                 progress=gr.Progress(track_tqdm=True)):\n",
    "    \"\"\"\n",
    "    é€æ­¥æ¨è«–ï¼Œæ¯ N å€‹ tile å›å‚³ä¸€æ¬¡ä¸­é–“çµæœï¼Œå¸¶é€²åº¦æ¢ã€‚\n",
    "    è¼¸å‡ºé †åºï¼šcaption(str), overlay(Image), raw(JSON)\n",
    "    \"\"\"\n",
    "    # å…ˆæŠŠä¸Šå‚³åœ–æš«å­˜åˆ°æª”æ¡ˆï¼Œæ²¿ç”¨ä½ ç¾æœ‰çš„å½±åƒ/è½‰ JPG æµç¨‹\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".png\", delete=False) as f:\n",
    "        pil_img.save(f.name)\n",
    "        p = Path(f.name)\n",
    "\n",
    "    try:\n",
    "        base_rgb = Image.open(p).convert(\"RGB\")\n",
    "        # ELA/CLIP ç”¨ JPGï¼ˆè·Ÿä½ çš„ code ä¸€æ¨£ï¼‰\n",
    "        if FORCE_JPG_NONJPG:\n",
    "            p_jpg, _tmp = as_jpg_if_needed(p)\n",
    "        else:\n",
    "            p_jpg = p\n",
    "        img_pil = Image.open(p_jpg).convert(\"RGB\")\n",
    "        W, H = img_pil.size\n",
    "\n",
    "        coords = make_grid(W, H, tile=int(tile), stride=int(stride))\n",
    "        n = len(coords)\n",
    "        tiles_out = []\n",
    "\n",
    "        # PRNU ç”¨åŸå§‹åœ–\n",
    "        np_img = np.asarray(base_rgb, dtype=np.uint8)\n",
    "\n",
    "        # æ¯å¤šå°‘æ­¥æ›´æ–°ä¸€æ¬¡ UIï¼ˆå¤§ç´„ 20 æ®µï¼‰\n",
    "        every = max(1, n // 20)\n",
    "\n",
    "        progress(0.0, desc=f\"æº–å‚™ä¸­â€¦ {W}Ã—{H}, tiles={n}\")\n",
    "        for i, (x,y,w,h) in enumerate(coords):\n",
    "            # å– tile\n",
    "            pil_tile = img_pil.crop((x,y,x+w,y+h))\n",
    "            np_tile  = np.asarray(np_img[y:y+h, x:x+w, :], dtype=np.uint8)\n",
    "\n",
    "            # ç‰¹å¾µ â†’ å­æ¨¡å‹ logit\n",
    "            prnu_i8 = prnu_i8_from_tile(np_tile)\n",
    "            ela_i8  = ela_i8_from_tile(pil_tile)\n",
    "\n",
    "            z_prnu = prnu_logit_from_i8(prnu_i8)\n",
    "            z_ela  = ela_logit_from_i8(ela_i8)\n",
    "            z_clip = clip_single.predict_logit(pil_tile) if (use_clip and clip_single.model is not None) else None\n",
    "\n",
    "            prob_fake = fuse_logits({\"prnu\": z_prnu, \"ela\": z_ela, \"clip\": z_clip})\n",
    "            pred = int(prob_fake >= 0.5)\n",
    "\n",
    "            tiles_out.append({\n",
    "                \"x\":x, \"y\":y, \"w\":w, \"h\":h,\n",
    "                \"prnu_logit\": float(z_prnu),\n",
    "                \"ela_logit\":  float(z_ela),\n",
    "                \"clip_logit\": (None if z_clip is None else float(z_clip)),\n",
    "                \"prob_fake\": float(prob_fake),\n",
    "                \"pred_label\": pred,\n",
    "            })\n",
    "\n",
    "            # é€²åº¦èˆ‡ä¸­é€”å›å‚³\n",
    "            if (i+1) % every == 0 or (i+1) == n:\n",
    "                progress((i+1)/n, desc=f\"æ¨è«–ä¸­â€¦ ({i+1}/{n})\")\n",
    "                probs = np.array([t['prob_fake'] for t in tiles_out], np.float32)\n",
    "                whole_prob = _aggregate_probs(probs, aggregate)\n",
    "                whole_pred = int(whole_prob >= 0.5)\n",
    "\n",
    "                # å³æ™‚ç†±åœ–ï¼ˆç”¨ç›®å‰ç´¯ç©çš„ tilesï¼‰\n",
    "                overlay_img = overlay_tiles(base_rgb, tiles_out, alpha=float(alpha),\n",
    "                                            draw_frame=bool(draw_boxes), show_score=bool(show_score))\n",
    "\n",
    "                out = {\n",
    "                    \"path\": str(p),\n",
    "                    \"image_size\": [H, W],\n",
    "                    \"tile\": int(tile),\n",
    "                    \"stride\": int(stride),\n",
    "                    \"aggregate\": aggregate,\n",
    "                    \"overall\": {\"prob_fake\": float(whole_prob), \"pred_label\": int(whole_pred)},\n",
    "                    \"tiles_done\": len(tiles_out),\n",
    "                    \"tiles_total\": n,\n",
    "                    \"tiles\": tiles_out,   # æ³¨æ„ï¼šé€™æ˜¯ç´¯ç©ä¸­çš„ tilesï¼ˆæœ€å¾Œä¸€æ¬¡å³æ˜¯å®Œæ•´çµæœï¼‰\n",
    "                }\n",
    "                caption = f\"pred={whole_pred}  prob_fake={whole_prob:.3f}  ({i+1}/{n})\"\n",
    "                yield caption, overlay_img, out\n",
    "\n",
    "    finally:\n",
    "        try: p.unlink()\n",
    "        except Exception: pass\n",
    "\n",
    "\n",
    "# ===== Gradio ä»‹é¢ =====\n",
    "with gr.Blocks(title=\"AI Image Detector (CUDA, with progress)\") as demo:\n",
    "    gr.Markdown(\"### Slide-256 Full-Image Inference â€” PRNU / ELA / CLIP + LR Fusionï¼ˆå«é€²åº¦æ¢ï¼‰\")\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            inp = gr.Image(type=\"pil\", label=\"ä¸Šå‚³å½±åƒ\")\n",
    "            with gr.Row():\n",
    "                tile   = gr.Number(value=256, precision=0, label=\"Tile size\")\n",
    "                stride = gr.Number(value=128, precision=0, label=\"Stride\")\n",
    "            aggregate = gr.Dropdown(choices=[\"mean_prob\",\"max_prob\",\"topk_mean:0.2\",\"topk_mean:0.25\",\"mean_logit\"],\n",
    "                                    value=\"topk_mean:0.25\", label=\"Aggregator\")\n",
    "            use_clip   = gr.Checkbox(value=True,  label=\"Use CLIP head\")\n",
    "            draw_boxes = gr.Checkbox(value=True,  label=\"Draw tile boxes\")\n",
    "            show_score = gr.Checkbox(value=True,  label=\"Show tile score\")\n",
    "            alpha      = gr.Slider(0.0, 1.0, value=0.35, step=0.05, label=\"Overlay alpha\")\n",
    "            run = gr.Button(\"é–‹å§‹æ¨è«–\", variant=\"primary\")\n",
    "        with gr.Column(scale=1):\n",
    "            caption = gr.Label(label=\"æ•´é«”é æ¸¬\")\n",
    "            overlay = gr.Image(label=\"å³æ™‚ç–ŠåŠ è¦–è¦ºåŒ–ï¼ˆæœƒé€æ­¥æ›´æ–°ï¼‰\")\n",
    "            raw     = gr.JSON(label=\"Raw è¼¸å‡ºï¼ˆæœ€å¾Œä¸€æ¬¡ç‚ºå®Œæ•´çµæœï¼‰\")\n",
    "\n",
    "    run.click(\n",
    "        infer_stream,\n",
    "        inputs=[inp, tile, stride, aggregate, use_clip, draw_boxes, show_score, alpha],\n",
    "        outputs=[caption, overlay, raw]\n",
    "    )\n",
    "\n",
    "# å»ºè­°åœ¨ notebook å…§ç”¨ queue() å–å¾—å¹³æ»‘é€²åº¦æ¢\n",
    "demo.queue(max_size=8).launch(share=False, inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11bc77a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === äº‹å¾Œå¤šæ¨™æº–å½™ç¸½ï¼šä¸é‡è·‘æ¨¡å‹ ===\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# åŒä½ ä¹‹å‰å°å·¥å…·\n",
    "def _aggregate_probs(probs: np.ndarray, method: str) -> float:\n",
    "    probs = np.asarray(probs, np.float32)\n",
    "    if probs.size == 0: \n",
    "        return 1e-6\n",
    "    if method == \"mean_prob\":\n",
    "        p = probs.mean()\n",
    "    elif method == \"max_prob\":\n",
    "        p = probs.max()\n",
    "    elif method.startswith(\"topk_mean\"):\n",
    "        try:\n",
    "            frac = float(method.split(\":\",1)[1]) if \":\" in method else 0.5\n",
    "        except Exception:\n",
    "            frac = 0.5\n",
    "        k = max(1, int(len(probs) * frac))\n",
    "        idx = np.argsort(-probs)[:k]\n",
    "        p = probs[idx].mean()\n",
    "    elif method == \"mean_logit\":\n",
    "        def _safe_logit(p, eps=1e-6, clamp=20.0):\n",
    "            p = float(np.clip(p, eps, 1.0 - eps))\n",
    "            z = np.log(p) - np.log(1.0 - p)\n",
    "            return float(np.clip(z, -clamp, clamp))\n",
    "        lgs = np.array([_safe_logit(float(x)) for x in probs], np.float32)\n",
    "        lg = float(np.clip(lgs.mean(), -20.0, 20.0))\n",
    "        p = float(1.0/(1.0+np.exp(-lg)))\n",
    "    else:\n",
    "        p = probs.mean()\n",
    "    return float(np.clip(p, 1e-6, 1-1e-6))\n",
    "\n",
    "# 1) è·‘ä¸€æ¬¡å®Œæ•´æ¨è«–ï¼ˆä¸éœ€è¦ aggregate å…¥åƒï¼‰\n",
    "def run_once(img, tile, stride, use_clip, alpha):\n",
    "    res = infer_image_by_tiles(\n",
    "        img, tile=int(tile), stride=int(stride),\n",
    "        aggregate='mean_prob',           # é€™è£¡åªæ˜¯å ä½ï¼Œä¸å½±éŸ¿å¾Œé¢å¤šæ¨™æº–è¨ˆç®—\n",
    "        use_clip=bool(use_clip),\n",
    "        save_overlay=True, overlay_alpha=float(alpha)\n",
    "    )\n",
    "    overlay = None\n",
    "    if res.get(\"overlay_path\"):\n",
    "        overlay = Image.open(res[\"overlay_path\"]).convert(\"RGB\")\n",
    "    # æç¤ºï¼šæ¨è«–å·²å®Œæˆï¼Œè«‹åœ¨å³å´å‹¾é¸å½™ç¸½æ–¹å¼\n",
    "    caption = \"æ¨è«–å®Œæˆï¼Œè«‹åœ¨å³å´å‹¾é¸ä¸€å€‹æˆ–å¤šå€‹å½™ç¸½æ–¹å¼ï¼ˆä¸æœƒé‡è·‘ï¼‰\"\n",
    "    return caption, overlay, res\n",
    "\n",
    "# 2) å¾ raw çµæœï¼ˆtilesï¼‰äº‹å¾Œè¨ˆç®—å¤šç¨®å½™ç¸½\n",
    "def reaggregate(raw_result: dict, methods: list[str]):\n",
    "    if not raw_result or \"tiles\" not in raw_result:\n",
    "        return \"å°šæœªæœ‰æ¨è«–çµæœ\", []\n",
    "    probs = np.array([t['prob_fake'] for t in raw_result['tiles']], np.float32)\n",
    "    table = []\n",
    "    best = (\"\", -1.0, 0)\n",
    "    for m in (methods or []):\n",
    "        p = _aggregate_probs(probs, m)\n",
    "        y = int(p >= 0.5)\n",
    "        table.append([m, round(float(p), 6), y])\n",
    "        if p > best[1]:\n",
    "            best = (m, p, y)\n",
    "    if not methods:\n",
    "        return \"è«‹è‡³å°‘é¸æ“‡ä¸€å€‹å½™ç¸½æ–¹å¼\", []\n",
    "    msg = f\"æœ€ä½³ï¼š{best[0]}  prob={best[1]:.4f}  pred={best[2]}\"\n",
    "    return msg, table\n",
    "\n",
    "# === Gradio ä»‹é¢ï¼ˆç²¾ç°¡ã€å¯ç›´æ¥ç”¨æ‰‹æ©Ÿï¼‰===\n",
    "with gr.Blocks(title=\"AI Image Detector â€” äº‹å¾Œå¤šæ¨™æº–å½™ç¸½\", css=\"\"\"\n",
    "  .gradio-container {max-width: 980px !important;}\n",
    "\"\"\") as demo2:\n",
    "    gr.Markdown(\"### Slide-256 â€” å…ˆæ¨è«–ï¼Œå†å¤šæ¨™æº–å½™ç¸½ï¼ˆä¸é‡è·‘æ¨¡å‹ï¼‰\")\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            inp = gr.Image(type=\"filepath\", label=\"ä¸Šå‚³æˆ–æ‹ç…§\",\n",
    "                           sources=[\"upload\",\"webcam\",\"clipboard\"], height=320)\n",
    "            with gr.Row():\n",
    "                tile   = gr.Number(value=256, precision=0, label=\"Tile\")\n",
    "                stride = gr.Number(value=128, precision=0, label=\"Stride\")\n",
    "            use_clip = gr.Checkbox(value=True, label=\"Use CLIP head\")\n",
    "            alpha    = gr.Slider(0.0, 1.0, value=0.35, step=0.05, label=\"Overlay alpha\")\n",
    "            run_btn  = gr.Button(\"é–‹å§‹æ¨è«–\", variant=\"primary\")\n",
    "        with gr.Column(scale=1):\n",
    "            caption = gr.Label(label=\"æ•´é«”è³‡è¨Š / å½™ç¸½è¨Šæ¯\")\n",
    "            overlay = gr.Image(label=\"Overlayï¼ˆèˆ‡å½™ç¸½ç„¡é—œï¼Œåƒ…ä¾ tile æ©Ÿç‡ï¼‰\")\n",
    "            # é¡¯ç¤ºåŸå§‹çµæœï¼ˆå« tilesï¼‰ï¼Œæ–¹ä¾¿é™¤éŒ¯ / ä¹Ÿæä¾› reaggregate çš„è¼¸å…¥\n",
    "            raw     = gr.JSON(label=\"Raw çµæœï¼ˆtilesï¼‰\")\n",
    "            # å¤šé¸å½™ç¸½æ–¹å¼ï¼ˆäº‹å¾Œç®—ï¼‰\n",
    "            methods = gr.CheckboxGroup(\n",
    "                choices=[\"mean_prob\",\"max_prob\",\"topk_mean:0.5\",\"topk_mean:0.25\",\"mean_logit\"],\n",
    "                label=\"é¸æ“‡ä¸€å€‹æˆ–å¤šå€‹å½™ç¸½æ–¹å¼ï¼ˆä¸é‡è·‘ï¼‰\"\n",
    "            )\n",
    "            recompute = gr.Button(\"é‡æ–°è¨ˆç®—å½™ç¸½\")\n",
    "            table = gr.Dataframe(\n",
    "                headers=[\"method\",\"prob_fake\",\"pred_label\"],\n",
    "                datatype=[\"str\",\"number\",\"number\"],\n",
    "                interactive=False,\n",
    "                label=\"å„å½™ç¸½æ–¹å¼çµæœ\"\n",
    "            )\n",
    "\n",
    "    # è·‘ä¸€æ¬¡æ¨è«–ï¼Œå­˜ raw çµæœï¼›ä¸éœ€è¦ aggregate å…¥åƒ\n",
    "    run_btn.click(\n",
    "        run_once,\n",
    "        inputs=[inp, tile, stride, use_clip, alpha],\n",
    "        outputs=[caption, overlay, raw]\n",
    "    )\n",
    "\n",
    "    # äº‹å¾Œå¤šæ¨™æº–å½™ç¸½ï¼šç›´æ¥è®€å– rawï¼ˆtilesï¼‰ï¼Œä¸é‡è·‘æ¨¡å‹\n",
    "    recompute.click(\n",
    "        reaggregate,\n",
    "        inputs=[raw, methods],\n",
    "        outputs=[caption, table]\n",
    "    )\n",
    "\n",
    "# ç”¨ queue å¯ä¿æŒé †æš¢ï¼›Gradio 4.x ä¸è¦ concurrency_count\n",
    "demo2.queue(max_size=8).launch(share=False, inline=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6418551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7261/2033640146.py:459: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  heat_img = Image.fromarray(heat_rgb, mode='RGB')\n",
      "/tmp/ipykernel_7261/2033640146.py:459: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  heat_img = Image.fromarray(heat_rgb, mode='RGB')\n",
      "/tmp/ipykernel_7261/2033640146.py:459: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  heat_img = Image.fromarray(heat_rgb, mode='RGB')\n",
      "/tmp/ipykernel_7261/2033640146.py:459: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  heat_img = Image.fromarray(heat_rgb, mode='RGB')\n",
      "/tmp/ipykernel_7261/2033640146.py:459: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  heat_img = Image.fromarray(heat_rgb, mode='RGB')\n",
      "/tmp/ipykernel_7261/2033640146.py:459: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  heat_img = Image.fromarray(heat_rgb, mode='RGB')\n",
      "/tmp/ipykernel_7261/2033640146.py:459: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  heat_img = Image.fromarray(heat_rgb, mode='RGB')\n",
      "/tmp/ipykernel_7261/2033640146.py:459: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  heat_img = Image.fromarray(heat_rgb, mode='RGB')\n",
      "/tmp/ipykernel_7261/2033640146.py:459: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  heat_img = Image.fromarray(heat_rgb, mode='RGB')\n",
      "/tmp/ipykernel_7261/2033640146.py:459: DeprecationWarning: 'mode' parameter is deprecated and will be removed in Pillow 13 (2026-10-15)\n",
      "  heat_img = Image.fromarray(heat_rgb, mode='RGB')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # ========= ç¯„ä¾‹ =========\n",
    "# if __name__ == \"__main__\":\n",
    "#     IMG_PATH = \"/home/yaya/ai-detect-proj/test_img/real/Wtc-photo.jpg\"\n",
    "#     result = infer_image_by_tiles(IMG_PATH, tile=256, stride=128, aggregate='mean_logit', use_clip=True)\n",
    "#     print(json.dumps(result, ensure_ascii=False, indent=2))\n",
    "#     if result.get('overlay_path'):\n",
    "#         print(\"Overlay saved to:\", result['overlay_path'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
